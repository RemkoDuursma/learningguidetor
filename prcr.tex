\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={A Learning Guide to R: data, analytical, and programming skills.},
            pdfauthor={Remko Duursma},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{A Learning Guide to R: data, analytical, and programming skills.}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Remko Duursma}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{2019-06-10}




\usepackage{booktabs}
\usepackage{amsthm}

% Main font
\usepackage[default,osfigures,scale=0.95]{opensans} 

\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother


\usepackage{framed}
\usepackage{etoolbox}


% % Taken from rnotesformat.sty
% \usepackage{parskip}
\usepackage{breakurl}
% \usepackage{fancyvrb}
\usepackage{geometry}
\geometry{verbose,tmargin=3cm,bmargin=3cm,lmargin=3cm,rmargin=3cm}
% \usepackage{url}
% \usepackage{xr}
% \usepackage[unicode=true,pdfusetitle,
%  bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
%  breaklinks=false,pdfborder={0 0 0},backref=false,colorlinks=true,linkcolor=blue]
%  {hyperref}
% \hypersetup{pdfstartview={XYZ null null 1}}





% Colours for shaded boxes
\definecolor{shadecolor}{rgb}{0.96,1,0.96}  %tryyourself box
\definecolor{shadecolor2}{rgb}{0.96,1,1}   %furtherreading box

\newlength{\boxwidth}
\setlength{\boxwidth}{\textwidth}

\newenvironment{rmdcaution}{%
  \def\FrameCommand{\fboxsep=\FrameSep \fboxrule=\FrameRule \fcolorbox{black}{shadecolor}}%
  \MakeFramed {\setlength{\boxwidth}{\textwidth}
  \addtolength{\boxwidth}{-2\FrameSep}
  \addtolength{\boxwidth}{-2\FrameRule}
  \setlength{\hsize}{\boxwidth} \FrameRestore}
  \begin{samepage}
  \large{\textbf{\textsf{Caution}}} 
%   \rule[2mm]{85mm}{.2pt}
%   \\ \nopagebreak
  \normalsize{}
  \end{samepage}
  }%
{\endMakeFramed}

\newenvironment{rmdinfo}{%
  \def\FrameCommand{\fboxsep=\FrameSep \fboxrule=\FrameRule \fcolorbox{black}{shadecolor}}%
  \MakeFramed {\setlength{\boxwidth}{\textwidth}
  \addtolength{\boxwidth}{-2\FrameSep}
  \addtolength{\boxwidth}{-2\FrameRule}
  \setlength{\hsize}{\boxwidth} \FrameRestore}
  \begin{samepage}
  \large{\textbf{\textsf{Info}}} 
%   \rule[2mm]{85mm}{.2pt}
%   \\ \nopagebreak
  \normalsize{}
  \end{samepage}
  }%
{\endMakeFramed}

\newenvironment{rmdtry}{%
  \def\FrameCommand{\fboxsep=\FrameSep \fboxrule=\FrameRule \fcolorbox{black}{shadecolor}}%
  \MakeFramed {\setlength{\boxwidth}{\textwidth}
  \addtolength{\boxwidth}{-2\FrameSep}
  \addtolength{\boxwidth}{-2\FrameRule}
  \setlength{\hsize}{\boxwidth} \FrameRestore}
  \begin{samepage}
  \large{\textbf{\textsf{Try this yourself}}} 
%   \rule[2mm]{85mm}{.2pt}
%   \\ \nopagebreak
  \normalsize{}
  \end{samepage}
  }%
{\endMakeFramed}

\newenvironment{rmdreading}{%
  \def\FrameCommand{\fboxsep=\FrameSep \fboxrule=\FrameRule \fcolorbox{black}{shadecolor2}}%
  \MakeFramed {\setlength{\boxwidth}{\textwidth}
  \addtolength{\boxwidth}{-2\FrameSep}
  \addtolength{\boxwidth}{-2\FrameRule}
  \setlength{\hsize}{\boxwidth} \FrameRestore}
  \begin{samepage}
  \large{\textbf{\textsf{Further reading}}} 
%   \rule[2mm]{85mm}{.2pt}
%   \\ \nopagebreak
  \normalsize{}
  \end{samepage}
  }%
{\endMakeFramed}

\newenvironment{rmdwarning}{%
  \def\FrameCommand{\fboxsep=\FrameSep \fboxrule=\FrameRule \fcolorbox{black}{shadecolor}}%
  \MakeFramed {\setlength{\boxwidth}{\textwidth}
  \addtolength{\boxwidth}{-2\FrameSep}
  \addtolength{\boxwidth}{-2\FrameRule}
  \setlength{\hsize}{\boxwidth} \FrameRestore}
  \begin{samepage}
  \large{\textbf{\textsf{Warning}}} 
%   \rule[2mm]{85mm}{.2pt}
%   \\ \nopagebreak
  \normalsize{}
  \end{samepage}
  }%
{\endMakeFramed}

\newenvironment{rmdnote}{%
  \def\FrameCommand{\fboxsep=\FrameSep \fboxrule=\FrameRule \fcolorbox{black}{shadecolor}}%
  \MakeFramed {\setlength{\boxwidth}{\textwidth}
  \addtolength{\boxwidth}{-2\FrameSep}
  \addtolength{\boxwidth}{-2\FrameRule}
  \setlength{\hsize}{\boxwidth} \FrameRestore}
  \begin{samepage}
  \large{\textbf{\textsf{Note}}} 
%   \rule[2mm]{85mm}{.2pt}
%   \\ \nopagebreak
  \normalsize{}
  \end{samepage}
  }%
{\endMakeFramed}

\let\BeginKnitrBlock\begin \let\EndKnitrBlock\end
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{preface}{%
\chapter{Preface}\label{preface}}

This book is not an introduction to statistical theory, although sometimes we repeat a little theory to be able to make sense of R output. This book should not be the first statistics book you read. Instead, this book shows you how to implement many useful data analysis routines in R. We really assume that you have already learned statistics elsewhere and are here to learn how to actually do the analyses with R.

We have learned from experience that data practictioners, that means scientists and everyone else who has an interest in learning from data, do not learn statistical analyses by studying the underlying theory. They learn from doing, and from using examples written by others who have learned by doing. For this reason the book in front of you is largely a compendium of examples. We have chosen the examples and the exercises in the hope that they resemble real-world problems.

We have placed many \emph{Try it yourself} boxes throughout the text to give you some ideas on what to try, but try to be creative and modify the examples to see what happens.

\hypertarget{intro}{%
\chapter{Beginner skills}\label{intro}}

\hypertarget{installingr}{%
\section{Installing R and Rstudio}\label{installingr}}

We assume you have installed R and Rstudio. We occasionally give some tips on how to use Rstudio effectively, but since Rstudio is likely to change more quickly than R - we instead suggest you keep an eye on their documentation (link).

We assume that you have installed both R, and Rstudio. Please visit both websites (\href{http://cran.r-project.org}{here} for R, \href{www.rstudio.org}{here for Rstudio}) to download the latest version for your platform. Note that Rstudio simply runs R for us (and provides many, many other features) - you still need to install R itself.

\textbf{Rstudio settings}

We strongly recommend you change the following default settings in Rstudio. The default behaviour is to save all your objects to an `RData' file when you exit, and loads the same objects when you open RStudio. This is very dangerous behaviour, and you \textbf{must} turn it off. For now, make sure you go to Tools \textgreater{} Global Options\ldots{} and on the General tab, make sure the settings are like the figure below.

\includegraphics[width=0.4\linewidth]{screenshots/neverloadrdata}

Another feature you may want to turn off is the automatic code completion, which is now a standard feature in RStudio. This is a matter of taste, but we find it handier to use code completion only when requested. If you change the settings as shown in the screenshot below, you can engage code completion by typing part of a function and then pressing \texttt{Tab}.

\includegraphics[width=0.4\linewidth]{screenshots/rstudionocodecomplete}

\BeginKnitrBlock{rmdreading}
This text is not a complete or even comprehensive guide to Rstudio - we focus on R. If you want to know more about all the options in the menu's, keyboard shortcuts, and various add-ons and features, \href{https://support.rstudio.com/hc/en-us/sections/200107586-Using-the-RStudio-IDE}{please visit this link} to get started.
\EndKnitrBlock{rmdreading}

\hypertarget{exampledata}{%
\subsection{Example data used throughout this book}\label{exampledata}}

All example datasets used throughout this book are provided in the R package \texttt{lgrdata}. Install it like any other package (see \ref{packages} for more information):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"lgrdata"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

At the start of each script where you use an example dataset, load the package:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lgrdata)}
\end{Highlighting}
\end{Shaded}

Then, you can make available any dataset from the package with :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(allometry)}
\end{Highlighting}
\end{Shaded}

Each dataset has help page, inspect it (\texttt{?allometry}) to learn a bit about the dataset, the meaning and units of the variables, and sometimes a simple example plot with the data.

\hypertarget{basicops}{%
\section{Basic operations}\label{basicops}}

In Rstudio, the R console is shown in one of the windows. The other windows include the `Environment' window (with tabs `Environment', `History', etc.), a `File management' window (where you can browse files, view plots, install packages, etc.), and a source window.

The source window (containing a script where you can write and save code) may not show up on your first use of Rstudio, press Ctrl-Shift-N to open a new script. We return to scripts in Section \ref{scripts}.

In the console, you can type R code and get immediate results, for example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# I want to add two numbers:}
\DecValTok{1} \OperatorTok{+}\StringTok{ }\DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2
\end{verbatim}

Here, we typed \texttt{1\ +\ 1}, hit Enter, and R produced \texttt{2}. The \texttt{{[}1{]}} means that the result only has one element (the number `2').

In this book, the R output is shown after \texttt{\#\#}. Every example can be run by you, simply copy the section (use the text selection tool in Adobe reader), and paste it into the console (with Ctrl + Enter on a Windows machine, or Cmd + Enter on a Mac).

We can do all sorts of basic calculator operations. Consider the following examples:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Arithmetic}
\DecValTok{12} \OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{10} \OperatorTok{+}\StringTok{ }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 132
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Scientific notation}
\FloatTok{3.5E03} \OperatorTok{+}\StringTok{ }\FloatTok{4E-01}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3500.4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# pi is a built-in constant}
\KeywordTok{sin}\NormalTok{(pi}\OperatorTok{/}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Absolute value}
\KeywordTok{abs}\NormalTok{(}\OperatorTok{-}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Yes, you can divide by zero}
\DecValTok{1001}\OperatorTok{/}\DecValTok{0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] Inf
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Square root}
\KeywordTok{sqrt}\NormalTok{(}\DecValTok{225}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Exponents}
\DecValTok{15}\OperatorTok{^}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 225
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Round down to nearest integer (and ceiling() for up or round() for closest)}
\KeywordTok{floor}\NormalTok{(}\FloatTok{3.1415}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3
\end{verbatim}

Try typing \texttt{?Math} for description of more mathematical functions.

Also note the use of \texttt{\#} for comments: anything after this symbol on the same line is \emph{not} read by R.

\BeginKnitrBlock{rmdtry}
When typing code directly into the console (other than a script, which is what you usually will do when developing more serious code), consider these tips:

\begin{itemize}
\tightlist
\item
  Press \textbf{UP} on your keyboard to repeat the previous command (and keep pressing UP to find all previous commands).
\item
  Press \textbf{TAB} to auto-complete the name of a function (even those from loaded packages); very handy if you don't remember the name of the function, or you can't be bothered typing it in.
\item
  Press \textbf{CTRL-L} (CMD-L on Mac) to `clear' the console. This does not remove the history or any objects, just starts a fresh screen.
\item
  Press \textbf{ESC} to cancel an operation (if R is taking long, and you don't want to wait).
\end{itemize}
\EndKnitrBlock{rmdtry}

\hypertarget{vectorintro}{%
\section{Working with vectors}\label{vectorintro}}

A very useful type of object is the \texttt{vector}, which is basically a string of numbers or bits of text (but not a combination of both). The power of R is that most functions can use a vector directly as input, which greatly simplifies coding in many applications.

Let's construct an example vector with 7 numbers:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nums1 <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{11}\NormalTok{,}\DecValTok{100}\NormalTok{,}\DecValTok{8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We can now do basic arithmetic with this \emph{numeric vector} :

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Get the sum of a vector:}
\KeywordTok{sum}\NormalTok{(nums1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 134
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Get mean, standard deviation, number of observations (length):}
\KeywordTok{mean}\NormalTok{(nums1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 19.14286
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sd}\NormalTok{(nums1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 35.83494
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{length}\NormalTok{(nums1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Some functions result in a new vector, for example:}
\KeywordTok{rev}\NormalTok{(nums1)  }\CommentTok{# reverse elements}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]   8 100  11   8   2   4   1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cumsum}\NormalTok{(nums1)  }\CommentTok{# cumulative sum}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]   1   5   7  15  26 126 134
\end{verbatim}

There are many more functions you can use directly on vectors. See the table below for a few useful ones.

\begin{table}[t]

\caption{\label{tab:unnamed-chunk-13}A selection of useful built-in functions in R.}
\centering
\begin{tabular}{l|l|l}
\hline
Function & What it does & Example\\
\hline
`length` & Length of the vector & `length(nums1)`\\
\hline
`rev` & Reverses the elements of a vector & `rev(nums1)`\\
\hline
`sort` & Sorts the elements of a vector & `sort(nums1, decreasing = TRUE)`\\
\hline
`order` & The order of elements in a vector & `order(nums1)`\\
\hline
`head` & The first few elements of a vector & `head(nums1, 5)`\\
\hline
`max` & The maximum value & `max(nums1)`\\
\hline
`min` & The minimum value & `min(nums1)`\\
\hline
`which.max` & Which element of the vector is the max? & `which.max(nums1)`\\
\hline
`which.min` & Which element of the vector is the min? & `which.min(nums1)`\\
\hline
`mean` & Computes the average of the vector & `mean(nums1)`\\
\hline
`median` & Computers the median & `median(nums1)`\\
\hline
`var` & Variance & `var(nums1)`\\
\hline
`sd` & Standard deviation & `sd(nums1)`\\
\hline
`cumsum` & Cumulative sum (running total) & `cumsum(nums1)`\\
\hline
`diff` & Successive difference of a vector & `diff(nums1)`\\
\hline
`unique` & Unique values used in the vector & `unique(nums1)`\\
\hline
`round` & Rounds numbers to a specified number of decimal points & `round(nums1, 2)`\\
\hline
\end{tabular}
\end{table}

\hypertarget{vectorized-operations}{%
\section{Vectorized operations}\label{vectorized-operations}}

To continue, we are first going to open a script - simply a text file where you can type your code, and execute it immediately. To do so, click on the menu File/New File/R Script. In the file that opens, try typing the examples below (or copy-pasting for the lazy). A single line can be run by placing the cursor on that line, and clicking `Run' in the menu just to the top-right of the window. Alternatively (and this is \textbf{recommended}), use the keyboard shortcut \texttt{Ctrl-Enter} (or \texttt{Cmd-Enter} on Mac) to run that line. If you make a text selection with the mouse, this selection can be executed with the same keyboard shortcut.

In the above section, we introduced a number of functions that you can use to do calculations on a vector of numbers. In R, a number of operations can be done on two vectors, and the result is a vector itself. Basically, R knows to apply these operations one element at a time. This is best illustrated by some examples:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Make two vectors,}
\NormalTok{vec1 <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\NormalTok{vec2 <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{11}\NormalTok{,}\DecValTok{12}\NormalTok{,}\DecValTok{13}\NormalTok{,}\DecValTok{14}\NormalTok{,}\DecValTok{15}\NormalTok{)}

\CommentTok{# Add a number, element-wise}
\NormalTok{vec1 }\OperatorTok{+}\StringTok{ }\DecValTok{10}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 11 12 13 14 15
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Element-wise quadratic:}
\NormalTok{vec1}\OperatorTok{^}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1  4  9 16 25
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Pair-wise multiplication:}
\NormalTok{vec1 }\OperatorTok{*}\StringTok{ }\NormalTok{vec2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 11 24 39 56 75
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Pair-wise sum:}
\NormalTok{vec1 }\OperatorTok{+}\StringTok{ }\NormalTok{vec2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 12 14 16 18 20
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Compare the pair-wise sum to the sum of both vectors:}
\KeywordTok{sum}\NormalTok{(vec1) }\OperatorTok{+}\StringTok{ }\KeywordTok{sum}\NormalTok{(vec2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 80
\end{verbatim}

In each of the above examples, the operators (like \texttt{+} and so on) `know' to make the calculations one element at a time (if one vector), or pair-wise (when two vectors). Clearly, for all examples where two vectors were used, the two vectors need to be the same length (i.e., have the same number of elements).

\hypertarget{multifunctions}{%
\subsection{Applying multiple functions at once}\label{multifunctions}}

In R, we can apply functions and operators in combination. In the following examples, the \emph{innermost} expressions are always evaluated first. This will make sense after some examples:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Mean of the vector 'vec1', *after* squaring the values:}
\KeywordTok{mean}\NormalTok{(vec1}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 11
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Mean of the vector, *then* square it:}
\KeywordTok{mean}\NormalTok{(vec1)}\OperatorTok{^}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Mean of the log of vec2:}
\KeywordTok{mean}\NormalTok{(}\KeywordTok{log}\NormalTok{(vec2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.558972
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Log of the mean of vec2:}
\KeywordTok{log}\NormalTok{(}\KeywordTok{mean}\NormalTok{(vec2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.564949
\end{verbatim}

Alternatively, we can use the \texttt{pipe} operator, which allows us to write the operators in order of application. For the pipe operator, we need to load the \texttt{magrittr} package (see \ref{packages} on how to install and load packages).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(magrittr)}

\CommentTok{# Identical to mean(log(vec2))}
\NormalTok{vec2 }\OperatorTok{%>%}\StringTok{ }\NormalTok{log }\OperatorTok{%>%}\StringTok{ }\NormalTok{mean}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.558972
\end{verbatim}

The above code can be written in at least two other equivalent ways: \texttt{log(vec2)\ \%\textgreater{}\%\ mean}, and even \texttt{log(vec2)\ \%\textgreater{}\%\ mean(.)}, where the \texttt{.} indicates explicitly the result from the previous operator.

In any of the following, we assume you have loaded either \texttt{magrittr}, or some package that loads it for you (for example, \texttt{dplyr}). If you have not, you will see the error message \texttt{could\ not\ find\ function\ "\%\textgreater{}\%"}.

The pipe operator has become very popular, and we use it when it greatly simplifies code, making it easier to follow what the code actually does (and in which order).

\hypertarget{objects-in-the-workspace}{%
\section{Objects in the workspace}\label{objects-in-the-workspace}}

In the examples above, we have created a few new objects. These objects are kept in memory for the remainder of your session (that is, until you close R).

In RStudio, you can browse all objects that are currently loaded in memory. Objects that are currently loaded in memory make up your \emph{workspace}. Find the window that has the tab `Environment'. Here you see a list of all the objects you have created in this R session. When you click on an object, a window opens that shows the contents of the object.

Alternatively, to see which objects you currently have in your workspace, use the following command:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ls}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "nums1"   "vec1"    "vec2"    "words"   "x"       "y"       "a"      
## [8] "b"       "numbers"
\end{verbatim}

To remove objects,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rm}\NormalTok{(nums1, nums2)}
\end{Highlighting}
\end{Shaded}

And to remove all objects that are currently loaded, use this command. \textbf{Note:} you want to use this wisely!

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rm}\NormalTok{(}\DataTypeTok{list=}\KeywordTok{ls}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

Finally, when you are ending your R session, but you want to continue exactly at this point the next time, make sure to save the current workspace. In RStudio, find the menu \texttt{Session} (at the top). Here you can save the current workspace, and also load a previously saved one.

\hypertarget{fileswd}{%
\section{Files in the working directory}\label{fileswd}}

Each time you run R, it `sees' one of your folders (`directories') and all the files in it. This folder is called the \emph{working directory}. You can change the working directory in RStudio in a couple of ways.

The first option, in Rstudio, is to go to the menu \texttt{Session\ \textgreater{}\ Set\ Working\ Directory\ \textgreater{}\ Choose\ Directory...}.

Or, find the `Files' tab in one of the RStudio windows (usually bottom-right). Here you can browse to the directory you want to use (by clicking on the small \texttt{...} button on the right ), and click \texttt{More\ \textgreater{}\ Set\ as\ working\ directory}.

You can also set or query the current working directory by typing the following code:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Set working directory to C:/myR}
\KeywordTok{setwd}\NormalTok{(}\StringTok{"C:/myR"}\NormalTok{)}

\CommentTok{# What is the current working directory?}
\KeywordTok{getwd}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\emph{Note:} For Windows users, use a forward slash (that is, /), not a back slash!

Finally, you can see which files are available in the current working directory, as well as in subdirectories, using the \texttt{dir} function (\emph{Note}: a synonym for this function is \texttt{list.files}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Show files in the working directory:}
\KeywordTok{dir}\NormalTok{()}

\CommentTok{# List files in some other directory:}
\KeywordTok{dir}\NormalTok{(}\StringTok{"c:/work/projects/data/"}\NormalTok{)}

\CommentTok{# Show files in the subdirectory "data":}
\KeywordTok{dir}\NormalTok{(}\StringTok{"data"}\NormalTok{)}

\CommentTok{# Show files in the working directory that end in csv.}
\CommentTok{# (The ignore.case=TRUE assures that we find files that end in 'CSV' as well as 'csv',}
\CommentTok{# and the '[]' is necessary to find the '.' in '.csv'.}
\KeywordTok{dir}\NormalTok{(}\DataTypeTok{pattern=}\StringTok{"[.]csv"}\NormalTok{, }\DataTypeTok{ignore.case=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{rstudio-projects}{%
\section{Rstudio projects}\label{rstudio-projects}}

If you end up working primarily from Rstudio, we very strongly recommend the use of Projects in Rstudio to keep your work organized, and to help set the working directory.

Rstudio projects are really just small files added to a certain folder, which ``tags'' that folder as containing a particular project. This idea works best if you have organized your work into smaller subsections, where you keep your different projects in separate folders.

\hypertarget{packages}{%
\section{Packages}\label{packages}}

Throughout this tutorial, we will focus on the basic functionality of R, but we will also call on a number of add-on `packages' that include additional functions. These packages need to be \emph{installed} (downloaded) before first use, and \emph{loaded} every time you start a new R session.

\hypertarget{install-packages-from-cran}{%
\subsection{Install packages from CRAN}\label{install-packages-from-cran}}

You can find a full list of packages available for R on the CRAN site (\url{http://cran.r-project.org/}, navigate to `Packages'), but be warned -- it's a very long list, with over 10000 packages. If you really want to browse a long list of packages, you should prefer the website \url{http://r-pkg.org/}, which provides a nice interface.

In RStudio, click on the \texttt{Packages} tab in the lower-right hand panel. There you can see which packages are already installed, and you can install more by clicking on the \texttt{Install} button.

Alternatively, to install a particular package, simply type:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"gplots"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\BeginKnitrBlock{rmdcaution}
Never use \texttt{install.packages} in an rmarkdown file (it simply does not work), and it is generally bad practice to add it to a script, since you don't want the packages to be installed every time the script is run. Instead, make it clear what the dependencies are in a README file, or use the approach outlined in ``Loading many packages'' further below, or in ``Install missing packages''.
\EndKnitrBlock{rmdcaution}

The package needs to be installed only once (except when you need to update it, see Section \ref{updatingpackages}). To use the package in your current R session, type:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(gplots)}
\end{Highlighting}
\end{Shaded}

This loads the \texttt{gplots} package from your library into working memory. You can now use the functions available in the \texttt{gplots} package. If you close and reopen R, you will need to load the package again (but you don't have to install it again).

To quickly learn which functions are included in a package, type:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\DataTypeTok{help=}\NormalTok{gplots)}
\end{Highlighting}
\end{Shaded}

\hypertarget{setting-the-cran-mirror}{%
\subsection{Setting the CRAN mirror}\label{setting-the-cran-mirror}}

CRAN is a central package for R packages, but it is hosted on many servers around the world. Back in the day, you always had to set the CRAN `mirror' once for every R session. If you are using Rstudio, though, you won't have to worry about this as it is set automatically to Rstudio's own CRAN mirror, which is actually just a clever service that sends you to a nearby server.

If you use R from the command line, you might want to set the mirror directly:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{options}\NormalTok{(}\DataTypeTok{repos =} \KeywordTok{c}\NormalTok{(}\DataTypeTok{CRAN =} \StringTok{"https://cran.rstudio.com/"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

This avoids an annoying popup when attempting \texttt{install.packages}.

\hypertarget{install-from-git-hosting-sites}{%
\subsection{Install from git hosting sites}\label{install-from-git-hosting-sites}}

The previous section applies to packages that have been uploaded to CRAN (the central repository for R packages). It is however also quite common for R packages to be available on Github or Bitbucket - two large web services that host source code under \emph{git} version control. For repositories that contain R packages, these cannot be installed via \texttt{install.packages}. Instead, do:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(remotes)}
\KeywordTok{install_bitbucket}\NormalTok{(}\StringTok{"remkoduursma/fitplc"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This installs an R package from www.bitbucket.org. Similarly, \texttt{install\_github} installs the package from www.github.com, if it is hosted there.

For this command to work, your system needs to be able to compile R packages from source. Windows users will need to install \href{https://cran.r-project.org/bin/windows/Rtools/}{Rtools}.

\hypertarget{updating-r-and-package-locations}{%
\subsection{Updating R and package locations}\label{updating-r-and-package-locations}}

By default, \texttt{install.packages} places the packages in a subdirectory of your R installation, which means that when you update R, you have to reinstall all packages - unless you follow these instructions. To check where your packages are being installed to, type:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{.libPaths}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

You may see more than one path listed - packages will be installed to the first directory. It is generally a good idea to make a custom location for all your packages, for example under \texttt{c:/RLIBRARY}, or \texttt{\textasciitilde{}/rpackages}, or some other location independent of where R is installed.

To do this, you have to add an environment variable \texttt{R\_LIBS}, that points to your custom directory. If you don't know how to do this, simply do a web search for `add environment variable windows/mac'. The next time you open Rstudio, \texttt{.libPaths()} should show the custom directory.

\hypertarget{updatingpackages}{%
\subsection{Updating packages}\label{updatingpackages}}

Besides updating R and Rstudio itself (which is recommended at least every couple of months or so), it is also a very good idea to keep all packages up to date. If your workflow ends up depending on an older version of the package, your code may not work on a different system. To update all \emph{installed} packages, you can run the following command - make sure to do this right after opening Rstudio:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{update.packages}\NormalTok{(}\DataTypeTok{ask=}\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

It is usually best to type `no' when the installation process asks if you want to compile some updated packages. Also, occasionally this process fails - usually stating e.g.~`package Rcpp not found'. Then first install those packages (the usual way), and retry \texttt{update.packages}.

\hypertarget{install-missing-packages}{%
\subsection{Install missing packages}\label{install-missing-packages}}

The \texttt{reinstallr} package can be used to install all packages that are `mentioned' in any of the source files in your working directory. That is, all those that are loaded in an R script, rmarkdown file, and some others, using \texttt{library} or \texttt{require}. You can simply do,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(reinstallr)}
\KeywordTok{reinstallr}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{conflicts}{%
\subsection{Conflicts}\label{conflicts}}

It is fairly common that certain functions appear in multiple packages. For example, \texttt{summarize} is a function in \texttt{Hmisc} and in \texttt{dplyr}. If you have loaded \texttt{Hmisc} first, and then load \texttt{dplyr}, you will see (among others), the following message:

\begin{verbatim}
The following objects are masked from ‘package:Hmisc’:

    src, summarize
\end{verbatim}

This means that if you now use \texttt{summarize()}, it will be used from the \texttt{dplyr} package. As a consequence of this, \emph{package conflicts are resolved based on the order in which you load the packages}. This can be very confusing (and dangerous!). It is better to use the \texttt{::} operator, when you want to make sure to use a function from a certain package:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Use summarize from dplyr}
\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{summarize}\NormalTok{(...)}
\end{Highlighting}
\end{Shaded}

In fact, it can be considered very good practice to \emph{always} use the \texttt{::} (called a \emph{namespace directive}) to make it clear in your code where the function is used from. We refrain from using the operator very often in this book though, as it makes the code a bit messy and longer.

\hypertarget{loading-many-packages}{%
\subsection{Loading many packages}\label{loading-many-packages}}

If you are using packages in a script file, it is usually considered a good idea to load any packages you will be using at the \emph{start} of the script. Usually you will see a long list of \texttt{library(this)}, and \texttt{library(that)}, but we like to use the \texttt{pacman} package at the top of a script, like this:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(pacman))}\KeywordTok{install.packages}\NormalTok{(}\StringTok{"pacman"}\NormalTok{)}
\NormalTok{pacman}\OperatorTok{::}\KeywordTok{p_load}\NormalTok{(gplots, geometry, rgl, remotes, svglite)}
\end{Highlighting}
\end{Shaded}

The first line checks whether the \texttt{pacman} package is available (\texttt{require} is like \texttt{library}, except it returns \texttt{TRUE} if the package could be loaded), and if not (\texttt{!}), it is installed. Next, \texttt{p\_load} from \texttt{pacman} can be used to load many packages in one line, \emph{installing the ones that are not available}. This approach is a very concise way to make your script reproducible.

\hypertarget{helpfiles}{%
\section{Accessing the help files}\label{helpfiles}}

Every function that you use in R has its own built-in help file. For example, to access the help file for the arithmetic mean, type \texttt{?mean}.

This opens up the help file in your default browser (but does not require an internet connection). Functions added by loading new packages also have built-in help files. For example, to read about the function \texttt{bandplot} in the \texttt{gplots} package, type:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(gplots)}
\NormalTok{?bandplot}

\CommentTok{# Alternatively:}
\NormalTok{?gplots}\OperatorTok{::}\NormalTok{bandplot}
\end{Highlighting}
\end{Shaded}

Do not get overwhelmed when looking at the help files. Much of R's reputation for a steep learning curve has to do with the rather obscure and often confusing help files. A good tip for beginners is to \emph{not read the help files}, but skip straight to the Example section at the bottom of the help file. The first line of the help file, which shows what kind of input, or arguments, the function takes, can also be helpful.

The built-in help files offer detailed documentation of built-in functions (and those offered by packages), but often you are looking for something, but don't quite know what exactly. This frustrating experience is well described by this quote, to R-help in 2006:

\begin{quote}
``This is probably documented, but I cannot find the right words or\\
expression for a search. My attempts failed.''

--- Denis Chabot
\end{quote}

Sometimes it is useful to search all help files (including all \emph{installed} packages, loaded or not) for a keyword, for example \texttt{??ANOVA} will find everything that mentions ANOVAs.

The best advice, though, is simply to \textbf{just use Google}. As a search, simply type the question like you would ask someone else, for example ``How to place legend outside plot with ggplot2?'', ``(Is there an) R package for 3D plots?''.

\hypertarget{writing-lots-of-code-rmarkdown-or-scripts}{%
\section{Writing lots of code: rmarkdown or scripts?}\label{writing-lots-of-code-rmarkdown-or-scripts}}

In this chapter you have written a little code directly to the Console, but for any more serious work you will use scripts or ``rmarkdown'' documents. In Chapter \ref{reporting}, we will give more information on \texttt{rmarkdown} documents: an outstanding format to collect code, output, and text in a single, well formatted document. Scripts on the other hand only include code (and comments), and can be executed completely, or piece-by-piece by selecting code manually.

For both options, a brief summary is provided below. Overall, you want to use \textbf{scripts} if you:

\begin{itemize}
\tightlist
\item
  Want to be able to run all R code at once, producing some sort of output in files, or some other side-effect (perhaps figures as PDF, new datasets written to disk, objects produced and saved, data downloaded or uploaded, etc.).
\end{itemize}

On the other hand, you should use an \textbf{rmarkdown document} if you:

\begin{itemize}
\tightlist
\item
  Want to produce a document that includes all output from your analyses, including tables, figures, output from statistical analyses, and so on. The document can be well formatted and directly shared (hiding code, for example), and published on the web or simply emailed to your co-workers.
\end{itemize}

\hypertarget{reproducible-documents-with-rmarkdown}{%
\subsection{Reproducible documents with rmarkdown}\label{reproducible-documents-with-rmarkdown}}

\begin{itemize}
\tightlist
\item
  Documents are mix of normal text, with markup (headers, captions, images, tables, formatting), and blocks of code, \textbf{code chunks}.
\item
  The document can be quickly converted to html, pdf, or an MS Word document, and includes output from code chunks (text output, figures), well formatted.
\item
  Easy to learn syntax, and Rstudio provides many shortcuts and tools for working with \texttt{rmarkdown}.
\item
  Output formats include HTML, PDF (if LaTeX is installed) and MS Word.
\item
  Make not just simple documents, but also HTML presentations (in many formats), blogs (with \texttt{blogdown}), books (with \texttt{bookdown}), auto-generated websites documenting R packages (with \texttt{pkgdown}), and many more templates provided by add-on packages.
\end{itemize}

We give more information in Section \ref{rmarkdown}.

\hypertarget{scripts}{%
\subsection{Using R scripts}\label{scripts}}

Clearly, R markdown is the right solution if you are interested in writing fully reproducable reports or presentations. For everything else, we use R scripts - simply text files that include R code. A script is meant to be fully executable, so that you can run the entire script, producing the desired results, files, objects, or side-effects. In Rstudio, you can open a new R script with \texttt{File/New\ File/R\ script}, simply a text file that is saved with extension \texttt{.R}.

To run your script, you can either click `Source' on the topright corner of the document, or execute it from R with:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{source}\NormalTok{(}\StringTok{"myscript.R"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This is \emph{not useful} when you are interested in the output that you normally see in the console. If you are \emph{printing} things to the screen in your script, the call to \texttt{source} will not show any of it. You can make these results visible by including \texttt{print} directly in your script, for example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# The output of this will not show up if you }
\CommentTok{# do source("somescript.R")}
\KeywordTok{summary}\NormalTok{(mtcars)}

\CommentTok{# Here, the output will be printed to the screen,}
\CommentTok{# also with source()}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(cars))}
\end{Highlighting}
\end{Shaded}

Although the trick with \texttt{print} works, usually you want to switch to \texttt{rmarkdown} if you are interested in viewing the outputs. Scripts are more useful for side effects, for example the creation of new datasets (that are saved to disk), production of figures as PDF files, up- or downloading of files, or even converting an rmarkdown file to HTML with various settings.

\hypertarget{running-r-from-the-command-line}{%
\subsubsection{Running R from the command line}\label{running-r-from-the-command-line}}

From outside R or Rstudio, you can run your script from the \emph{command line} with \texttt{Rscript}, for example:

\begin{verbatim}
Rscript myscript.R
\end{verbatim}

(Note that this only works on Windows if R is added to the search path).

You can also run bits of R code directly via,

\begin{verbatim}
Rscript -e "sqrt(9)"
\end{verbatim}

\hypertarget{running-scripts-in-the-background}{%
\subsubsection{Running scripts in the background}\label{running-scripts-in-the-background}}

Suppose you have a script that takes a long time to complete. You want to run this script in a background process, so it does not tie up Rstudio for a long time. A nice feature in Rstudio (since late 2018) can be found on the Jobs tab, in the Console pane.

There, click `Start Job', and select an R script you would like to run, and the working directory that should be used. The script will be run in the background, and the results will be shown in the Jobs tab. This way you can run an R script for every core you have available to you.

\hypertarget{summarize}{%
\chapter{Data skills}\label{summarize}}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Analysing data is much more than applying the right statistics at the right time. A lot of effort and time is spent on reading, filtering, reshaping, bending and twisting your data before you can actually use the data for visualization and analysis.

In this chapter we learn many skills for working with data in R. All of these skills can be seen as mandatory skills before you learn new statistical techniques or fancy new visualizations. We first look at reading datasets into \emph{dataframes}, filtering data when certain conditions are met, and learn in detail about the most important data types that can be stored in dataframes.

We will also look at various ways to summarize data, from simple summaries of what is contained in the original data, to more complex tables of statistics by grouping variables. Finally we will look at merging (joining) dataframes by one or more key-variables, and reshaping datasets (from long to wide, and back).

\textbf{Packages used in this chapter}

The examples will generally let you know which packages are used, but for your convenience, here is a complete list of the packages used.

For plotting, we often use \texttt{ggplot2} and \texttt{ggthemes} (these are usually omitted from the examples):

Otherwise:

\begin{itemize}
\tightlist
\item
  \texttt{lgrdata} (for the example datasets, see \ref{exampledata})
\item
  \texttt{lubridate} (for dates and times)
\item
  \texttt{dplyr} (for various data skills)
\item
  \texttt{padr} (for aggregating timeseries data)
\item
  \texttt{doBy} (for \texttt{summaryBy}, handy for making summary tables)
\item
  \texttt{Hmisc} (for \texttt{contents} and \texttt{describe}, both summarize dataframes)
\item
  \texttt{tidyr} (for reshaping dataframes)
\item
  \texttt{reshape2} (for reshaping dataframes)
\item
  \texttt{data.table} (for \texttt{fread}, fast reading of dataframes)
\item
  \texttt{readxl} (for reading Excel files)
\item
  \texttt{stringr} (for working with text)
\end{itemize}

\hypertarget{generating-data}{%
\section{Generating data}\label{generating-data}}

\hypertarget{sequences}{%
\subsection{Sequences of numbers}\label{sequences}}

Let's look at a few ways to generate sequences of numbers that we can use in the examples and exercises. There are also a number of real-world situations where you want to use these functions.

First, as we saw already, we can use \texttt{c}() to `concatenate' (link together) a series of numbers. We can also combine existing vectors in this way, for example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{)}
\NormalTok{b <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{)}
\KeywordTok{c}\NormalTok{(a,b)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 3 4 5 6
\end{verbatim}

We can generate sequences of numbers using \texttt{:}, \texttt{seq} and \texttt{rep}, like so:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Sequences of integer numbers using the ":" operator:}
\DecValTok{1}\OperatorTok{:}\DecValTok{10}   \CommentTok{# Numbers 1 through 10}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{5}\OperatorTok{:-}\DecValTok{5}   \CommentTok{# From 5 to -5, backwards}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  5  4  3  2  1  0 -1 -2 -3 -4 -5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Examples using seq()}
\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from=}\DecValTok{10}\NormalTok{,}\DataTypeTok{to=}\DecValTok{100}\NormalTok{,}\DataTypeTok{by=}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  10  20  30  40  50  60  70  80  90 100
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from=}\DecValTok{23}\NormalTok{, }\DataTypeTok{by=}\DecValTok{2}\NormalTok{, }\DataTypeTok{length=}\DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 23 25 27 29 31 33 35 37 39 41 43 45
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Replicate numbers:}
\KeywordTok{rep}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DataTypeTok{times =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 2 2 2 2 2 2 2 2 2 2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{), }\DataTypeTok{each=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4 4 4 5 5 5
\end{verbatim}

The \texttt{rep} function works with any type of vector. For example, character vectors:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Simple replication}
\KeywordTok{rep}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\DataTypeTok{times =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "a" "a" "a"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Repeat elements of a vector}
\KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"E. tereticornis"}\NormalTok{,}\StringTok{"E. saligna"}\NormalTok{), }\DataTypeTok{each=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "E. tereticornis" "E. tereticornis" "E. tereticornis" "E. saligna"     
## [5] "E. saligna"      "E. saligna"
\end{verbatim}

\hypertarget{randomnumbers}{%
\subsection{Random numbers}\label{randomnumbers}}

We can draw random numbers using the \texttt{runif} function. The \texttt{runif} function draws from a uniform distribution, meaning there is an equal probability of any number being chosen.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Ten random numbers between 0 and 1}
\KeywordTok{runif}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 0.9155525 0.9808714 0.6954055 0.7959569 0.8144647 0.8374154 0.7861935
##  [8] 0.5242173 0.5390675 0.7666385
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Five random numbers between 100 and 1000}
\KeywordTok{runif}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{1000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 332.6357 648.0441 642.2567 985.0922 177.7964
\end{verbatim}

\BeginKnitrBlock{rmdtry}
The \texttt{runif} function is part of a much larger class of functions, each of which returns
numbers from a different probability distribution. Inspect the help pages of the functions \texttt{rnorm}
for the normal distribution, and \texttt{rexp} for the exponential distribution. Try generating some data from a normal distribution with a mean of 100, and a standard deviation of 10.
\EndKnitrBlock{rmdtry}

Next, we will \texttt{sample} numbers from an existing vector.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{numbers <-}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{15}
\KeywordTok{sample}\NormalTok{(numbers, }\DataTypeTok{size=}\DecValTok{20}\NormalTok{, }\DataTypeTok{replace=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  4 10 11  2 10  3 12  2 11 10  1  1  7  1 12  5  3 12 11  8
\end{verbatim}

This command samples 20 numbers from the \texttt{numbers} vector, with replacement.

\hypertarget{readingdata}{%
\section{Reading data}\label{readingdata}}

There are many ways to read data into R, but we are going to keep things simple and show only a couple of options to read data from text files, and from databases (hosted online).

Throughout this book we focus on `rectangular data', that is, data that can be organized in a table with columns and rows. A data table like this, with individual observations in rows, and various data fields in columns, is called a \emph{data frame}.

We first show a few options to read text files into dataframes in R, including comma, tab-delimited, and JSON formats, and how to read data from Excel. Reading data from remote (No)SQL databases is included in Chapter \ref{webservices}.

\hypertarget{readcsv}{%
\subsection{Reading CSV files}\label{readcsv}}

A very common text format for data is `Comma-Separated Values', or CSV. You can use \texttt{read.csv} to read these files. Suppose you have the file \texttt{Allometry.csv} in your working directory, you can read in the file into a dataframe with,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{allometry <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"Allometry.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Here, \texttt{read.csv} assumes that your system uses a point (`.') to separate digits, but in many parts of the world the default is a comma - in which case values are separated by `;'. In this case, use \texttt{read.csv2} instead of \texttt{read.csv}.

Make sure you fully understand the concept of a working directory (see Section \ref{fileswd}) before continuing.

If the file is stored elsewhere, you can specify the entire path (this is known as an \emph{absolute} path).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{allometry <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"c:/projects/data/Allometry.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

It is generally \emph{not recommended} to use absolute paths, because the script will then depend on an exact location of a datafile. But sometimes you want to refer to very large files or databases that are stored in a central location.

If the file is stored in a sub-directory of your working directory, you can specify the \emph{relative} path.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{allometry <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/Allometry.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The latter option is probably useful to keep your data files separate from your scripts and outputs in your working directory.

The function \texttt{read.csv} has many options, let's look at some of them. We can skip a number of rows from being read, and only read a fixed number of rows. For example, use this command to read rows 10-15, skipping the header line (which is in the first line of the file) and the next 9 lines. \emph{Note:} you have to skip 10 rows to read rows 10-15, because the header line (which is ignored) counts as a row in the text file!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{allomsmall <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"Allometry.csv"}\NormalTok{, }\DataTypeTok{skip=}\DecValTok{10}\NormalTok{, }\DataTypeTok{nrows=}\DecValTok{5}\NormalTok{, }\DataTypeTok{header=}\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{reading-large-csv-files}{%
\subsection{Reading large CSV files}\label{reading-large-csv-files}}

We used the built-in \texttt{read.csv} function above, but note that for large files, it is rather slow. The best alternative is to use \texttt{fread} from the \texttt{data.table} package. The \texttt{data.table} package is an excellent resource if you need to do data manipulations on large files (though the syntax takes some getting used to).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(data.table)}
\NormalTok{allom <-}\StringTok{ }\KeywordTok{fread}\NormalTok{(}\StringTok{"Allometry.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Of course, you could use \texttt{fread} even for small files, but I generally recommend to keep dependencies to a minimum. In other words, use built-in (`base') functions when you can, to develop more robust and reproducable code.

\hypertarget{tabdelimtext}{%
\subsection{Reading Tab-delimited text files}\label{tabdelimtext}}

Sometimes, data files are provided as text files that are TAB-delimited. To read these files, use the following command:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata <-}\StringTok{ }\KeywordTok{read.table}\NormalTok{(}\StringTok{"sometabdelimdata.txt"}\NormalTok{, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In fact, \texttt{read.table} is the more general function - \texttt{read.csv} is a specific case for comma-delimited files. When using \texttt{read.table}, you must specify whether a header (i.e., a row with column names) is present in the dataset (unlike \texttt{read.csv}, it is the default to not read the header). If you have a text file with some other delimiter, for example \texttt{;}, use the \texttt{sep} argument:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata <-}\StringTok{ }\KeywordTok{read.table}\NormalTok{(}\StringTok{"somedelimdata.txt"}\NormalTok{, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{sep=}\StringTok{";"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{including-data-in-a-script}{%
\subsection{Including data in a script}\label{including-data-in-a-script}}

You can also write the dataset in a text file, and read it as in the following examples. This is useful if you have (found) a small dataset that you typed in by hand, or for making reproducible code snippets that include the dataset.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{read.table}\NormalTok{(}\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{text=}\StringTok{"}
\StringTok{a b}
\StringTok{1 2}
\StringTok{3 4}
\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   a b
## 1 1 2
## 2 3 4
\end{verbatim}

\hypertarget{json}{%
\subsection{JSON}\label{json}}

A very popular format for data, especially on the web, is JSON - a text-based format that can represent not just rectangular data (dataframes), but any complex nested data structure.

We can use the \texttt{jsonlite} package to read JSON data, and convert it to a dataframe if the data allows it, as in the following example.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Fake data can be read fro this site.}
\CommentTok{# Visit the link to see what the original data looks like.}
\NormalTok{url <-}\StringTok{ "https://jsonplaceholder.typicode.com/posts/1/comments"}

\CommentTok{# Package to read JSON; it is very fast.}
\KeywordTok{library}\NormalTok{(jsonlite)}

\CommentTok{# fromJSON reads and simplifies the data into a dataframe (if possible)}
\NormalTok{comment_data <-}\StringTok{ }\KeywordTok{fromJSON}\NormalTok{(url)}

\CommentTok{# We end up with a dataframe.}
\NormalTok{Hmisc}\OperatorTok{::}\KeywordTok{contents}\NormalTok{(comment_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Data frame:comment_data  500 observations and 5 variables    Maximum # NAs:0
## 
## 
##          Storage
## postId   integer
## id       integer
## name   character
## email  character
## body   character
\end{verbatim}

\hypertarget{nosql-databases}{%
\subsection{(No)SQL databases}\label{nosql-databases}}

We show examples of how to obtain data from SQL and NoSQL databases in Chapter \ref{webservices}.

\hypertarget{excel-spreadsheets}{%
\subsection{Excel spreadsheets}\label{excel-spreadsheets}}

Excel spreadsheets are \emph{not} a recommended way to store data, but often you don't make that choice yourself. If you do need to read an XLS or XLSX file, the \texttt{readxl} package works very well. \emph{Note}: avoid older implementations like the \texttt{xlsx} package and \texttt{read.xls} in the \texttt{gtools} package, which are less reliable.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(readxl)}
\NormalTok{mydata <-}\StringTok{ }\KeywordTok{read_excel}\NormalTok{(}\StringTok{"mspreadsheet.xlsx"}\NormalTok{, }\DataTypeTok{sheet =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Here, \texttt{sheet} will specify the sheet by number, alternatively you can refer to the sheet by name (e.g., \texttt{sheet\ =\ \textquotesingle{}rawdata\textquotesingle{}}).

\hypertarget{proprietary-formats}{%
\subsection{Proprietary formats}\label{proprietary-formats}}

Many statistical software packages store data in their own format, not just text files. For data from \textbf{SPSS}, \textbf{SAS} or \textbf{Stata}, we recommend the \texttt{haven} package for reading the data into dataframes, and the \texttt{foreign} package provides further support for Minitab, \textbf{Systat}, and \textbf{Weka.}

\hypertarget{web-services}{%
\subsection{Web services}\label{web-services}}

Nowadays many data are available via a `RESTful' API, which is now by far the most common way to download publicly available (open) data (and many other services as well). We discuss reading data from a REST service, as well as setting up our REST service in Chapter \ref{webservices}.

\hypertarget{dataframes}{%
\section{Working with dataframes}\label{dataframes}}

As mentioned, this book focuses heavily on dataframes, because this is the object you will use most of the time in data analysis. The following sections provide a brief introduction, but we will see many examples using dataframes throughout this manual.

Like matrices, dataframes have two dimensions: they contain both columns and rows. Unlike matrices, each column can hold a different type of data. This is very useful for keeping track of different types of information about data points. For example, you might use one column to hold height measurements, and another to hold the matching species IDs. When you read in a file using \texttt{read.csv}, the data is automatically stored in a dataframe. Dataframes can also be created from scratch using the function \texttt{data.frame} (see Section \ref{vecstodfr}), but usually we start with data read from a file.

\BeginKnitrBlock{rmdinfo}
\textbf{What is a tibble?}
Sometimes you will notice that some functions return objects that are very similar to
dataframes, but are actually called `tibbles' (for example, \texttt{read\_excel} returns one). A tibble is a newer format for dataframes, and is internally very nearly the same. You can pretty much always assume that dataframes and tibbles behave in the same way.
\EndKnitrBlock{rmdinfo}

\hypertarget{vecstodfr}{%
\subsection{Convert vectors into a dataframe}\label{vecstodfr}}

Suppose you have two or more vectors (of the same length), and you want to include these in a new dataframe. You can use the function \texttt{data.frame}. Here is a simple example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vec1 <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{9}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{45}\NormalTok{)}
\NormalTok{vec2 <-}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{5}

\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ vec1, }\DataTypeTok{y =}\NormalTok{ vec2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    x y
## 1  9 1
## 2 10 2
## 3  1 3
## 4  2 4
## 5 45 5
\end{verbatim}

Here, we made a dataframe with columns named \texttt{x} and \texttt{y}. \emph{Note}: take care to ensure that the vectors have the same length, otherwise it won't work!

\BeginKnitrBlock{rmdtry}
Modify the previous example so that the two vectors are \emph{not} the same length. Then, attempt to combine them in a dataframe and inspect the resulting error message.
\EndKnitrBlock{rmdtry}

\hypertarget{variables-in-the-dataframe}{%
\subsection{Variables in the dataframe}\label{variables-in-the-dataframe}}

We read the \texttt{allometry} data (make sure the \texttt{lgrdata} package is loaded) to practice basic dataframe skills.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lgrdata)}
\KeywordTok{data}\NormalTok{(allometry)}
\end{Highlighting}
\end{Shaded}

After reading the dataframe, it is good practice to always quickly inspect the dataframe to see if anything went wrong. I routinely look at the first few rows with \texttt{head}. Then, to check the types of variables in the dataframe, use the \texttt{str} function (short for `structure'). This function is useful for other objects as well, to view in detail what the object contains.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(allometry)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   species diameter height   leafarea branchmass
## 1    PSME    54.61  27.04 338.485622  410.24638
## 2    PSME    34.80  27.42 122.157864   83.65030
## 3    PSME    24.89  21.23   3.958274    3.51270
## 4    PSME    28.70  24.96  86.350653   73.13027
## 5    PSME    34.80  29.99  63.350906   62.39044
## 6    PSME    37.85  28.07  61.372765   53.86594
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{str}\NormalTok{(allometry)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    63 obs. of  5 variables:
##  $ species   : Factor w/ 3 levels "PIMO","PIPO",..: 3 3 3 3 3 3 3 3 3 3 ...
##  $ diameter  : num  54.6 34.8 24.9 28.7 34.8 ...
##  $ height    : num  27 27.4 21.2 25 30 ...
##  $ leafarea  : num  338.49 122.16 3.96 86.35 63.35 ...
##  $ branchmass: num  410.25 83.65 3.51 73.13 62.39 ...
\end{verbatim}

Individual variables in a dataframe can be extracted using the dollar \texttt{\$} sign.
Let's print all the tree diameters here, after rounding to one decimal point:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(allometry}\OperatorTok{$}\NormalTok{diameter,}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 54.6 34.8 24.9 28.7 34.8 37.9 22.6 39.4 39.9 26.2 43.7 69.8 44.5 56.6
## [15] 54.6  5.3  6.1  7.4  8.3 13.5 51.3 22.4 69.6 58.4 33.3 44.2 30.5 27.4
## [29] 43.2 38.9 52.6 20.8 24.1 24.9 46.0 35.0 23.9 60.2 12.4  4.8 70.6 11.4
## [43] 11.9 60.2 60.7 70.6 57.7 43.1 18.3 43.4 18.5 12.9 37.9 26.9 38.6  6.5
## [57] 31.8 73.7 28.2 61.5 51.6 18.3  8.4
\end{verbatim}

It is also straightforward to add new variables to a dataframe. Let's convert the tree diameter to inches, and add it to the dataframe as a new variable:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{allometry}\OperatorTok{$}\NormalTok{diameterInch <-}\StringTok{ }\NormalTok{allometry}\OperatorTok{$}\NormalTok{diameter }\OperatorTok{/}\StringTok{ }\FloatTok{2.54}
\end{Highlighting}
\end{Shaded}

Instead of using the \texttt{\$}-notation every time (which can result in lengthy, messy code, especially when your variable names are long) you can use \texttt{with} to indicate where the variables are stored. Let's add a new variable called \texttt{volindex}, a volume index defined as the square of tree diameter times height:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{allometry}\OperatorTok{$}\NormalTok{volindex <-}\StringTok{ }\KeywordTok{with}\NormalTok{(allometry, diameter}\OperatorTok{^}\DecValTok{2} \OperatorTok{*}\StringTok{ }\NormalTok{height)}
\end{Highlighting}
\end{Shaded}

The \texttt{with} function allows for more readable code, while at the same time making sure that the variables \texttt{diameter} and \texttt{height} are read from the dataframe \texttt{allometry}.

An even better approach is to use \texttt{mutate} from the \texttt{dplyr} package (similar to base R's \texttt{transform}, but with a useful advantage).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr)}
\NormalTok{allometry <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(allometry, }
                \DataTypeTok{diameterInch =}\NormalTok{ diameter }\OperatorTok{/}\StringTok{ }\FloatTok{2.54}\NormalTok{,}
                \DataTypeTok{volindex =}\NormalTok{ diameterInch}\OperatorTok{^}\DecValTok{2} \OperatorTok{*}\StringTok{ }\NormalTok{height)}
\end{Highlighting}
\end{Shaded}

Where \texttt{mutate} adds new variables to the dataframe, and (unlike \texttt{transform}) it is able to use variables used just before in the same call (note \texttt{diameterInch} was created in the same call).

\BeginKnitrBlock{rmdtry}
The above examples are important - many times throughout this book you will be required to perform similar operations. As an exercise, also add the ratio of height to diameter to the dataframe.
\EndKnitrBlock{rmdtry}

A simple summary of the dataframe can be printed with the \texttt{summary} function; where we use indexing (\texttt{{[},1:3{]}}) to use the first three columns of \texttt{allometry} only to save space.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(allometry[,}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  species      diameter         height     
##  PIMO:19   Min.   : 4.83   Min.   : 3.57  
##  PIPO:22   1st Qu.:21.59   1st Qu.:21.26  
##  PSME:22   Median :34.80   Median :28.40  
##            Mean   :35.56   Mean   :26.01  
##            3rd Qu.:51.44   3rd Qu.:33.93  
##            Max.   :73.66   Max.   :44.99
\end{verbatim}

For the numeric variables, the minimum, 1st quantile, median, mean, 3rd quantile, and maximum values are printed. For so-called `factor' variables (i.e., categorical variables), a simple table is printed (in this case, for the \texttt{species} variable). We will come back to factors in Section sec:workingfactors. If the variables have missing values, the number of missing values is printed as well (see Section \ref{workingmissing}).

To see how many rows and columns your dataframe contains (handy for double-checking you read the data correctly), use \texttt{nrow} and \texttt{ncol}. Alternatively, \texttt{dim} gives the `dimension' of the dataframe (rows x columns).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{nrow}\NormalTok{(allometry)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 63
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ncol}\NormalTok{(allometry)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7
\end{verbatim}

\hypertarget{namesdataframe}{%
\subsection{Changing column names in dataframes}\label{namesdataframe}}

To access the names of a dataframe as a vector, use the \texttt{names} function. You can also use this to change the names. Consider this example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# read names:}
\KeywordTok{names}\NormalTok{(allometry)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "species"      "diameter"     "height"       "leafarea"    
## [5] "branchmass"   "diameterInch" "volindex"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# rename all (make sure vector is same length as number of columns!)}
\KeywordTok{names}\NormalTok{(allometry) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"spec"}\NormalTok{,}\StringTok{"diam"}\NormalTok{,}\StringTok{"ht"}\NormalTok{,}\StringTok{"leafarea"}\NormalTok{,}\StringTok{"branchm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We can also change some of the names, using simple indexing (see Section \ref{vectorindexing}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# rename Second one to 'Diam'}
\KeywordTok{names}\NormalTok{(allometry)[}\DecValTok{2}\NormalTok{] <-}\StringTok{ "Diam"}

\CommentTok{# rename 1st and 2nd:}
\KeywordTok{names}\NormalTok{(allometry)[}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{] <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"SP"}\NormalTok{,}\StringTok{"D"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Better yet is to use \texttt{rename} from the \texttt{dplyr} package, which makes sure you change the right column names (indexing as above can be dangerous if the order of columns has changed!).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr)}

\CommentTok{# The names on the right are the original names, on the left are the new ones.}
\NormalTok{allometry <-}\StringTok{ }\KeywordTok{rename}\NormalTok{(allometry, }
                       \DataTypeTok{spec =}\NormalTok{ species,}
                       \DataTypeTok{diam =}\NormalTok{ diameter)}
\end{Highlighting}
\end{Shaded}

\hypertarget{extracting-data}{%
\section{Extracting data}\label{extracting-data}}

\hypertarget{vectorindexing}{%
\subsection{Vectors}\label{vectorindexing}}

Let's look at reordering or taking subsets of a vector, or \texttt{indexing} as it is commonly called. This is an important skill to learn, so we will look at several examples.

Let's define two \texttt{numeric\ vectors}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nums1 <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{11}\NormalTok{,}\DecValTok{100}\NormalTok{,}\DecValTok{8}\NormalTok{)}
\NormalTok{nums2 <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{3.3}\NormalTok{,}\FloatTok{8.1}\NormalTok{,}\FloatTok{2.5}\NormalTok{,}\FloatTok{9.8}\NormalTok{,}\FloatTok{21.2}\NormalTok{,}\FloatTok{13.8}\NormalTok{,}\FloatTok{0.9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Individual elements of a vector can be extracted using square brackets, \texttt{{[}\ {]}}. For example, to extract the first and then the fifth element of a vector:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nums1[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nums1[}\DecValTok{5}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 11
\end{verbatim}

You can also use another object to do the indexing, as long as it contains a integer number. For example,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Get last element:}
\NormalTok{nelements <-}\StringTok{ }\KeywordTok{length}\NormalTok{(nums1)}
\NormalTok{nums1[nelements]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8
\end{verbatim}

This last example extracts the last element of a vector. To do this, we first found the length of the vector, and used that to \emph{index} the vector to extract the last element.

We can also select multiple elements, by \emph{indexing} the vector with another vector. Recall how to construct sequences of numbers, explained in Section \ref{sequences}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Select the first 3:}
\NormalTok{nums1[}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 4 2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Select a few elements of a vector:}
\NormalTok{selectthese <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\NormalTok{nums1[selectthese]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1 11  4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Select every other element:}
\NormalTok{everyother <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DataTypeTok{by=}\DecValTok{2}\NormalTok{)}
\NormalTok{nums1[everyother]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1  2 11  8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Select five random elements:}
\NormalTok{ranels <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(nums2), }\DecValTok{5}\NormalTok{)}
\NormalTok{nums2[ranels]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  8.1 21.2  2.5 13.8  9.8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Remove the first element:}
\NormalTok{nums1[}\OperatorTok{-}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]   4   2   8  11 100   8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Remove the first and last element:}
\NormalTok{nums1[}\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\KeywordTok{length}\NormalTok{(nums1))]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]   4   2   8  11 100
\end{verbatim}

Next, we can look at selecting elements of a vector based on the values in that vector. Suppose we want to make a new vector, based on vector \texttt{nums2} but only where the value within certain bounds. We can use simple logical statements to index a vector.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Subset of nums2, where value is at least 10 :}
\NormalTok{nums2[nums2 }\OperatorTok{>}\StringTok{ }\DecValTok{10}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 21.2 13.8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Subset of nums2, where value is between 5 and 10:}
\NormalTok{nums2[nums2 }\OperatorTok{>}\StringTok{ }\DecValTok{5} \OperatorTok{&}\StringTok{ }\NormalTok{nums2 }\OperatorTok{<}\StringTok{ }\DecValTok{10}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8.1 9.8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Subset of nums2, where value is smaller than 1, or larger than 20:}
\NormalTok{nums2[nums2 }\OperatorTok{<}\StringTok{ }\DecValTok{1} \OperatorTok{|}\StringTok{ }\NormalTok{nums2 }\OperatorTok{>}\StringTok{ }\DecValTok{20}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 21.2  0.9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Subset of nums1, where value is exactly 8:}
\NormalTok{nums1[nums1 }\OperatorTok{==}\StringTok{ }\DecValTok{8}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8 8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Subset nums1 where number is NOT equal to 100}
\NormalTok{nums1[nums1 }\OperatorTok{!=}\StringTok{ }\DecValTok{100}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1  4  2  8 11  8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Subset of nums1, where value is one of 1,4 or 11:}
\NormalTok{nums1[nums1 }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{11}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1  4 11
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Subset of nums1, where value is NOT 1,4 or 11:}
\NormalTok{nums1[}\OperatorTok{!}\NormalTok{(nums1 }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{11}\NormalTok{))]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]   2   8 100   8
\end{verbatim}

These examples showed you several new logical operators (\textless{}, \textgreater{}, ==, \&). See the help page \texttt{?Logic} for more details on logical operators. We will return to logical data in Section sec:workinglogic.

\hypertarget{assigning-new-values-to-subsets}{%
\subsubsection{Assigning new values to subsets}\label{assigning-new-values-to-subsets}}

All of this becomes very useful if we realize that new values can be easily assigned to subsets. This works for any of the examples above. For instance,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Where nums1 was 100, make it -100}
\NormalTok{nums1[nums1 }\OperatorTok{==}\StringTok{ }\DecValTok{100}\NormalTok{] <-}\StringTok{ }\DecValTok{-100}

\CommentTok{# Where nums2 was less than 5, make it zero}
\NormalTok{nums2[nums2 }\OperatorTok{<}\StringTok{ }\DecValTok{5}\NormalTok{] <-}\StringTok{ }\DecValTok{0}
\end{Highlighting}
\end{Shaded}

\BeginKnitrBlock{rmdtry}
Using the first set of examples in this section, practice assigning new values to subsets of vectors.
\EndKnitrBlock{rmdtry}

\hypertarget{subsetdataframes}{%
\subsection{Dataframes}\label{subsetdataframes}}

In base R, there are two ways to take a subset of a dataframe: using the square bracket notation (\texttt{{[}{]}}) as in the above examples, or using the \texttt{filter} function from the \texttt{dplyr} package. We will learn both, as they are both useful from time to time.

Similar to vectors, dataframes can be indexed with row and column numbers using \texttt{mydataframe{[}row,column{]}}.

Here, \texttt{row} refers to the row number (which can be a vector of any length), and \texttt{column} to the column number (which can also be a vector). You can also refer to the column by its \emph{name} rather than its number, which can be very useful. All this will become clearer after some examples.

Let's look at a few examples using the Allometry dataset.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Load data}
\KeywordTok{data}\NormalTok{(allometry)}

\CommentTok{# Extract tree diameters: take the 4th observation of the 2nd variable:}
\NormalTok{allometry[}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 28.7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# We can also index the dataframe by its variable name:}
\NormalTok{allometry[}\DecValTok{4}\NormalTok{,}\StringTok{"diameter"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 28.7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extract the first 3 rows of 'height':}
\NormalTok{allometry[}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{, }\StringTok{"height"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 27.04 27.42 21.23
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extract the first 5 rows, of ALL variables}
\CommentTok{# Note the use of the comma followed by nothing}
\CommentTok{# This means 'every column' and is very useful!}
\NormalTok{allometry[}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   species diameter height   leafarea branchmass
## 1    PSME    54.61  27.04 338.485622  410.24638
## 2    PSME    34.80  27.42 122.157864   83.65030
## 3    PSME    24.89  21.23   3.958274    3.51270
## 4    PSME    28.70  24.96  86.350653   73.13027
## 5    PSME    34.80  29.99  63.350906   62.39044
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extract the fourth column}
\CommentTok{# Here we use nothing, followed by a comma,}
\CommentTok{# to indicate 'every row'}
\NormalTok{allometry[,}\DecValTok{4}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 338.485622 122.157864   3.958274  86.350653  63.350906  61.372765
##  [7]  32.077794 147.270523 141.787332  45.020041 145.809802 349.057010
## [13] 176.029213 319.507115 234.368784   4.851567   7.595163  11.502851
## [19]  25.380647  65.698749 160.839174  31.780702 189.733007 253.308265
## [25]  91.538428  90.453658  99.736790  34.464685  68.150309  46.326060
## [31] 160.993131   9.806496  20.743280  21.649603  66.633675  54.267994
## [37]  19.844680 131.727303  22.365837   2.636336 411.160376  15.476022
## [43]  14.493428 169.053644 139.651156 376.308256 417.209436 103.672633
## [49]  33.713580 116.154916  44.934469  18.855867 154.078625  70.602797
## [55] 169.163842   7.650902  93.072006 277.494360 131.856837 121.428976
## [61] 212.443589  82.093031   6.551044
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Select only 'height' and 'diameter', store in new dataframe:}
\NormalTok{allomhd <-}\StringTok{ }\NormalTok{allometry[,}\KeywordTok{c}\NormalTok{(}\StringTok{"height"}\NormalTok{, }\StringTok{"diameter"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

As we saw when working with vectors (see Section \ref{vectorindexing}), we can use expressions to extract data. Because each column in a dataframe is a vector, we can apply the same techniques to dataframes, as in the following examples.

We can also use one vector in a dataframe to find subsets of another. For example, what if we want to find the value of one vector, if another vector has a particular value?

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extract diameters larger than 60}
\NormalTok{allometry}\OperatorTok{$}\NormalTok{diameter[allometry}\OperatorTok{$}\NormalTok{diameter }\OperatorTok{>}\StringTok{ }\DecValTok{60}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 69.85 69.60 60.20 70.61 60.20 60.71 70.61 73.66 61.47
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extract all rows of allom where diameter is larger than 60.}
\CommentTok{# Make sure you understand the difference with the above example!}
\NormalTok{allometry[allometry}\OperatorTok{$}\NormalTok{diameter }\OperatorTok{>}\StringTok{ }\DecValTok{60}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    species diameter height leafarea branchmass
## 12    PSME    69.85  31.35 349.0570   543.9731
## 23    PIPO    69.60  39.37 189.7330   452.4246
## 38    PIPO    60.20  31.73 131.7273   408.3383
## 41    PIPO    70.61  31.93 411.1604  1182.4222
## 44    PIPO    60.20  35.14 169.0536   658.2397
## 45    PIMO    60.71  39.84 139.6512   139.2559
## 46    PIMO    70.61  40.66 376.3083   541.3062
## 58    PIMO    73.66  44.64 277.4944   275.7165
## 60    PIMO    61.47  44.99 121.4290   199.8634
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# We can use one vector to index another. For example, find the height of the tree}
\CommentTok{# that has the largest diameter, we can do:}
\NormalTok{allometry}\OperatorTok{$}\NormalTok{height[}\KeywordTok{which.max}\NormalTok{(allometry}\OperatorTok{$}\NormalTok{diameter)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 44.64
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Recalling the previous section, this is identical to:}
\NormalTok{allometry[}\KeywordTok{which.max}\NormalTok{(allometry}\OperatorTok{$}\NormalTok{diameter), }\StringTok{"height"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 44.64
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Get 10 random observations of 'leafarea'. Here, we make a new vector }
\CommentTok{# on the fly with sample(), which we use to index the dataframe.}
\NormalTok{allometry[}\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(allometry),}\DecValTok{10}\NormalTok{),}\StringTok{"leafarea"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 376.308256 169.163842  33.713580  54.267994 253.308265   6.551044
##  [7] 349.057010  15.476022 234.368784  91.538428
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# As we did with vectors, we can also use %in% to select a subset.}
\CommentTok{# This example selects only two species in the dataframe.}
\NormalTok{allometry[allometry}\OperatorTok{$}\NormalTok{species }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"PIMO"}\NormalTok{,}\StringTok{"PIPO"}\NormalTok{),]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    species diameter    height   leafarea branchmass
## 23    PIPO    69.60 39.369999 189.733007  452.42455
## 24    PIPO    58.42 35.810000 253.308265  595.64015
## 25    PIPO    33.27 20.800001  91.538428  160.44416
## 26    PIPO    44.20 29.110001  90.453658  149.72883
## 27    PIPO    30.48 22.399999  99.736790   44.13532
## 28    PIPO    27.43 27.690001  34.464685   22.98360
## 29    PIPO    43.18 35.580000  68.150309  106.40410
## 30    PIPO    38.86 33.120001  46.326060   58.24071
## 31    PIPO    52.58 41.160003 160.993131  214.34109
## 32    PIPO    20.83 23.340000   9.806496    8.25614
## 33    PIPO    24.13 25.940001  20.743280   22.60111
## 34    PIPO    24.89 25.110000  21.649603   16.77015
## 35    PIPO    45.97 30.389999  66.633675   87.36908
## 36    PIPO    35.05 28.399999  54.267994   51.09006
## 37    PIPO    23.88 23.380001  19.844680   13.98343
## 38    PIPO    60.20 31.729999 131.727303  408.33826
## 39    PIPO    12.45  7.360001  22.365837   16.98648
## 40    PIPO     4.83  3.570000   2.636336    1.77810
## 41    PIPO    70.61 31.929997 411.160376 1182.42222
## 42    PIPO    11.43  6.920000  15.476022    9.25151
## 43    PIPO    11.94  5.849999  14.493428    7.55701
## 44    PIPO    60.20 35.139998 169.053644  658.23971
## 45    PIMO    60.71 39.840003 139.651156  139.25590
## 46    PIMO    70.61 40.659999 376.308256  541.30618
## 47    PIMO    57.66 38.889998 417.209436  310.56688
## 48    PIMO    43.13 36.240000 103.672633  100.40178
## 49    PIMO    18.29 23.130000  33.713580   14.48567
## 50    PIMO    43.43 37.589998 116.154916  108.44781
## 51    PIMO    18.54 21.289999  44.934469   16.54457
## 52    PIMO    12.95 13.440000  18.855867    8.71068
## 53    PIMO    37.85 36.590000 154.078625   72.02907
## 54    PIMO    26.92 29.049999  70.602797   35.87333
## 55    PIMO    38.61 35.519999 169.163842  114.06445
## 56    PIMO     6.48  5.420000   7.650902    3.50621
## 57    PIMO    31.75 34.559999  93.072006   44.72725
## 58    PIMO    73.66 44.640000 277.494360  275.71655
## 59    PIMO    28.19 22.590000 131.856837   91.76231
## 60    PIMO    61.47 44.989998 121.428976  199.86339
## 61    PIMO    51.56 40.229999 212.443589  220.55688
## 62    PIMO    18.29 12.980000  82.093031   28.04785
## 63    PIMO     8.38  4.950000   6.551044    4.36969
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extract tree diameters for the PIMO species, as long as diameter > 50}
\NormalTok{allometry}\OperatorTok{$}\NormalTok{diameter[allometry}\OperatorTok{$}\NormalTok{species }\OperatorTok{==}\StringTok{ "PIMO"} \OperatorTok{&}\StringTok{ }\NormalTok{allometry}\OperatorTok{$}\NormalTok{diameter }\OperatorTok{>}\StringTok{ }\DecValTok{50}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 60.71 70.61 57.66 73.66 61.47 51.56
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# (not all output shown)}
\end{Highlighting}
\end{Shaded}

\BeginKnitrBlock{rmdtry}
As with vectors, we can quickly assign new values to subsets of data using the \texttt{\textless{}-} operator. Try this on some of the examples above.
\EndKnitrBlock{rmdtry}

\hypertarget{a-faster-method}{%
\subsection{A faster method}\label{a-faster-method}}

While the above method to index dataframes is very flexible and concise, sometimes it leads to code that is difficult to understand. It is also easy to make mistakes when you subset dataframes by the column or row number (imagine the situation where the dataset has changed and you redo the analysis). Consider the \texttt{filter} function as a convenient and safe alternative, from the \texttt{dplyr} package. (Note that base R provides a nearly identical function, \texttt{subset}, but \texttt{filter} is much faster).

With \texttt{filter}, you can select rows that meet a certain criterion, and columns as well. This example uses the pupae data. The last example shows the use of \texttt{select} from \texttt{dplyr} to keep only certain columns, conveniently with the pipe operator.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Read data}
\KeywordTok{data}\NormalTok{(pupae)}

\CommentTok{# For filter(), select().}
\KeywordTok{library}\NormalTok{(dplyr)}

\CommentTok{# Take subset of pupae, ambient temperature treatment and CO2 is 280.}
\CommentTok{# Note: statements separated by commas are interpreted as AND by filter()}
\KeywordTok{filter}\NormalTok{(pupae, }
\NormalTok{       T_treatment }\OperatorTok{==}\StringTok{ "ambient"}\NormalTok{,}
\NormalTok{       CO2_treatment }\OperatorTok{==}\StringTok{ }\DecValTok{280}\NormalTok{,}
\NormalTok{       Gender }\OperatorTok{==}\StringTok{ }\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   T_treatment CO2_treatment Gender PupalWeight Frass
## 1     ambient           280      0       0.244 1.900
## 2     ambient           280      0       0.221    NA
## 3     ambient           280      0       0.280 1.996
## 4     ambient           280      0       0.257 1.069
## 5     ambient           280      0       0.275 2.198
## 6     ambient           280      0       0.254 2.220
## 7     ambient           280      0       0.258 1.877
## 8     ambient           280      0       0.224 1.488
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# (not all output shown)}

\CommentTok{# Take subset where Frass is larger than 2.9. }
\CommentTok{# Also, keep only variables 'PupalWeight' and 'Frass'.}
\KeywordTok{filter}\NormalTok{(pupae, Frass }\OperatorTok{>}\StringTok{ }\FloatTok{2.6}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(PupalWeight, Frass)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   PupalWeight Frass
## 1       0.319 2.770
## 2       0.384 2.672
## 3       0.385 2.603
## 4       0.405 3.117
## 5       0.473 2.631
## 6       0.469 2.747
\end{verbatim}

\hypertarget{deleting-columns}{%
\subsection{Deleting columns}\label{deleting-columns}}

It is rarely necessary to delete columns from a dataframe, unless you want to save a copy of the dataframe to disk (see Section \ref{exportingdata}). Instead of deleting columns, you can take a subset and make a new dataframe to continue with. Also, it should not be necessary to delete columns from the dataframe that you have accidentally created in a reproducible script: when things go wrong, simply clear the workspace and run the entire script again.

That aside, you have the following options to delete a column from a dataframe.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# A simple example dataframe}
\NormalTok{dfr <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{a=}\OperatorTok{-}\DecValTok{5}\OperatorTok{:}\DecValTok{0}\NormalTok{, }\DataTypeTok{b=}\DecValTok{10}\OperatorTok{:}\DecValTok{15}\NormalTok{)}

\CommentTok{# Delete the second column (make a new dataframe 'dfr2' that does not include that column)}
\CommentTok{# This only works if you know the column index (here, 2) for sure,}
\CommentTok{# it does not work with a column name!}
\NormalTok{dfr2 <-}\StringTok{ }\NormalTok{dfr[,}\OperatorTok{-}\DecValTok{2}\NormalTok{]}

\CommentTok{# Using select() from the dplyr, we can drop columns by name:}
\NormalTok{dfr2 <-}\StringTok{ }\KeywordTok{select}\NormalTok{(dfr, }\OperatorTok{-}\NormalTok{a)}
\end{Highlighting}
\end{Shaded}

\hypertarget{exportingdata}{%
\section{Exporting data}\label{exportingdata}}

To write a dataframe to a comma-separated values (CSV) file, use the \texttt{write.csv} function. For example,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Some data}
\NormalTok{dfr <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x=}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{, }\DataTypeTok{y=}\DecValTok{2}\OperatorTok{:}\DecValTok{4}\NormalTok{)}

\CommentTok{# Write to disk (row names are generally not wanted in the CSV file).}
\KeywordTok{write.csv}\NormalTok{(dfr,}\StringTok{"somedata.csv"}\NormalTok{, }\DataTypeTok{row.names=}\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

If you want more options, or a different delimiter (such as TAB), look at the \texttt{write.table} function. Note that if you write a dataset to a text file, and read it back in with \texttt{read.csv} (or \texttt{read.table}), the dataset will not be exactly the same. One reason is the number of digits used in the text file, or that you have converted some columns to character, numeric, or whatever.

If you want to store a dataframe to disk, and later read it back into R exactly as it was before, it is preferred to use a \textbf{binary format}. This idea works for any R object, not just dataframes:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Much faster than writing text files, resulting files are much smaller,}
\CommentTok{# and objects are saved exactly as they were in R.}
\KeywordTok{saveRDS}\NormalTok{(dfr, }\StringTok{"somefile.rds"}\NormalTok{)}

\CommentTok{# To read the object back in, do:}
\NormalTok{dfr <-}\StringTok{ }\KeywordTok{readRDS}\NormalTok{(}\StringTok{"somefile.rds"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

It is also possible to save all objects that are currently loaded in memory (everything that shows up with \texttt{ls()}) with the command \texttt{save.image}. However, we strongly urge against it, as it is easy to lose track of which objects are important, and it is too easy to make a mess of things. A fresh installation of Rstudio saves all your objects after you quit Rstudio, but as we mentioned in Section \ref{installingr}, we suggest you switch that behaviour off.

\hypertarget{special-data-types}{%
\section{Special data types}\label{special-data-types}}

Now that we know how to read in dataframes, it is time we take a closer look at the types of data that can be contained in a dataframe. For the purpose of this book, a dataframe can contain six types of data. These are summarized in the table below:

\begin{tabular}{l|l|l|l}
\hline
Data type & Description & Example & Section\\
\hline
*numeric* & Any number, including `double` (double precision floating point) and `integer` (whole numbers). In R you very rarely have to worry about the exact nature of numeric values. & `c(1, 12.3491, 10/2, 10\textasciicircum{}6, pi)` & \\
\hline
*character* & Strings of text & `c('apple', 'pear', letters[1:3])` & \textbackslash{}@ref(workingtext)\\
\hline
*factor* & Categorial variable. Preferred over character when few unique levels (values) present in the data. Must use in statistical models, plotting. Internally stored as an integer corresponding to the *level* of the factor variable. & `factor(c('Control','Fertilized','Irrigated'))` & \textbackslash{}@ref(workingfactors)\\
\hline
*logical* & Either TRUE or FALSE. Internally stored as 0 (FALSE) or 1 (TRUE). & `10 == 100/10` & \textbackslash{}@ref(workinglogic)\\
\hline
*Date* & Special Date class. Internally stored as number of days since 1970-1-1. & `as.Date(Sys.time())` & \textbackslash{}@ref(readingdates)\\
\hline
*POSIXct* & Special Date-time class. Internally stored as number of seconds since 1970-1-1, and may have timezone attributes. & `lubridate::ymd\_hms('1883-08-26 14:00')` & \textbackslash{}@ref(datetime)\\
\hline
\end{tabular}

Also, R has a very useful built-in data type to represent \textbf{missing values}. This is represented by \texttt{NA} (Not Available) (see Section \ref{workingmissing}).

We will show how to convert between data types at the end of this chapter (Section \ref{converttype}).

\hypertarget{workingfactors}{%
\subsection{Working with factors}\label{workingfactors}}

The \emph{factor} data type is used to represent qualitative, categorical data.

When reading data from file, for example with \texttt{read.csv}, R will automatically convert any variable to a factor if it is unable to convert it to a numeric variable. If a variable is actually numeric, but you want to treat it as a factor, you can use \texttt{as.factor} to convert it, as in the following example.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Make sure you have loaded the lgrdata package}
\KeywordTok{data}\NormalTok{(pupae)}

\CommentTok{# This dataset contains a temperature (T_treatment) and CO2 treatment (CO2_treatment).}
\CommentTok{# Both should logically be factors, however, CO2_treatment is read as numeric:}
\KeywordTok{str}\NormalTok{(pupae)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    84 obs. of  5 variables:
##  $ T_treatment  : Factor w/ 2 levels "ambient","elevated": 1 1 1 1 1 1 1 1 1 1 ...
##  $ CO2_treatment: int  280 280 280 280 280 280 280 280 280 280 ...
##  $ Gender       : int  0 1 0 0 0 1 0 1 0 1 ...
##  $ PupalWeight  : num  0.244 0.319 0.221 0.28 0.257 0.333 0.275 0.312 0.254 0.356 ...
##  $ Frass        : num  1.9 2.77 NA 2 1.07 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# To convert it to a factor, we use:}
\NormalTok{pupae}\OperatorTok{$}\NormalTok{CO2_treatment <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(pupae}\OperatorTok{$}\NormalTok{CO2_treatment)}

\CommentTok{# Compare with the above,}
\KeywordTok{str}\NormalTok{(pupae)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    84 obs. of  5 variables:
##  $ T_treatment  : Factor w/ 2 levels "ambient","elevated": 1 1 1 1 1 1 1 1 1 1 ...
##  $ CO2_treatment: Factor w/ 2 levels "280","400": 1 1 1 1 1 1 1 1 1 1 ...
##  $ Gender       : int  0 1 0 0 0 1 0 1 0 1 ...
##  $ PupalWeight  : num  0.244 0.319 0.221 0.28 0.257 0.333 0.275 0.312 0.254 0.356 ...
##  $ Frass        : num  1.9 2.77 NA 2 1.07 ...
\end{verbatim}

In the \texttt{allometry} example dataset, the \texttt{species} variable is a good example of a factor. A factor variable has a number of `levels', which are the text values that the variable has in the dataset. Factors can also represent treatments of an experimental study. For example,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(allometry)}
\KeywordTok{levels}\NormalTok{(allometry}\OperatorTok{$}\NormalTok{species)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "PIMO" "PIPO" "PSME"
\end{verbatim}

Shows the three species in this dataset. We can also count the number of rows in the dataframe for each species, like this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{table}\NormalTok{(allometry}\OperatorTok{$}\NormalTok{species)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## PIMO PIPO PSME 
##   19   22   22
\end{verbatim}

Note that the three species are always shown in the order of the \textbf{levels of the factor}: when the dataframe was read, these levels were assigned based on alphabetical order. Often, this is not a very logical order, and you may want to rearrange the levels to get more meaningful results.

In our example, let's shuffle the levels around, using \texttt{factor}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{allometry}\OperatorTok{$}\NormalTok{species <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(allometry}\OperatorTok{$}\NormalTok{species, }\DataTypeTok{levels=}\KeywordTok{c}\NormalTok{(}\StringTok{"PSME"}\NormalTok{,}\StringTok{"PIMO"}\NormalTok{,}\StringTok{"PIPO"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Now revisit the commands above, and note that the results are the same, but the order of the \texttt{levels} of
the \texttt{factor} is different. You can also reorder the levels of a factor by the values of another variable, see the example in Section \ref{reorder}.

\hypertarget{turn-numeric-data-into-factors}{%
\subsubsection{Turn numeric data into factors}\label{turn-numeric-data-into-factors}}

We can also generate new factors, and add them to the dataframe. This is a common application:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Add a new variable to allom:  'small' when diameter is less than 10, 'large' otherwise.}
\NormalTok{allometry}\OperatorTok{$}\NormalTok{treeSizeClass <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(}\KeywordTok{ifelse}\NormalTok{(allometry}\OperatorTok{$}\NormalTok{diameter }\OperatorTok{<}\StringTok{ }\DecValTok{10}\NormalTok{, }\StringTok{"small"}\NormalTok{, }\StringTok{"large"}\NormalTok{))}

\CommentTok{# Now, look how many trees fall in each class.}
\CommentTok{# Note that somewhat confusingly, 'large' is printed before 'small'.}
\CommentTok{# Once again, this is because the order of the factor levels is alphabetical by default.}
\KeywordTok{table}\NormalTok{(allometry}\OperatorTok{$}\NormalTok{treeSizeClass)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## large small 
##    56     7
\end{verbatim}

What if we want to add a new factor based on a numeric variable with more than two levels? In that case, we cannot use \texttt{ifelse}. We must find a different method. Look at this example using \texttt{cut}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# The cut function takes a numeric vectors and cuts it into a categorical variable.}
\CommentTok{# Continuing the example above, let's make 'small','medium' and 'large' tree size classes:}
\NormalTok{allometry}\OperatorTok{$}\NormalTok{treeSizeClass <-}\StringTok{ }\KeywordTok{cut}\NormalTok{(allometry}\OperatorTok{$}\NormalTok{diameter, }\DataTypeTok{breaks=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{25}\NormalTok{,}\DecValTok{50}\NormalTok{,}\DecValTok{75}\NormalTok{), }
                           \DataTypeTok{labels=}\KeywordTok{c}\NormalTok{(}\StringTok{"small"}\NormalTok{,}\StringTok{"medium"}\NormalTok{,}\StringTok{"large"}\NormalTok{))}

\CommentTok{# And the results,}
\KeywordTok{table}\NormalTok{(allometry}\OperatorTok{$}\NormalTok{treeSizeClass)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  small medium  large 
##     22     24     17
\end{verbatim}

\hypertarget{empty-factor-levels}{%
\subsubsection{Empty factor levels}\label{empty-factor-levels}}

It is important to understand how factors are used in R: they are not simply text variables, or `character strings'. Each unique value of a factor variable is assigned a \emph{level}, which is used every time you summarize your data by the factor variable.

Crucially, even when you delete data, the original factor \emph{level} is still present. Although this behaviour might seem strange, it makes a lot of sense in many cases (zero observations for a particular factor level can be quite informative!).

Sometimes it is more convenient to drop empty factor levels with the \texttt{droplevels} function. Consider this example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Note that 'T_treatment' (temperature treatment) is a factor with two levels,}
\CommentTok{# with 37 and 47 observations in total:}
\KeywordTok{table}\NormalTok{(pupae}\OperatorTok{$}\NormalTok{T_treatment)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  ambient elevated 
##       37       47
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Suppose we decide to keep only the ambient treatment:}
\NormalTok{pupae_amb <-}\StringTok{ }\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{filter}\NormalTok{(pupae, T_treatment }\OperatorTok{==}\StringTok{ "ambient"}\NormalTok{)}

\CommentTok{# Now, the level is still present, although empty:}
\KeywordTok{table}\NormalTok{(pupae_amb}\OperatorTok{$}\NormalTok{T_treatment)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  ambient elevated 
##       37        0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# In this case, we don't want to keep the empty factor level.}
\CommentTok{# Use droplevels to get rid of any empty levels:}
\NormalTok{pupae_amb2 <-}\StringTok{ }\KeywordTok{droplevels}\NormalTok{(pupae_amb)}
\end{Highlighting}
\end{Shaded}

\BeginKnitrBlock{rmdtry}
Compare the \texttt{summary} of \texttt{pupae\_amb} and \texttt{pupae\_amb2}, and note the differences.
\EndKnitrBlock{rmdtry}

\hypertarget{changelevels}{%
\subsubsection{Changing the levels of a factor}\label{changelevels}}

Sometimes you may want to change the levels of a factor, for example to replace abbreviations with more readable labels. To do this, we can assign new values with the \texttt{levels} function, as in the following example using the pupae data:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Change the levels of T_treatment by assigning a character vector to the levels.}
\KeywordTok{levels}\NormalTok{(pupae}\OperatorTok{$}\NormalTok{T_treatment) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Ambient"}\NormalTok{,}\StringTok{"Ambient + 3C"}\NormalTok{)}

\CommentTok{# Or only change the first level, using subscripting.}
\KeywordTok{levels}\NormalTok{(pupae}\OperatorTok{$}\NormalTok{T_treatment)[}\DecValTok{1}\NormalTok{] <-}\StringTok{ "Control"}
\end{Highlighting}
\end{Shaded}

\BeginKnitrBlock{rmdtry}
Using the method above, you can also merge levels of a factor, simply by assigning the same new level to both old levels. Try this on a dataset of your choice (for example, in the \texttt{allom} data, you can assign new species levels, `Douglas-fir' for PSME, and `Pine' for both PIMO and PIPO). Then check the results with \texttt{levels()}.
\EndKnitrBlock{rmdtry}

\hypertarget{workinglogic}{%
\subsection{Working with logical data}\label{workinglogic}}

Some data can only take two values: true, or false. For data like these, R has the \emph{logical} data type.

The following examples use various logical operators, and all return TRUE or FALSE, or a vector of them. The help page \texttt{?Syntax} has a comprehensive list of operators in R (including the logical operators).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Answers to (in)equalities are always logical:}
\DecValTok{10} \OperatorTok{>}\StringTok{ }\DecValTok{5}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{101} \OperatorTok{==}\StringTok{ }\DecValTok{100} \OperatorTok{+}\StringTok{ }\DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# ... or use objects for comparison:}
\NormalTok{apple <-}\StringTok{ }\DecValTok{2}
\NormalTok{pear <-}\StringTok{ }\DecValTok{3}
\NormalTok{apple }\OperatorTok{==}\StringTok{ }\NormalTok{pear}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# NOT equal to.}
\NormalTok{apple }\OperatorTok{!=}\StringTok{ }\NormalTok{pear}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Logical comparisons like these also work for vectors, for example:}
\NormalTok{nums <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{21}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{12}\NormalTok{)}
\NormalTok{nums }\OperatorTok{>}\StringTok{ }\DecValTok{5}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  TRUE  TRUE FALSE  TRUE FALSE FALSE  TRUE
\end{verbatim}

The functions \texttt{which}, \texttt{any} and \texttt{all} are very useful to know when working with logical data:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Find which of the numbers are larger than 5:}
\KeywordTok{which}\NormalTok{(nums }\OperatorTok{>}\StringTok{ }\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 4 7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Other useful functions are 'any' and 'all':}
\CommentTok{# Are any numbers larger than 25?}
\KeywordTok{any}\NormalTok{(nums }\OperatorTok{>}\StringTok{ }\DecValTok{25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Are all numbers less than or equal to 10?}
\KeywordTok{all}\NormalTok{(nums }\OperatorTok{<=}\StringTok{ }\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

You have already been using logical data when we filtered dataframes and vectors:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Use & for AND, for example to take subsets where two conditions are met:}
\KeywordTok{subset}\NormalTok{(pupae, PupalWeight }\OperatorTok{>}\StringTok{ }\FloatTok{0.4} \OperatorTok{&}\StringTok{ }\NormalTok{Frass }\OperatorTok{>}\StringTok{ }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    T_treatment CO2_treatment Gender PupalWeight Frass
## 25     ambient           400      1       0.405 3.117
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Use | for OR}
\NormalTok{nums[nums }\OperatorTok{<}\StringTok{ }\DecValTok{2} \OperatorTok{|}\StringTok{ }\NormalTok{nums }\OperatorTok{>}\StringTok{ }\DecValTok{20}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 21  0  1
\end{verbatim}

Logical data are coded by integer numbers (0 = \texttt{FALSE}, 1 = \texttt{TRUE}), but normally you don't see this, since R will only \emph{print} \texttt{TRUE} and \texttt{FALSE} `labels'. However, once you know this, some analyses become even easier.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# How many numbers are larger than 5?}
\CommentTok{#- Short solution}
\KeywordTok{sum}\NormalTok{(nums }\OperatorTok{>}\StringTok{ }\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#- Long solution}
\KeywordTok{length}\NormalTok{(nums[nums }\OperatorTok{>}\StringTok{ }\DecValTok{5}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# What fraction of data is larger than some value?}
\KeywordTok{mean}\NormalTok{(pupae}\OperatorTok{$}\NormalTok{PupalWeight }\OperatorTok{>}\StringTok{ }\FloatTok{0.3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.4880952
\end{verbatim}

\hypertarget{workingmissing}{%
\subsection{Working with missing values}\label{workingmissing}}

In R, missing values are represented with \texttt{NA}, a special data type that indicates the data is simply \emph{Not Available}.

Many functions can handle missing data, usually in different ways. For example, suppose we have the following vector:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myvec1 <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{11}\NormalTok{,}\DecValTok{13}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\OtherTok{NA}\NormalTok{,}\DecValTok{9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In order to calculate the mean, we might want to either exclude the missing value (and calculate the mean of the remaining five numbers), or we might want \texttt{mean(myvec1)} to fail (produce an error). This last case is useful if we don't expect missing values, and want R to only calculate the mean when there are no \texttt{NA}'s in the dataset.

These two options are shown in this example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Calculate mean: this fails if there are missing values}
\KeywordTok{mean}\NormalTok{(myvec1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Calculate mean after removing the missing values}
\KeywordTok{mean}\NormalTok{(myvec1, }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8.8
\end{verbatim}

Many functions have an argument \texttt{na.rm}, or similar. Refer to the help page of the function to learn about the various options (if any) for dealing with missing values. For example, see the help pages \texttt{?lm} and \texttt{?sd}.

The function \texttt{is.na} returns \texttt{TRUE} when a value is missing, which can be useful to see which values are missing, or how many,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Is a value missing? (TRUE or FALSE)}
\KeywordTok{is.na}\NormalTok{(myvec1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE FALSE FALSE FALSE  TRUE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Which of the elements of a vector is missing?}
\KeywordTok{which}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(myvec1))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# How many values in a vector are NA?}
\KeywordTok{sum}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(myvec1))  }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

\hypertarget{making-missing-values}{%
\subsubsection{Making missing values}\label{making-missing-values}}

In many cases it is useful to change some bad data values to \texttt{NA}. We can use our indexing skills to do so,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Some vector that contains bad values coded as -9999}
\NormalTok{datavec <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\OperatorTok{-}\DecValTok{9999}\NormalTok{,}\DecValTok{100}\NormalTok{,}\DecValTok{3}\NormalTok{,}\OperatorTok{-}\DecValTok{9999}\NormalTok{,}\DecValTok{5}\NormalTok{)}

\CommentTok{# Assign NA to the values that were -9999}
\NormalTok{datavec[datavec }\OperatorTok{==}\StringTok{ }\DecValTok{-9999}\NormalTok{] <-}\StringTok{ }\OtherTok{NA} 
\end{Highlighting}
\end{Shaded}

In other cases, missing values arise when certain operations did not produce the desired result. Consider this example,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# A character vector, some of these look like numbers:}
\NormalTok{myvec <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"101"}\NormalTok{,}\StringTok{"289"}\NormalTok{,}\StringTok{"12.3"}\NormalTok{,}\StringTok{"abc"}\NormalTok{,}\StringTok{"99"}\NormalTok{)}

\CommentTok{# Convert the vector to numeric:}
\KeywordTok{as.numeric}\NormalTok{(myvec)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: NAs introduced by coercion
\end{verbatim}

\begin{verbatim}
## [1] 101.0 289.0  12.3    NA  99.0
\end{verbatim}

The warning message \textbf{NAs introduced by coercion} means that missing values were produced by when we tried to turn one data type (character) to another (numeric).

\hypertarget{not-a-number}{%
\subsubsection{Not A Number}\label{not-a-number}}

Another type of missing value is the result of calculations that went wrong, for example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Attempt to take the logarithm of a negative number:}
\KeywordTok{log}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in log(-1): NaNs produced
\end{verbatim}

\begin{verbatim}
## [1] NaN
\end{verbatim}

The result is \texttt{NaN}, short for \emph{Not A Number}.

Dividing by zero is not usually meaningful, but R does not produce a missing value:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1000}\OperatorTok{/}\DecValTok{0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] Inf
\end{verbatim}

It produces `Infinity' instead.

\hypertarget{naindataframe}{%
\subsubsection{Missing values in dataframes}\label{naindataframe}}

When working with dataframes, you often want to remove missing values for a particular analysis. We'll use the \texttt{pupae} dataset for the following examples. Note we use the \texttt{dplyr} package for \texttt{filter}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# (re-)load data}
\KeywordTok{data}\NormalTok{(pupae)}

\CommentTok{# Look at a summary to see if there are missing values:}
\KeywordTok{summary}\NormalTok{(pupae)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    T_treatment CO2_treatment       Gender        PupalWeight    
##  ambient :37   Min.   :280.0   Min.   :0.0000   Min.   :0.1720  
##  elevated:47   1st Qu.:280.0   1st Qu.:0.0000   1st Qu.:0.2562  
##                Median :400.0   Median :0.0000   Median :0.2975  
##                Mean   :344.3   Mean   :0.4487   Mean   :0.3110  
##                3rd Qu.:400.0   3rd Qu.:1.0000   3rd Qu.:0.3560  
##                Max.   :400.0   Max.   :1.0000   Max.   :0.4730  
##                                NA's   :6                        
##      Frass      
##  Min.   :0.986  
##  1st Qu.:1.515  
##  Median :1.818  
##  Mean   :1.846  
##  3rd Qu.:2.095  
##  Max.   :3.117  
##  NA's   :1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Notice there are 6 NA's (missing values) for Gender, and 1 for Frass.}

\CommentTok{# Option 1: take subset of data where Gender is not missing:}
\NormalTok{pupae_subs1 <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(pupae, }\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(Gender))}

\CommentTok{# Option 2: take subset of data where Frass AND Gender are not missing}
\NormalTok{pupae_subs2 <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(pupae, }
                      \OperatorTok{!}\KeywordTok{is.na}\NormalTok{(Frass),}
                      \OperatorTok{!}\KeywordTok{is.na}\NormalTok{(Gender))}

\CommentTok{# A more rigorous subset: remove all rows from a dataset where ANY variable }
\CommentTok{# has a missing value:}
\NormalTok{pupae_nona <-}\StringTok{ }\NormalTok{pupae[}\KeywordTok{complete.cases}\NormalTok{(pupae),]}

\CommentTok{# This was an example where indexing (using square brackets) is a bit more }
\CommentTok{# convenient than the dplyr approach, where we have to write the following.}
\CommentTok{# A number of similar looking statements do not work!}
\NormalTok{pupae_nona <-}\StringTok{ }\NormalTok{pupae }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(}\KeywordTok{complete.cases}\NormalTok{(.))}
\end{Highlighting}
\end{Shaded}

\hypertarget{subsetmissing}{%
\subsubsection{Subsetting when there are missing values}\label{subsetmissing}}

When there are missing values in a vector, and you take a subset (for example all data larger than some value), should the missing values be included or dropped? There is no one answer to this, but it is important to know that \texttt{subset} drops them, but the square bracket method (\texttt{{[}{]}}) keeps them.

Consider this example, and especially the use of \texttt{which} to drop missing values when subsetting.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# A small dataframe}
\NormalTok{dfr <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{a=}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{, }\DataTypeTok{b=}\KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\OtherTok{NA}\NormalTok{,}\DecValTok{6}\NormalTok{,}\OtherTok{NA}\NormalTok{))}

\CommentTok{# subset drops all missing values}
\CommentTok{# Note: dplyr::filter also drops NA}
\KeywordTok{subset}\NormalTok{(dfr, b }\OperatorTok{>}\StringTok{ }\DecValTok{4}\NormalTok{, }\DataTypeTok{select=}\NormalTok{b)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   b
## 3 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# square bracket notation keeps them}
\NormalTok{dfr[dfr}\OperatorTok{$}\NormalTok{b }\OperatorTok{>}\StringTok{ }\DecValTok{4}\NormalTok{,}\StringTok{"b"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] NA  6 NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# ... but drops them when we use 'which'}
\NormalTok{dfr[}\KeywordTok{which}\NormalTok{(dfr}\OperatorTok{$}\NormalTok{b }\OperatorTok{>}\StringTok{ }\DecValTok{4}\NormalTok{),}\StringTok{"b"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6
\end{verbatim}

\hypertarget{workingtext}{%
\subsection{Working with text}\label{workingtext}}

Many datasets include variables that are text only (think of comments, species names, locations, sample codes, and so on), it is useful to learn how to modify, extract, and analyse text-based (`character') variables.

Consider the following simple examples when working with a single character string:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Count number of characters in a bit of text:}
\NormalTok{sentence <-}\StringTok{ "Not a very long sentence."}
\KeywordTok{nchar}\NormalTok{(sentence)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 25
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extract the first 3 characters:}
\KeywordTok{substr}\NormalTok{(sentence, }\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Not"
\end{verbatim}

We can also apply these functions to a vector:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Substring all elements of a vector}
\KeywordTok{substr}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"good"}\NormalTok{,}\StringTok{"good riddance"}\NormalTok{,}\StringTok{"good on ya"}\NormalTok{),}\DecValTok{1}\NormalTok{,}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "good" "good" "good"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Number of characters of all elements of a vector}
\KeywordTok{nchar}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"hey"}\NormalTok{,}\StringTok{"hi"}\NormalTok{,}\StringTok{"how"}\NormalTok{,}\StringTok{"ya"}\NormalTok{,}\StringTok{"doin"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3 2 3 2 4
\end{verbatim}

\hypertarget{paste}{%
\subsubsection{Combining text}\label{paste}}

To glue bits of text together, use the \texttt{paste} function, like so:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Add a suffix to each text element of a vector:}
\NormalTok{txt <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"apple"}\NormalTok{,}\StringTok{"pear"}\NormalTok{,}\StringTok{"banana"}\NormalTok{)}
\KeywordTok{paste}\NormalTok{(txt, }\StringTok{"fruit"}\NormalTok{, }\DataTypeTok{sep =} \StringTok{"-"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "apple-fruit"  "pear-fruit"   "banana-fruit"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Glue them all together into a single string using the collapse argument}
\KeywordTok{paste}\NormalTok{(txt, }\DataTypeTok{collapse =} \StringTok{"-"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "apple-pear-banana"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Combine numbers and text:}
\KeywordTok{paste}\NormalTok{(}\StringTok{"Question"}\NormalTok{, }\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Question 1" "Question 2" "Question 3"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# This can be of use to make new variables in a dataframe,}
\CommentTok{# as in this example where we combine two factors to create a new one:}
\NormalTok{pupae}\OperatorTok{$}\NormalTok{T_CO2 <-}\StringTok{ }\KeywordTok{with}\NormalTok{(pupae, }\KeywordTok{paste}\NormalTok{(T_treatment, CO2_treatment, }\DataTypeTok{sep=}\StringTok{"-"}\NormalTok{))}
\KeywordTok{head}\NormalTok{(pupae}\OperatorTok{$}\NormalTok{T_CO2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "ambient-280" "ambient-280" "ambient-280" "ambient-280" "ambient-280"
## [6] "ambient-280"
\end{verbatim}

\BeginKnitrBlock{rmdtry}
Run the final example above, and inspect the variable \texttt{T\_CO2} (with \texttt{str}) that we added to the dataframe. Make it into a factor variable using \texttt{as.factor}, and inspect the variable again.
\EndKnitrBlock{rmdtry}

\hypertarget{textgrep}{%
\subsubsection{\texorpdfstring{Text in dataframes and \texttt{grep}}{Text in dataframes and grep}}\label{textgrep}}

When you read in a dataset (with \texttt{read.csv}, \texttt{read.table} or similar), any variable that R cannot convert to numeric \emph{is automatically converted to a factor}. This means that if a column has even just one value that is text (or some garble that does not represent a number), the column cannot be numeric.

When you want non-numeric columns to be read in as \emph{character} instead of \emph{factor}, you must do:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cereals <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"cereals.csv"}\NormalTok{, }\DataTypeTok{stringsAsFactors =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Here, the argument \texttt{stringsAsFactors=FALSE} avoided the automatic conversion of character variables to factors.

While we know that factors are very useful, sometimes we want a variable to be treated like text. For example, if we plan to analyse text directly, or extract numbers or other information from bits of text. Let's look at a few examples using the \texttt{titanic} dataset.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Load dataset}
\KeywordTok{data}\NormalTok{(titanic)}

\CommentTok{# Is passenger name stored as a character?}
\KeywordTok{is.character}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{Name)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Evidently not. We can convert it to character:}
\NormalTok{titanic}\OperatorTok{$}\NormalTok{Name <-}\StringTok{ }\KeywordTok{as.character}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{Name)}

\CommentTok{# ... or as part of a dplyr chain:}
\NormalTok{titanic <-}\StringTok{ }\NormalTok{titanic }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{Name =} \KeywordTok{as.character}\NormalTok{(Name))}
\end{Highlighting}
\end{Shaded}

The following example uses \texttt{grep}, a very powerful function. This function can make use of \emph{regular expressions}, a flexible tool for text processing.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extract cereal names (for convenience).}
\KeywordTok{data}\NormalTok{(cereals)}
\NormalTok{cerealnames <-}\StringTok{ }\NormalTok{cereals}\OperatorTok{$}\NormalTok{Cereal.name}

\CommentTok{# Find the cereals that have 'Raisin' in them.}
\CommentTok{# grep() returns the index of values that contain Raisin}
\KeywordTok{grep}\NormalTok{(}\StringTok{"Raisin"}\NormalTok{,cerealnames)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 23 45 46 50 52 53 59 60 61 71
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# grepl() returns TRUE or FALSE}
\KeywordTok{grepl}\NormalTok{(}\StringTok{"Raisin"}\NormalTok{,cerealnames)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [12] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [23]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [34] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [45]  TRUE  TRUE FALSE FALSE FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE
## [56] FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE
## [67] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# That result just gives you the indices of the vector that have 'Raisin' in them.}
\CommentTok{# these are the corresponding names:}
\NormalTok{cerealnames[}\KeywordTok{grep}\NormalTok{(}\StringTok{"Raisin"}\NormalTok{,cerealnames)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "Crispy_Wheat_&_Raisins"           
##  [2] "Muesli_Raisins,_Dates,_&_Almonds" 
##  [3] "Muesli_Raisins,_Peaches,_&_Pecans"
##  [4] "Nutri-Grain_Almond-Raisin"        
##  [5] "Oatmeal_Raisin_Crisp"             
##  [6] "Post_Nat._Raisin_Bran"            
##  [7] "Raisin_Bran"                      
##  [8] "Raisin_Nut_Bran"                  
##  [9] "Raisin_Squares"                   
## [10] "Total_Raisin_Bran"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Now find the cereals whose name starts with Raisin.}
\CommentTok{# The ^ symbol is part of a 'regular expression', it indicates 'starts with':}
\KeywordTok{grep}\NormalTok{(}\StringTok{"^Raisin"}\NormalTok{,cerealnames)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 59 60 61
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Or end with 'Bran'}
\CommentTok{# The $ symbol is part of a 'regular expression', and indicates 'ends with':}
\KeywordTok{grep}\NormalTok{(}\StringTok{"Bran$"}\NormalTok{, cerealnames)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1  2  3 20 29 53 59 60 65 71
\end{verbatim}

As mentioned, \texttt{grep} can do a \emph{lot} of different things, so don't be alarmed if you find the help page \emph{a bit overwhelming}. However, there are a few options worth knowing about. One very useful option is to turn off the case-sensitivity, for example:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{grep}\NormalTok{(}\StringTok{"bran"}\NormalTok{, cerealnames, }\DataTypeTok{ignore.case=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1  2  3  4  9 10 20 29 53 59 60 65 71
\end{verbatim}

finds \texttt{Bran} and \texttt{bran} and \texttt{BRAN}.

Finally, using the above tools, let's add a new variable to the \texttt{cereal} dataset that is \texttt{TRUE} when the name of the cereal ends in `Bran', otherwise it is \texttt{FALSE}. For this example, the \texttt{grepl} function is more useful (because it returns TRUE and FALSE).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# grepl will return FALSE when Bran is not found, TRUE otherwise}
\NormalTok{cereals}\OperatorTok{$}\NormalTok{BranOrNot <-}\StringTok{ }\KeywordTok{grepl}\NormalTok{(}\StringTok{"Bran$"}\NormalTok{, cerealnames)}

\CommentTok{# Quick summary:}
\KeywordTok{table}\NormalTok{(cereals}\OperatorTok{$}\NormalTok{BranOrNot)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## FALSE  TRUE 
##    67    10
\end{verbatim}

\BeginKnitrBlock{rmdreading}
A clear explanation of regular expressions is on the Wikipedia page \url{http://en.wikipedia.org/wiki/Regular_expressions}. Also worth a look is Robin Lovelace's introduction specifically for R and RStudio at \url{https://www.r-bloggers.com/regular-expressions-in-r-vs-rstudio/}.
\EndKnitrBlock{rmdreading}

\hypertarget{more-control-with-the-stringr-package}{%
\subsubsection{\texorpdfstring{More control with the \texttt{stringr} package}{More control with the stringr package}}\label{more-control-with-the-stringr-package}}

In the previous section we used \texttt{grep} and \texttt{grepl} to find text in strings, which we can use to subset dataframes, or simply to find data. We can do a lot more with strings, but things get a bit difficult quickly when we stick to base R. Instead, the \texttt{stringr} package provides an easy-to-use interface to many common text operations. The following examples give a few very handy tips, but the package provides much more (see \texttt{library(help=stringr)}).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(stringr)}

\CommentTok{# Extract all numbers from a string}
\CommentTok{# Note that the result is a character!}
\KeywordTok{str_extract}\NormalTok{(}\StringTok{"I have 5 apples"}\NormalTok{, }\StringTok{"[0-9]"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "5"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extract the nth word from text.}
\KeywordTok{word}\NormalTok{(}\StringTok{"Dantchoff, Mr Khristo"}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Mr"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Replace text that matches a pattern.}
\CommentTok{# (sub or gsub from base R also work OK)}
\KeywordTok{str_replace}\NormalTok{(}\StringTok{"Dantchoff, Mr Khristo"}\NormalTok{, }\StringTok{"Mr"}\NormalTok{, }\StringTok{"Mrs"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Dantchoff, Mrs Khristo"
\end{verbatim}

\hypertarget{combining-text-and-r-objects-with-glue}{%
\subsubsection{\texorpdfstring{Combining text and R objects with \texttt{glue}}{Combining text and R objects with glue}}\label{combining-text-and-r-objects-with-glue}}

When controlling output, we often want to combine results stored in R objects, and text. As we saw in Section \ref{paste}, we can use \texttt{paste} to achieve this, but there's a better way:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(glue)}

\KeywordTok{data}\NormalTok{(titanic)}
\KeywordTok{glue}\NormalTok{(}\StringTok{"The titanic dataset has \{nrow(titanic)\} rows. "}\NormalTok{,}
     \StringTok{"For \{percmissing\}% of the data, Age is missing."}\NormalTok{,}
     \DataTypeTok{percmissing =} \KeywordTok{round}\NormalTok{(}\DecValTok{100} \OperatorTok{*}\StringTok{ }\KeywordTok{mean}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{Age)), }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## The titanic dataset has 1313 rows. For 42.4% of the data, Age is missing.
\end{verbatim}

With \texttt{glue}, we can include both R code directly within \texttt{\{\}} (as we did with \texttt{nrow(titanic)}), and also use temporary variables (here: \texttt{percmissing}) that are given as extra arguments. Also note that strings separated by \texttt{,} are pasted together by \texttt{glue}.

\hypertarget{workingwithdates}{%
\subsection{Working with dates and times}\label{workingwithdates}}

Admittedly, working with dates and times in R is somewhat annoying at first. The built-in help files on this subject describe all aspects of this special data type, but do not offer much for the beginning R user. This section covers basic operations that you may need when analysing and formatting datasets.

For working with dates, we use the \texttt{lubridate} package, which simplifies it tremendously.

\hypertarget{readingdates}{%
\subsubsection{Reading dates}\label{readingdates}}

The built-in \texttt{Date} class in R is encoded as an integer number representing the number of days since 1-1-1970 (but this actual origin does not matter for the user). Converting a character string to a date with \texttt{as.Date} is straightforward if you use the standard order of dates: \texttt{YYYY-MM-DD}. So, for example,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as.Date}\NormalTok{(}\StringTok{"2008-5-22"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2008-05-22"
\end{verbatim}

The output here is not interesting, R simply prints the date. Because dates are represented as numbers in R, we can do basic arithmetic:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# First load lubridate when working with dates or date-time combinations.}
\CommentTok{# (as.Date and difftime are part of the base package, but lubridate provides}
\CommentTok{# years(), months(), and many more functions used below).}
\KeywordTok{library}\NormalTok{(lubridate)}

\CommentTok{# A date, 7 days later:}
\KeywordTok{as.Date}\NormalTok{(}\StringTok{"2011-5-12"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\DecValTok{7}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2011-05-19"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Difference between dates.}
\KeywordTok{as.Date}\NormalTok{(}\StringTok{"2009-7-1"}\NormalTok{) }\OperatorTok{-}\StringTok{ }\KeywordTok{as.Date}\NormalTok{(}\StringTok{"2008-12-1"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Time difference of 212 days
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# With difftime, you can specify the units:}
\KeywordTok{difftime}\NormalTok{(}\KeywordTok{as.Date}\NormalTok{(}\StringTok{"2009-7-1"}\NormalTok{), }\KeywordTok{as.Date}\NormalTok{(}\StringTok{"2008-12-1"}\NormalTok{), }\DataTypeTok{units =} \StringTok{"weeks"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Time difference of 30.28571 weeks
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# To add other timespans, use functions months(), years() or weeks() to}
\CommentTok{# avoid problems with leap years}
\KeywordTok{as.Date}\NormalTok{(}\StringTok{"2013-8-18"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{years}\NormalTok{(}\DecValTok{10}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{months}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2023-09-18"
\end{verbatim}

\BeginKnitrBlock{rmdtry}
The previous example showed a very useful trick for adding numbers to a \texttt{Date} to get a new \texttt{Date} a few days later. Confirm for yourself that this method accounts for leap years. That is, the day before \texttt{2011-3-1} should be \texttt{2011-2-28} (2011 is not a leap year). But what about \texttt{2012-3-1}?
\EndKnitrBlock{rmdtry}

Often, text strings representing the date are not in the standard format. Fortunately, it is possible to convert any reasonable sequence to a \texttt{Date} object in R. All we have to do is provide a character string to \texttt{as.Date} and tell the function the order of the fields.

To convert any format to a Date, we can use the \texttt{lubridate} package, which contains the functions \texttt{ymd}, \texttt{mdy}, and all other combinations of y, m, and d.~These functions are pretty smart, as can be seen in these examples:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Day / month / year}
\KeywordTok{as.Date}\NormalTok{(}\KeywordTok{dmy}\NormalTok{(}\StringTok{"31/12/1991"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "1991-12-31"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Month - day - year (note, only two digits for the year)}
\KeywordTok{as.Date}\NormalTok{(}\KeywordTok{mdy}\NormalTok{(}\StringTok{"4-17-92"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "1992-04-17"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Year month day}
\KeywordTok{as.Date}\NormalTok{(}\KeywordTok{ymd}\NormalTok{(}\StringTok{"1976-5-22"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "1976-05-22"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#-- Unusual formatting can be read in with the 'format' argument}
\CommentTok{# in as.Date. See ?strptime for a list of codes.}
\CommentTok{# For example, Year and day of year ("%j" stands for 'Julian date')}
\KeywordTok{as.Date}\NormalTok{(}\StringTok{"2011 121"}\NormalTok{, }\DataTypeTok{format=}\StringTok{"%Y %j"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2011-05-01"
\end{verbatim}

Another method to construct date objects is when you do not have a character string as in the above example, but separate numeric variables for year, month and day. In this case, use the \texttt{ISOdate} function:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as.Date}\NormalTok{(}\KeywordTok{ISOdate}\NormalTok{(}\DecValTok{2008}\NormalTok{,}\DecValTok{12}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2008-12-02"
\end{verbatim}

Finally, here is a simple way to find the number of days since you were born, using \texttt{today} from the lubridate package.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Today's date (and time) can be with the today() function}
\KeywordTok{today}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2019-06-10"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# We can now simply subtract your birthday from today's date.}
\KeywordTok{today}\NormalTok{() }\OperatorTok{-}\StringTok{ }\KeywordTok{as.Date}\NormalTok{(}\StringTok{"1976-5-22"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Time difference of 15724 days
\end{verbatim}

\hypertarget{example-using-dates-in-a-dataframe}{%
\subsubsection{Example: using dates in a dataframe}\label{example-using-dates-in-a-dataframe}}

The \texttt{as.Date} function that we met in the previous section also works with vectors of dates, and the \texttt{Date} class can also be part of a dataframe. Let's take a look at the Hydro data to practice working with dates.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Load the hydro dataset}
\KeywordTok{data}\NormalTok{(hydro)}

\CommentTok{# Now convert this to a Date variable. }
\CommentTok{# If you first inspect head(hydro$Date), you will see the format is DD/MM/YYYY}
\NormalTok{hydro}\OperatorTok{$}\NormalTok{Date <-}\StringTok{ }\KeywordTok{as.Date}\NormalTok{(}\KeywordTok{dmy}\NormalTok{(hydro}\OperatorTok{$}\NormalTok{Date))}
\end{Highlighting}
\end{Shaded}

If any of the date conversions go wrong, the \texttt{dmy} function (or its equivalents) should print a message letting you know. You can double check if \texttt{any} of the converted dates is \texttt{NA} like this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{any}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(hydro}\OperatorTok{$}\NormalTok{Date))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

We now have successfully read in the date variable. The \texttt{min} and \texttt{max} functions are useful to check the range of dates in the dataset:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Minimum and maximum date (that is, oldest and most recent),}
\KeywordTok{min}\NormalTok{(hydro}\OperatorTok{$}\NormalTok{Date)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2005-08-08"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{max}\NormalTok{(hydro}\OperatorTok{$}\NormalTok{Date)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2011-08-08"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#... and length of measurement period:}
\KeywordTok{max}\NormalTok{(hydro}\OperatorTok{$}\NormalTok{Date) }\OperatorTok{-}\StringTok{ }\KeywordTok{min}\NormalTok{(hydro}\OperatorTok{$}\NormalTok{Date)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Time difference of 2191 days
\end{verbatim}

Finally, the \texttt{Date} class is very handy when plotting. Let's make a simple graph of the Hydro dataset. The following code produces Fig. \ref{fig:hydroplot}. Note how the \texttt{X} axis is automatically formatted to display the date in a (fairly) pretty way.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(hydro, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Date, }\DataTypeTok{y =}\NormalTok{ storage)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{02-dataskills_files/figure-latex/hydroplot-1.pdf}
\caption{\label{fig:hydroplot}A simple plot of the hydro data.}
\end{figure}

\hypertarget{datetime}{%
\subsubsection{Date-Time combinations}\label{datetime}}

For dates that include the time, R has a special class called \texttt{POSIXct}. The \texttt{lubridate} package makes it easy to work with this class.

Internally, a date-time is represented as the number of seconds since the 1st of January, 1970. Time zones are also supported, but we will not use this functionality in this book (as it can be quite confusing).

From the lubridate package, we can use any combination of (y)ear,(m)onth,(d)ay, (h)our, (m)inutes, (s)econds. For example \texttt{ymd\_hms} converts a character string in that order.

Let's look at some examples,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Load lubridate}
\KeywordTok{library}\NormalTok{(lubridate)}

\CommentTok{# The standard format is YYYY-MM-DD HH:MM:SS}
\KeywordTok{ymd_hms}\NormalTok{(}\StringTok{"2012-9-16 13:05:00"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2012-09-16 13:05:00 UTC"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Read two times (note the first has no seconds, so we can use ymd_hm)}
\NormalTok{time1 <-}\StringTok{ }\KeywordTok{ymd_hm}\NormalTok{(}\StringTok{"2008-5-21 9:05"}\NormalTok{)}
\NormalTok{time2 <-}\StringTok{ }\KeywordTok{ymd_hms}\NormalTok{(}\StringTok{"2012-9-16 13:05:00"}\NormalTok{)}

\CommentTok{# Time difference:}
\NormalTok{time2 }\OperatorTok{-}\StringTok{ }\NormalTok{time1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Time difference of 1579.167 days
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# And an example with a different format, DD/M/YY H:MM}
\KeywordTok{dmy_hm}\NormalTok{(}\StringTok{"23-1-89 4:30"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "1989-01-23 04:30:00 UTC"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# To convert a date-time to a Date, you can also use the as.Date function,}
\CommentTok{# which will simply drop the time.}
\KeywordTok{as.Date}\NormalTok{(time1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2008-05-21"
\end{verbatim}

As with \texttt{Date} objects, we can calculate timespans using a few handy functions.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# What time is it 3 hours and 15 minutes from now?}
\KeywordTok{now}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{hours}\NormalTok{(}\DecValTok{3}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{minutes}\NormalTok{(}\DecValTok{15}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2019-06-10 13:04:38 CEST"
\end{verbatim}

\BeginKnitrBlock{rmdtry}
The 2012 Sydney marathon started at 7:20AM on September 16th. The winner completed the race in 2 hours, 11 minutes and 50 seconds. What was the time when the racer crossed the finish line? Using the \texttt{weekdays} function, which day was the race held?
\EndKnitrBlock{rmdtry}

\hypertarget{example-date-times-in-a-dataframe}{%
\subsubsection{Example: date-times in a dataframe}\label{example-date-times-in-a-dataframe}}

Now let's use a real dataset to practice the use of date-times. We also introduce the functions \texttt{month}, \texttt{yday}, \texttt{hour} and \texttt{minute} to conveniently extract components of date-time objects.

The last command produces Fig. \ref{fig:hfemetdate}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Read the 2008 met dataset from the HFE.}
\KeywordTok{data}\NormalTok{(hfemet2008)}

\CommentTok{# Convert 'DateTime' to POSIXct class.}
\CommentTok{# The order of the original data is MM/DD/YYYY HH:MM}
\CommentTok{# We also add various date and time fields to the dataframe.}
\NormalTok{hfemet <-}\StringTok{ }\NormalTok{hfemet2008 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{DateTime =} \KeywordTok{mdy_hm}\NormalTok{(DateTime),}
         \DataTypeTok{Date =} \KeywordTok{as.Date}\NormalTok{(DateTime),}
         \DataTypeTok{DOY =} \KeywordTok{yday}\NormalTok{(DateTime),}
         \DataTypeTok{hour =} \KeywordTok{hour}\NormalTok{(DateTime),}
         \DataTypeTok{minute =} \KeywordTok{minute}\NormalTok{(DateTime),}
         \DataTypeTok{month =} \KeywordTok{month}\NormalTok{(DateTime))}

\CommentTok{# Make sure all datetimes were converted OK (if not, NAs would be produced)}
\KeywordTok{any}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(hfemet}\OperatorTok{$}\NormalTok{DateTime))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# FALSE is good here!}

\CommentTok{# Make a simple line plot for data from one month.}
\KeywordTok{filter}\NormalTok{(hfemet, month }\OperatorTok{==}\StringTok{  }\DecValTok{6}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ DateTime, }\DataTypeTok{y =}\NormalTok{  Tair)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{02-dataskills_files/figure-latex/hfemetdate-1.pdf}
\caption{\label{fig:hfemetdate}Air temperature for June at the HFE}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# We can also take a subset of just one day, using the Date variable we added:}
\NormalTok{hfemet_oneday <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(hfemet, Date }\OperatorTok{==}\StringTok{ }\KeywordTok{as.Date}\NormalTok{(}\StringTok{"2008-11-1"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{seqdates}{%
\subsubsection{Sequences of dates and times}\label{seqdates}}

It is often useful to generate sequences of dates. We can use \texttt{seq} as we do for numeric variables (as we already saw in Section \ref{sequences}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# A series of dates, by day:}
\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from=}\KeywordTok{as.Date}\NormalTok{(}\StringTok{"2011-1-1"}\NormalTok{), }\DataTypeTok{to=}\KeywordTok{as.Date}\NormalTok{(}\StringTok{"2011-1-5"}\NormalTok{), }\DataTypeTok{by=}\StringTok{"day"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2011-01-01" "2011-01-02" "2011-01-03" "2011-01-04" "2011-01-05"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Two-weekly dates:}
\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from=}\KeywordTok{as.Date}\NormalTok{(}\StringTok{"2011-1-1"}\NormalTok{), }\DataTypeTok{length=}\DecValTok{4}\NormalTok{, }\DataTypeTok{by=}\StringTok{"2 weeks"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2011-01-01" "2011-01-15" "2011-01-29" "2011-02-12"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Monthly:}
\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from=}\KeywordTok{as.Date}\NormalTok{(}\StringTok{"2011-12-13"}\NormalTok{), }\DataTypeTok{length=}\DecValTok{4}\NormalTok{, }\DataTypeTok{by=}\StringTok{"months"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2011-12-13" "2012-01-13" "2012-02-13" "2012-03-13"
\end{verbatim}

Similarly, you can generate sequences of date-times.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Generate a sequence with 30 min timestep:}
\CommentTok{# Here, the 'by' field specifies the timestep in seconds.}
\NormalTok{fromtime <-}\StringTok{ }\KeywordTok{ymd_hm}\NormalTok{(}\StringTok{"2012-6-1 14:30"}\NormalTok{)}
\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from=}\NormalTok{fromtime, }\DataTypeTok{length=}\DecValTok{3}\NormalTok{, }\DataTypeTok{by=}\DecValTok{30}\OperatorTok{*}\DecValTok{60}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2012-06-01 14:30:00 UTC" "2012-06-01 15:00:00 UTC"
## [3] "2012-06-01 15:30:00 UTC"
\end{verbatim}

\hypertarget{converttype}{%
\subsection{Converting between data types}\label{converttype}}

It is often useful, or even necessary, to convert from one data type to another. For example, when you read in data with \texttt{read.csv} or \texttt{read.table}, any column that contains some non-numeric values (that is, values that cannot be converted to a number) will be converted to a factor variable. Sometimes you actually want to convert it to numeric, which will result in some missing values (\texttt{NA}) when the value could not be converted to a number.

Another common example is when one of your variables should be read in as a factor variable (for example, a column with treatment codes), but because all the values are numeric, R will simply assume it is a numeric column.

Before we learn how to convert, it is useful to make sure you know what type of data you have to begin with. To find out what type of data a particular vector is, we use \texttt{str} (this is also useful for any other object in R).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Numeric}
\NormalTok{y <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{100}\NormalTok{,}\DecValTok{10}\NormalTok{)}
\KeywordTok{str}\NormalTok{(y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  num [1:3] 1 100 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# This example also shows the dimension of the vector ([1:3]).}

\CommentTok{# Character}
\NormalTok{x <-}\StringTok{ "sometext"}
\KeywordTok{str}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  chr "sometext"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Factor}
\NormalTok{p <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"apple"}\NormalTok{,}\StringTok{"banana"}\NormalTok{))}
\KeywordTok{str}\NormalTok{(p)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  Factor w/ 2 levels "apple","banana": 1 2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Logical}
\NormalTok{z <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{TRUE}\NormalTok{,}\OtherTok{FALSE}\NormalTok{)}
\KeywordTok{str}\NormalTok{(z)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  logi [1:2] TRUE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Date}
\NormalTok{sometime <-}\StringTok{ }\KeywordTok{as.Date}\NormalTok{(}\StringTok{"1979-9-16"}\NormalTok{)}
\KeywordTok{str}\NormalTok{(sometime)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  Date[1:1], format: "1979-09-16"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Date-Time}
\KeywordTok{library}\NormalTok{(lubridate)}
\NormalTok{onceupon <-}\StringTok{ }\KeywordTok{ymd_hm}\NormalTok{(}\StringTok{"1969-8-18 09:00"}\NormalTok{)}
\KeywordTok{str}\NormalTok{(onceupon)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  POSIXct[1:1], format: "1969-08-18 09:00:00"
\end{verbatim}

To test for a particular type of data, use the \texttt{is.*something*} functions,
which give \texttt{TRUE} if the object is of that type, for example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Test for numeric data type:}
\KeywordTok{is.numeric}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{189}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Test for character:}
\KeywordTok{is.character}\NormalTok{(}\StringTok{"HIE"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

We can convert between types with the \texttt{as.*something*} class of functions.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# First we make six example values that we will use to convert}
\NormalTok{mynum <-}\StringTok{ }\DecValTok{1001}
\NormalTok{mychar <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"1001"}\NormalTok{,}\StringTok{"100 apples"}\NormalTok{)}
\NormalTok{myfac <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"280"}\NormalTok{,}\StringTok{"400"}\NormalTok{,}\StringTok{"650"}\NormalTok{))}
\NormalTok{mylog <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{TRUE}\NormalTok{,}\OtherTok{FALSE}\NormalTok{,}\OtherTok{FALSE}\NormalTok{,}\OtherTok{TRUE}\NormalTok{)}
\NormalTok{mydate <-}\StringTok{ }\KeywordTok{as.Date}\NormalTok{(}\StringTok{"2015-03-18"}\NormalTok{)}
\NormalTok{mydatetime <-}\StringTok{ }\KeywordTok{ymd_hm}\NormalTok{(}\StringTok{"2011-8-11 16:00"}\NormalTok{)}

\CommentTok{# A few examples:}

\CommentTok{# Convert to character}
\KeywordTok{as.character}\NormalTok{(mynum)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "1001"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as.character}\NormalTok{(myfac)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "280" "400" "650"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Convert to numeric}
\CommentTok{# Note that one missing value is created}
\KeywordTok{as.numeric}\NormalTok{(mychar)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: NAs introduced by coercion
\end{verbatim}

\begin{verbatim}
## [1] 1001   NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Warning!!!}
\CommentTok{# When converting from a factor to numeric, first convert to character}
\CommentTok{# !!!}
\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{as.character}\NormalTok{(myfac))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 280 400 650
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Convert to Date}
\KeywordTok{as.Date}\NormalTok{(mydatetime)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2011-08-11"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Convert to factor}
\KeywordTok{as.factor}\NormalTok{(mylog)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE  FALSE FALSE TRUE 
## Levels: FALSE TRUE
\end{verbatim}

\BeginKnitrBlock{rmdcaution}
When converting a factor to numeric (i.e.~when the factor labels can be converted to numeric values), first convert it to character: \texttt{x\ \textless{}-\ as.numeric(as.character(somefactor))}. The reason for this is that factor variables are internally stored as integer numbers, referring to the \emph{levels} of the factor.
\EndKnitrBlock{rmdcaution}

\hypertarget{summarizing-dataframes}{%
\section{Summarizing dataframes}\label{summarizing-dataframes}}

There are a few useful functions to print general summaries of a dataframe, to see which variables are included, what types of data they contain, and so on. We already looked at \texttt{summary} and \texttt{str} in Section \ref{dataframes}.

Two more very useful functions are from the \texttt{Hmisc} package. The first, \texttt{describe}, is much like \texttt{summary}, but offers slightly more sophisticated statistics. The second, \texttt{contents}, is similar to \texttt{str}, but does a very nice job of summarizing the \texttt{factor} variables in your dataframe, prints the number of missing variables, the number of rows, and so on.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Load data}
\KeywordTok{data}\NormalTok{(pupae)}

\CommentTok{# Make sure CO2_treatment is a factor (it will be read as a number)}
\NormalTok{pupae}\OperatorTok{$}\NormalTok{CO2_treatment <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(pupae}\OperatorTok{$}\NormalTok{CO2_treatment)}

\CommentTok{# Show contents:}
\KeywordTok{library}\NormalTok{(Hmisc)  }
\KeywordTok{contents}\NormalTok{(pupae)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Data frame:pupae 84 observations and 5 variables    Maximum # NAs:6
## 
## 
##               Levels Storage NAs
## T_treatment        2 integer   0
## CO2_treatment      2 integer   0
## Gender               integer   6
## PupalWeight           double   0
## Frass                 double   1
## 
## +-------------+----------------+
## |Variable     |Levels          |
## +-------------+----------------+
## |T_treatment  |ambient,elevated|
## +-------------+----------------+
## |CO2_treatment|280,400         |
## +-------------+----------------+
\end{verbatim}

Here, \texttt{storage} refers to the internal storage type of the variable: note that the factor variables are stored as `integer', and other numbers as `double' (this refers to the precision of the number).

\hypertarget{tapplyaggregate}{%
\subsection{Making summary tables}\label{tapplyaggregate}}

\hypertarget{tapply}{%
\subsubsection{\texorpdfstring{Summarizing vectors with \texttt{tapply}}{Summarizing vectors with tapply}}\label{tapply}}

If we have the following dataset called \texttt{plantdat},

\includegraphics[width=0.33\linewidth]{screenshots/exampledata}

and execute the command

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{with}\NormalTok{(plantdat, }\KeywordTok{tapply}\NormalTok{(Plantbiomass, Treatment, mean))}
\end{Highlighting}
\end{Shaded}

we get the result

\includegraphics[width=0.33\linewidth]{screenshots/tapplyresult}

Note that the result is a \texttt{vector} (elements of a vector can have names, like columns of a dataframe).

If we have the following dataset called \texttt{plantdat2},

\includegraphics[width=0.33\linewidth]{screenshots/exampledatalarger}

and execute the command

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{with}\NormalTok{(plantdat2, }\KeywordTok{tapply}\NormalTok{(Plantbiomass, }\KeywordTok{list}\NormalTok{(Species, Treatment), mean))}
\end{Highlighting}
\end{Shaded}

we get the result

\includegraphics[width=0.33\linewidth]{screenshots/tapplyresultlarger}

Note that the result here is a \texttt{matrix}, where \texttt{A} and \texttt{B}, the species codes, are the rownames of this matrix.

Often, you want to summarize a variable by the levels of another variable. For example, in the \texttt{rain} data, the \texttt{Rain} variable gives daily values, but we might want to calculate annual sums,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Read data}
\KeywordTok{data}\NormalTok{(rain)}

\CommentTok{# Annual rain totals.}
\KeywordTok{with}\NormalTok{(rain, }\KeywordTok{tapply}\NormalTok{(Rain, Year, }\DataTypeTok{FUN=}\NormalTok{sum))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   1996   1997   1998   1999   2000   2001   2002   2003   2004   2005 
##  717.2  640.4  905.4 1021.3  693.5  791.5  645.9  691.8  709.5  678.2
\end{verbatim}

The \texttt{tapply} function applies a function (\texttt{sum}) to a vector (\texttt{Rain}), that is split into chunks depending on another variable (\texttt{Year}).

We can also use the \texttt{tapply} function on more than one variable at a time. Consider these examples on the \texttt{pupae} data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Average pupal weight by CO2 and T treatment:}
\KeywordTok{with}\NormalTok{(pupae, }\KeywordTok{tapply}\NormalTok{(PupalWeight, }\KeywordTok{list}\NormalTok{(CO2_treatment, T_treatment), }\DataTypeTok{FUN=}\NormalTok{mean))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       ambient elevated
## 280 0.2900000  0.30492
## 400 0.3419565  0.29900
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Further split the averages, by gender of the pupae.}
\KeywordTok{with}\NormalTok{(pupae, }\KeywordTok{tapply}\NormalTok{(PupalWeight, }\KeywordTok{list}\NormalTok{(CO2_treatment, T_treatment, Gender), }\DataTypeTok{FUN=}\NormalTok{mean))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## , , 0
## 
##      ambient  elevated
## 280 0.251625 0.2700000
## 400 0.304000 0.2687143
## 
## , , 1
## 
##       ambient  elevated
## 280 0.3406000 0.3386364
## 400 0.3568333 0.3692857
\end{verbatim}

As the examples show, the \texttt{tapply} function produces summary tables by one or more factors. The resulting object is either a vector (when using one factor), or a matrix (as in the examples using the pupae data).

The limitations of \texttt{tapply} are that you can only summarize one variable at a time, and that the result is not a dataframe.

The main advantage of \texttt{tapply} is that we can use it as input to \texttt{barplot}, as the following example demonstrates (Fig. fig:pupgroupedbar\})

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Pupal weight by CO2 and Gender. Result is a matrix.}
\NormalTok{pupm <-}\StringTok{ }\KeywordTok{with}\NormalTok{(pupae, }\KeywordTok{tapply}\NormalTok{(PupalWeight, }\KeywordTok{list}\NormalTok{(CO2_treatment,Gender), }
\NormalTok{                           mean, }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{))}

\CommentTok{# When barplot is provided a matrix, it makes a grouped barplot.}
\CommentTok{# We specify xlim to make some room for the legend.}
\KeywordTok{barplot}\NormalTok{(pupm, }\DataTypeTok{beside=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{legend.text=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{xlim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{8}\NormalTok{),}
        \DataTypeTok{xlab=}\StringTok{"Gender"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Pupal weight"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{02-dataskills_files/figure-latex/pupgroupedbar-1.pdf}
\caption{\label{fig:pupgroupedbar}A grouped barplot of average pupal weight by CO2 and Gender for the pupae dataset. This is easily achieved via the use of tapply.}
\end{figure}

\hypertarget{summaryby}{%
\subsubsection{\texorpdfstring{Quick summary tables with \texttt{summaryBy}}{Quick summary tables with summaryBy}}\label{summaryby}}

If we have the following dataset called \texttt{plantdat},

\includegraphics[width=0.33\linewidth]{screenshots/exampledata}

and execute the command

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(doBy)}
\KeywordTok{summaryBy}\NormalTok{(Plantbiomass }\OperatorTok{~}\StringTok{ }\NormalTok{treatment, }\DataTypeTok{FUN=}\NormalTok{mean, }\DataTypeTok{data=}\NormalTok{plantdat)}
\end{Highlighting}
\end{Shaded}

we get the result

\includegraphics[width=0.33\linewidth]{screenshots/summarybyresult}

Note that the result here is a \texttt{dataframe}.

If we have the following dataset called \texttt{plantdat2},

\includegraphics[width=0.33\linewidth]{screenshots/exampledatalarger}

and execute the command

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summaryBy}\NormalTok{(Plantbiomass }\OperatorTok{~}\StringTok{ }\NormalTok{Species }\OperatorTok{+}\StringTok{ }\NormalTok{Treatment, }\DataTypeTok{FUN=}\NormalTok{mean, }\DataTypeTok{data=}\NormalTok{dfr)}
\end{Highlighting}
\end{Shaded}

we get the result

\includegraphics[width=0.33\linewidth]{screenshots/summarybyresultlarger}

Note that the result here is a \texttt{dataframe}.

In practice, it is often useful to make summary tables of multiple variables at once, and to end up with a dataframe. In this book we first use \texttt{summaryBy}, from the \texttt{doBy} package, to achieve this.

With \texttt{summaryBy}, we can generate multiple summaries (mean, standard deviation, etc.) on more than one variable in a dataframe at once. We can use a convenient formula interface for this. It is of the form,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summaryBy}\NormalTok{(Yvar1 }\OperatorTok{+}\StringTok{ }\NormalTok{Yvar2 }\OperatorTok{~}\StringTok{ }\NormalTok{Groupvar1 }\OperatorTok{+}\StringTok{ }\NormalTok{Groupvar2, }\DataTypeTok{FUN=}\KeywordTok{c}\NormalTok{(mean,sd), }\DataTypeTok{data=}\NormalTok{mydata)}
\end{Highlighting}
\end{Shaded}

where we summarize the (numeric) variables \texttt{Yvar1} and \texttt{Yvar2} by all combinations of the (factor) variables \texttt{Groupvar1} and \texttt{Groupvar2}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Load the doBy package}
\KeywordTok{library}\NormalTok{(doBy)}

\CommentTok{# read pupae data if you have not already}
\KeywordTok{data}\NormalTok{(pupae)}

\CommentTok{# Get mean and standard deviation of Frass by CO2 and T treatments}
\KeywordTok{summaryBy}\NormalTok{(Frass }\OperatorTok{~}\StringTok{ }\NormalTok{CO2_treatment }\OperatorTok{+}\StringTok{ }\NormalTok{T_treatment,}
          \DataTypeTok{data=}\NormalTok{pupae, }\DataTypeTok{FUN=}\KeywordTok{c}\NormalTok{(mean,sd))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   CO2_treatment T_treatment Frass.mean  Frass.sd
## 1           280     ambient         NA        NA
## 2           280    elevated   1.479520 0.2387150
## 3           400     ambient   2.121783 0.4145402
## 4           400    elevated   1.912045 0.3597471
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Note that there is a missing value. We can specify na.rm=TRUE,}
\CommentTok{# which will be passed to both mean() and sd(). It works because those}
\CommentTok{# functions recognize that argument (i.e. na.rm is NOT an argument of }
\CommentTok{# summaryBy itself!)}
\KeywordTok{summaryBy}\NormalTok{(Frass }\OperatorTok{~}\StringTok{ }\NormalTok{CO2_treatment }\OperatorTok{+}\StringTok{ }\NormalTok{T_treatment,}
          \DataTypeTok{data=}\NormalTok{pupae, }\DataTypeTok{FUN=}\KeywordTok{c}\NormalTok{(mean,sd), }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   CO2_treatment T_treatment Frass.mean  Frass.sd
## 1           280     ambient   1.953923 0.4015635
## 2           280    elevated   1.479520 0.2387150
## 3           400     ambient   2.121783 0.4145402
## 4           400    elevated   1.912045 0.3597471
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# However, if we use a function that does not recognize it, we first have to}
\CommentTok{# exclude all missing values before making a summary table, like this:}
\NormalTok{pupae_nona <-}\StringTok{ }\NormalTok{pupae[}\KeywordTok{complete.cases}\NormalTok{(pupae),]}

\CommentTok{# Get mean and standard deviation for}
\CommentTok{# the pupae data (Pupal weight and Frass), by CO2 and T treatment.}
\CommentTok{# Note that length() does not recognize na.rm (see ?length), which is}
\CommentTok{# why we have excluded any NA from pupae first.}
\KeywordTok{summaryBy}\NormalTok{(PupalWeight}\OperatorTok{+}\NormalTok{Frass }\OperatorTok{~}\StringTok{ }\NormalTok{CO2_treatment }\OperatorTok{+}\StringTok{ }\NormalTok{T_treatment,}
          \DataTypeTok{data=}\NormalTok{pupae_nona,}
          \DataTypeTok{FUN=}\KeywordTok{c}\NormalTok{(mean,sd,length))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   CO2_treatment T_treatment PupalWeight.mean Frass.mean PupalWeight.sd
## 1           280     ambient        0.2912500   1.957333     0.04895847
## 2           280    elevated        0.3014583   1.473167     0.05921000
## 3           400     ambient        0.3357000   2.103250     0.05886479
## 4           400    elevated        0.3022381   1.931000     0.06602189
##    Frass.sd PupalWeight.length Frass.length
## 1 0.4192227                 12           12
## 2 0.2416805                 24           24
## 3 0.4186310                 20           20
## 4 0.3571969                 21           21
\end{verbatim}

You can also use any function that returns a vector of results. In the following example we calculate the 5\% and 95\% quantiles of all numeric variables in the allometry dataset. To do this, use \texttt{.} for the left-hand side of the formula.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# . ~ species means 'all numeric variables by species'.}
\CommentTok{# Extra arguments to the function used (in this case quantile) can be set here as well,}
\CommentTok{# they will be passed to that function (see ?quantile).}
\KeywordTok{summaryBy}\NormalTok{(. }\OperatorTok{~}\StringTok{ }\NormalTok{species, }\DataTypeTok{data=}\NormalTok{allometry, }\DataTypeTok{FUN=}\NormalTok{quantile, }\DataTypeTok{probs=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.05}\NormalTok{, }\FloatTok{0.95}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   species diameter.5% diameter.95% height.5% height.95% leafarea.5%
## 1    PIMO      8.1900      70.9150  5.373000     44.675    7.540916
## 2    PIPO     11.4555      69.1300  5.903499     39.192   10.040843
## 3    PSME      6.1635      56.5385  5.276000     32.602    4.988747
##   leafarea.95% branchmass.5% branchmass.95%
## 1     380.3984      4.283342       333.6408
## 2     250.1295      7.591966       655.1097
## 3     337.5367      3.515638       403.7902
\end{verbatim}

\hypertarget{dplyr}{%
\subsubsection{\texorpdfstring{Summarizing dataframes with \texttt{dplyr}}{Summarizing dataframes with dplyr}}\label{dplyr}}

We started with the \texttt{summaryBy} package, since it is so easy to use. A more modern and popular approach is to use \texttt{dplyr} for all your dataframe summarizing needs. The main advantage is that \texttt{dplyr} is very, very fast. For datasets with \textgreater{} hundreds of thousands of rows, you will notice an incredible speed increase. For millions of rows, you really have to use \texttt{dplyr} (or \texttt{data.table}, but we don't cover that package in this book).

Making summary tables as we did in the above examples requires two steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Group your dataframe by one or more factor variables
\item
  Apply summarizing functions to each of the groups
\end{enumerate}

As is the norm, we use the pipe operator (\texttt{\%\textgreater{}\%}) to keep the steps apart. Here is a simple example to get started.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr)}

\KeywordTok{group_by}\NormalTok{(pupae, CO2_treatment, T_treatment) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{Frass_mean =} \KeywordTok{mean}\NormalTok{(Frass, }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{),}
            \DataTypeTok{Frass_sd =} \KeywordTok{sd}\NormalTok{(Frass, }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 4
## # Groups:   CO2_treatment [2]
##   CO2_treatment T_treatment Frass_mean Frass_sd
##           <int> <fct>            <dbl>    <dbl>
## 1           280 ambient           1.95    0.402
## 2           280 elevated          1.48    0.239
## 3           400 ambient           2.12    0.415
## 4           400 elevated          1.91    0.360
\end{verbatim}

I used \texttt{as.data.frame} at the end, so we arrive at an actual dataframe, not a tibble (only for the reason so you can compare the output to the previous examples). The \texttt{dplyr} package (and others) always produce tibbles, which are really just dataframes but with some adjusted printing methods.

In \texttt{summarize} you can specify each of the new variables that should be produced, in this case giving mean and standard deviation of Frass. If we want to apply a number of functions over many variables, we can use \texttt{summarize\_at}, like so:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{group_by}\NormalTok{(pupae, CO2_treatment, T_treatment) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize_at}\NormalTok{(}\DataTypeTok{.vars =} \KeywordTok{c}\NormalTok{(}\StringTok{"Frass"}\NormalTok{, }\StringTok{"PupalWeight"}\NormalTok{),}
                \DataTypeTok{.funs =} \KeywordTok{c}\NormalTok{(}\StringTok{"mean"}\NormalTok{, }\StringTok{"sd"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 6
## # Groups:   CO2_treatment [2]
##   CO2_treatment T_treatment Frass_mean PupalWeight_mean Frass_sd
##           <int> <fct>            <dbl>            <dbl>    <dbl>
## 1           280 ambient          NA               0.290  NaN    
## 2           280 elevated          1.48            0.305    0.239
## 3           400 ambient           2.12            0.342    0.415
## 4           400 elevated          1.91            0.299    0.360
## # ... with 1 more variable: PupalWeight_sd <dbl>
\end{verbatim}

The result is identical to our last example with \texttt{summaryBy}.

Let's look at a more advanced example using weather data collected at the Hawkesbury Forest Experiment in 2008. The data given are in half-hourly time steps. It is a reasonable request to provide data as daily averages (for temperature) and daily sums (for precipitation).

The following code produces a daily weather dataset, and Fig. \ref{fig:hfemetaggregate}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Read data, convert DateTime field to a proper Datetime class using}
\CommentTok{# lubridate's mdy_hm function, and add a Date column with as.Date.}
\CommentTok{# Instead of loading packages, we use :: in the example below to make sure}
\CommentTok{# the functions are used from the right package.}
\KeywordTok{data}\NormalTok{(hfemet2008)}

\NormalTok{hfemet_agg <-}\StringTok{ }\NormalTok{hfemet2008 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{DateTime =}\NormalTok{ lubridate}\OperatorTok{::}\KeywordTok{mdy_hm}\NormalTok{(DateTime),}
         \DataTypeTok{Date =} \KeywordTok{as.Date}\NormalTok{(DateTime)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(Date) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{Rain =} \KeywordTok{sum}\NormalTok{(Rain),}
            \DataTypeTok{Tair =} \KeywordTok{mean}\NormalTok{(Tair))}

\CommentTok{# A simple plot of daily rainfall.}
\KeywordTok{library}\NormalTok{(ggplot2)}
\KeywordTok{ggplot}\NormalTok{(hfemet_agg, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Date, }\DataTypeTok{y =}\NormalTok{ Rain)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{stat=}\StringTok{"identity"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{02-dataskills_files/figure-latex/hfemetaggregate-1.pdf}
\caption{\label{fig:hfemetaggregate}Daily rainfall at the HFE in 2008}
\end{figure}

\hypertarget{using-padr-to-aggregate-timeseries-data}{%
\subsubsection{\texorpdfstring{Using \texttt{padr} to aggregate timeseries data}{Using padr to aggregate timeseries data}}\label{using-padr-to-aggregate-timeseries-data}}

In the previous example we saw a quick and concise methods to aggregate and filter a dataframe that includes a single date-time column (here roughly referred to as timeseries data). In the example, we calculated daily totals and averages, but what if we want to aggregate by other timespans, like two-week intervals, 6 months, or 15 minutes? The \texttt{padr} package is very convenient for this sort of mutation.

The following example uses \texttt{padr} in combination with several functions from \texttt{dplyr} to make a table of total rainfall in 4 hour increments for one day, using the \texttt{hfemet2008} dataset.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr)}
\KeywordTok{library}\NormalTok{(padr)}
\KeywordTok{library}\NormalTok{(lubridate)}

\CommentTok{# From the lgrdata package}
\KeywordTok{data}\NormalTok{(hfemet2008)}

\KeywordTok{mutate}\NormalTok{(hfemet2008, }\DataTypeTok{DateTime =} \KeywordTok{mdy_hm}\NormalTok{(DateTime)) }\OperatorTok{%>%}\StringTok{ }\CommentTok{# convert to proper DateTime}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\KeywordTok{as.Date}\NormalTok{(DateTime) }\OperatorTok{==}\StringTok{ "2008-6-3"}\NormalTok{) }\OperatorTok{%>%}\StringTok{       }\CommentTok{# select a single day}
\StringTok{  }\KeywordTok{thicken}\NormalTok{(}\StringTok{"4 hours"}\NormalTok{, }\DataTypeTok{round=}\StringTok{"down"}\NormalTok{) }\OperatorTok{%>%}\StringTok{              }\CommentTok{# add datetime in 4hour steps}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(DateTime_}\DecValTok{4}\NormalTok{_hour) }\OperatorTok{%>%}\StringTok{                     }\CommentTok{# set grouping variable}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{Rain =} \KeywordTok{sum}\NormalTok{(Rain)) }\OperatorTok{%>%}\StringTok{                   }\CommentTok{# sum over the grouping variable}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\DataTypeTok{DateTime =}\NormalTok{ DateTime_}\DecValTok{4}\NormalTok{_hour, Rain)          }\CommentTok{# show two variables}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   DateTime             Rain
##   <dttm>              <dbl>
## 1 2008-06-03 00:00:00   2.4
## 2 2008-06-03 04:00:00   1.8
## 3 2008-06-03 08:00:00  11.8
## 4 2008-06-03 12:00:00   5.6
## 5 2008-06-03 16:00:00   6.6
## 6 2008-06-03 20:00:00  26.4
\end{verbatim}

\hypertarget{xtabs}{%
\subsection{Tables of counts}\label{xtabs}}

It is often useful to count the number of observations by one or more multiple factors. One option is to use \texttt{tapply} or \texttt{summaryBy} in combination with the \texttt{length} function. A much better alternative is to use the \texttt{xtabs} and \texttt{ftable} functions, in addition to the simple use of \texttt{table}. Alternatively, \texttt{dplyr} provides a \texttt{count} function. We will look at both options.

Consider these examples using the Titanic data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Read titanic data}
\KeywordTok{data}\NormalTok{(titanic)}

\CommentTok{# Count observations by passenger class}
\KeywordTok{table}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{PClass)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 1st 2nd 3rd 
## 322 280 711
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# With more grouping variables, it is more convenient to use xtabs.}
\CommentTok{# Count observations by combinations of passenger class, sex, and whether they survived:}
\KeywordTok{xtabs}\NormalTok{( }\OperatorTok{~}\StringTok{ }\NormalTok{PClass }\OperatorTok{+}\StringTok{ }\NormalTok{Sex }\OperatorTok{+}\StringTok{ }\NormalTok{Survived, }\DataTypeTok{data=}\NormalTok{titanic)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## , , Survived = 0
## 
##       Sex
## PClass female male
##    1st      9  120
##    2nd     13  148
##    3rd    132  441
## 
## , , Survived = 1
## 
##       Sex
## PClass female male
##    1st    134   59
##    2nd     94   25
##    3rd     80   58
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# The previous output is hard to read, consider using ftable on the result:}
\KeywordTok{ftable}\NormalTok{(}\KeywordTok{xtabs}\NormalTok{( }\OperatorTok{~}\StringTok{ }\NormalTok{PClass }\OperatorTok{+}\StringTok{ }\NormalTok{Sex }\OperatorTok{+}\StringTok{ }\NormalTok{Survived, }\DataTypeTok{data=}\NormalTok{titanic))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##               Survived   0   1
## PClass Sex                    
## 1st    female            9 134
##        male            120  59
## 2nd    female           13  94
##        male            148  25
## 3rd    female          132  80
##        male            441  58
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Using dplyr, the result is a dataframe (actually, a tibble)}
\KeywordTok{library}\NormalTok{(dplyr)}
\NormalTok{titanic }\OperatorTok{%>%}\StringTok{ }\KeywordTok{count}\NormalTok{(PClass, Sex, Survived)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 12 x 4
##    PClass Sex    Survived     n
##    <fct>  <fct>     <int> <int>
##  1 1st    female        0     9
##  2 1st    female        1   134
##  3 1st    male          0   120
##  4 1st    male          1    59
##  5 2nd    female        0    13
##  6 2nd    female        1    94
##  7 2nd    male          0   148
##  8 2nd    male          1    25
##  9 3rd    female        0   132
## 10 3rd    female        1    80
## 11 3rd    male          0   441
## 12 3rd    male          1    58
\end{verbatim}

\hypertarget{summaryvars}{%
\subsection{Adding summary variables to dataframes}\label{summaryvars}}

We saw how \texttt{tapply} can make simple tables of averages (or totals, or other functions) of some variable by the levels of one or more factor variables. The result of \texttt{tapply} is typically a vector with a length equal to the number of levels of the factor you summarized by (see examples in Section \ref{tapply}).

Consider the \texttt{allometry} dataset, which includes tree height for three species. Suppose you want to add a new variable `MaxHeight', that is the maximum tree height observed per species. We can use \texttt{ave} to achieve this:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Read data}
\NormalTok{allom <-}\StringTok{ }\NormalTok{allometry }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{MaxHeight =} \KeywordTok{ave}\NormalTok{(height, species, }\DataTypeTok{FUN=}\NormalTok{max))}

\CommentTok{# Look at first few rows (or just type allom to see whole dataset)}
\KeywordTok{head}\NormalTok{(allom)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   species diameter height   leafarea branchmass treeSizeClass MaxHeight
## 1    PSME    54.61  27.04 338.485622  410.24638         large      33.3
## 2    PSME    34.80  27.42 122.157864   83.65030        medium      33.3
## 3    PSME    24.89  21.23   3.958274    3.51270         small      33.3
## 4    PSME    28.70  24.96  86.350653   73.13027        medium      33.3
## 5    PSME    34.80  29.99  63.350906   62.39044        medium      33.3
## 6    PSME    37.85  28.07  61.372765   53.86594        medium      33.3
\end{verbatim}

Note that you can use any function in place of \texttt{max}, as long as that function can take a vector as an argument, and returns a single number.

\BeginKnitrBlock{rmdtry}
If you want results similar to \texttt{ave}, you can use \texttt{summaryBy} with the argument \texttt{full.dimension=TRUE}. Try \texttt{summaryBy} on the \texttt{pupae} dataset with that argument set, and compare the result to \texttt{full.dimension=FALSE}, which is the default.
\EndKnitrBlock{rmdtry}

\hypertarget{reorder}{%
\subsection{Reordering factor levels based on a summary variable}\label{reorder}}

It is often useful to tabulate your data in a meaningful order. We saw that, when using \texttt{summaryBy}, \texttt{tapply} or similar functions, that the results are always in the order of your factor levels. Recall that the default order is alphabetical. This is rarely what you want.

You can reorder the factor levels by some summary variable. For example,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Reorder factor levels for 'Manufacturer' in the cereal data }
\CommentTok{# by the mean amount of sodium.}

\CommentTok{# Read data, show default (alphabetical) levels:}
\KeywordTok{data}\NormalTok{(cereals)}
\KeywordTok{levels}\NormalTok{(cereals}\OperatorTok{$}\NormalTok{Manufacturer)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "A" "G" "K" "N" "P" "Q" "R"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Now reorder:}
\NormalTok{cereals <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(cereals, }
                 \DataTypeTok{Manufacturer =} \KeywordTok{reorder}\NormalTok{(Manufacturer, sodium, }
\NormalTok{                                        median, }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{))}

\CommentTok{# And inspect the new levels}
\KeywordTok{levels}\NormalTok{(cereals}\OperatorTok{$}\NormalTok{Manufacturer)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "A" "N" "Q" "P" "K" "G" "R"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Tables are now printed in order:}
\KeywordTok{with}\NormalTok{(cereals, }\KeywordTok{tapply}\NormalTok{(sodium, Manufacturer, median))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     A     N     Q     P     K     G     R 
##   0.0   7.5  75.0 160.0 170.0 200.0 200.0
\end{verbatim}

This trick comes in handy when making barplots; it is customary to plot them in ascending order if there is no specific order to the factor levels, as in this example.

The following code produces Fig. \ref{fig:coweetabar}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Here we read the data, add a reordered factor variable,}
\CommentTok{# and continue with making the summary table used in the plot.}
\KeywordTok{data}\NormalTok{(coweeta)}

\NormalTok{coweeta_table <-}\StringTok{ }\NormalTok{coweeta }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{species =} \KeywordTok{reorder}\NormalTok{(species, height, mean, }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(species) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{height_mean =} \KeywordTok{mean}\NormalTok{(height, }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{),}
            \DataTypeTok{height_sd =} \KeywordTok{sd}\NormalTok{(height, }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{))}

\KeywordTok{ggplot}\NormalTok{(coweeta_table, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ species, }\DataTypeTok{y =}\NormalTok{ height_mean)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{stat=}\StringTok{"identity"}\NormalTok{, }\DataTypeTok{fill=}\StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_errorbar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{ymin =}\NormalTok{ height_mean }\OperatorTok{-}\StringTok{ }\NormalTok{height_sd,}
                    \DataTypeTok{ymax =}\NormalTok{ height_mean }\OperatorTok{+}\StringTok{ }\NormalTok{height_sd), }\DataTypeTok{width=}\FloatTok{0.2}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{y =} \StringTok{"Height (m)"}\NormalTok{, }\DataTypeTok{x =} \StringTok{"Species"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{02-dataskills_files/figure-latex/coweetabar-1.pdf}
\caption{\label{fig:coweetabar}An ordered barplot for the coweeta tree data (error bars are 1 SD).}
\end{figure}

The above example uses the more modern approach with \texttt{ggplot2} and \texttt{dplyr}, but we can get practically the same result with \texttt{doBy} and \texttt{gplots} - below is the code for comparison (output not shown).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(doBy)}
\NormalTok{coweeta}\OperatorTok{$}\NormalTok{species <-}\StringTok{ }\KeywordTok{with}\NormalTok{(coweeta, }\KeywordTok{reorder}\NormalTok{(species, height, mean, }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{))}
\NormalTok{coweeta_agg <-}\StringTok{ }\KeywordTok{summaryBy}\NormalTok{(height }\OperatorTok{~}\StringTok{ }\NormalTok{species, }\DataTypeTok{data=}\NormalTok{coweeta, }\DataTypeTok{FUN=}\KeywordTok{c}\NormalTok{(mean,sd))}

\CommentTok{# For barplot2, which adds options for error bars}
\KeywordTok{library}\NormalTok{(gplots)}

\CommentTok{# This par setting makes the x-axis labels vertical, so they don't overlap.}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{las=}\DecValTok{2}\NormalTok{)}
\KeywordTok{with}\NormalTok{(coweeta_agg, }\KeywordTok{barplot2}\NormalTok{(height.mean, }\DataTypeTok{names.arg=}\NormalTok{species,}
                           \DataTypeTok{space=}\FloatTok{0.3}\NormalTok{, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{,}\DataTypeTok{plot.grid=}\OtherTok{TRUE}\NormalTok{,}
                           \DataTypeTok{ylab=}\StringTok{"Height (m)"}\NormalTok{,}
                           \DataTypeTok{plot.ci=}\OtherTok{TRUE}\NormalTok{,}
                           \DataTypeTok{ci.l=}\NormalTok{height.mean }\OperatorTok{-}\StringTok{ }\NormalTok{height.sd,}
                           \DataTypeTok{ci.u=}\NormalTok{height.mean }\OperatorTok{+}\StringTok{ }\NormalTok{height.sd))}
\end{Highlighting}
\end{Shaded}

\BeginKnitrBlock{rmdtry}
The above example orders the factor levels by increasing median sodium levels.
Try reversing the factor levels, using the following code after \texttt{reorder}.
\texttt{coweeta\$species\ \textless{}-\ factor(coweeta\$species,\ levels=rev(levels(coweeta\$species)))}
Here we used \texttt{rev} to reverse the levels.
\EndKnitrBlock{rmdtry}

\hypertarget{combining-dataframes}{%
\section{Combining dataframes}\label{combining-dataframes}}

\hypertarget{merge}{%
\subsection{Merging dataframes}\label{merge}}

If we have the following dataset called \texttt{plantdat},

\includegraphics[width=0.33\linewidth]{screenshots/exampledata}

and we have another dataset, that includes the same \texttt{PlantID} variable (but is not necessarily ordered, nor does it have to include values for every plant):

\includegraphics[width=0.33\linewidth]{screenshots/leafnitrogendata}

and execute the command

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{merge}\NormalTok{(plantdat, leafnitrogendata, }\DataTypeTok{by=}\StringTok{"PlantID"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

we get the result

\includegraphics[width=0.33\linewidth]{screenshots/mergeresult}

Note the missing value (\texttt{NA}) for the plant for which no leaf nitrogen data was available.

In many problems, you do not have a single dataset that contains all the measurements you are interested in -- unlike most of the example datasets in this tutorial. Suppose you have two datasets that you would like to combine, or \texttt{merge}. This is straightforward in R, but there are some pitfalls.

Let's start with a common situation when you need to combine two datasets that have a different number of rows.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Two dataframes}
\NormalTok{data1 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{unit=}\KeywordTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{,}\StringTok{"x"}\NormalTok{,}\StringTok{"x"}\NormalTok{,}\StringTok{"y"}\NormalTok{,}\StringTok{"z"}\NormalTok{,}\StringTok{"z"}\NormalTok{),}\DataTypeTok{Time=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{data2 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{unit=}\KeywordTok{c}\NormalTok{(}\StringTok{"y"}\NormalTok{,}\StringTok{"z"}\NormalTok{,}\StringTok{"x"}\NormalTok{), }\DataTypeTok{height=}\KeywordTok{c}\NormalTok{(}\FloatTok{3.4}\NormalTok{,}\FloatTok{5.6}\NormalTok{,}\FloatTok{1.2}\NormalTok{))}

\CommentTok{# Look at the dataframes}
\NormalTok{data1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   unit Time
## 1    x    1
## 2    x    2
## 3    x    3
## 4    y    1
## 5    z    1
## 6    z    2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   unit height
## 1    y    3.4
## 2    z    5.6
## 3    x    1.2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Merge dataframes:}
\NormalTok{combdata <-}\StringTok{ }\KeywordTok{merge}\NormalTok{(data1, data2, }\DataTypeTok{by=}\StringTok{"unit"}\NormalTok{)}

\CommentTok{# Combined data}
\NormalTok{combdata}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   unit Time height
## 1    x    1    1.2
## 2    x    2    1.2
## 3    x    3    1.2
## 4    y    1    3.4
## 5    z    1    5.6
## 6    z    2    5.6
\end{verbatim}

Sometimes, the variable you are merging with has a different name in either dataframe. In that case, you can either rename the variable before merging, or use the following option:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{merge}\NormalTok{(data1, data2, }\DataTypeTok{by.x=}\StringTok{"unit"}\NormalTok{, }\DataTypeTok{by.y=}\StringTok{"item"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Where \texttt{data1} has a variable called `unit', and \texttt{data2} has a variable called `item'.

Other times you need to merge two dataframes with multiple key variables. Consider this example, where two dataframes have measurements on the same units at some of the the same times, but on different variables:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Two dataframes}
\NormalTok{data1 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{unit=}\KeywordTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{,}\StringTok{"x"}\NormalTok{,}\StringTok{"x"}\NormalTok{,}\StringTok{"y"}\NormalTok{,}\StringTok{"y"}\NormalTok{,}\StringTok{"y"}\NormalTok{,}\StringTok{"z"}\NormalTok{,}\StringTok{"z"}\NormalTok{,}\StringTok{"z"}\NormalTok{),}
\DataTypeTok{Time=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{),}
\DataTypeTok{Weight=}\KeywordTok{c}\NormalTok{(}\FloatTok{3.1}\NormalTok{,}\FloatTok{5.2}\NormalTok{,}\FloatTok{6.9}\NormalTok{,}\FloatTok{2.2}\NormalTok{,}\FloatTok{5.1}\NormalTok{,}\FloatTok{7.5}\NormalTok{,}\FloatTok{3.5}\NormalTok{,}\FloatTok{6.1}\NormalTok{,}\FloatTok{8.0}\NormalTok{))}
\NormalTok{data2 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{unit=}\KeywordTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{,}\StringTok{"x"}\NormalTok{,}\StringTok{"y"}\NormalTok{,}\StringTok{"y"}\NormalTok{,}\StringTok{"z"}\NormalTok{,}\StringTok{"z"}\NormalTok{),}
\DataTypeTok{Time=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{),}
\DataTypeTok{Height=}\KeywordTok{c}\NormalTok{(}\FloatTok{12.1}\NormalTok{,}\FloatTok{24.4}\NormalTok{,}\FloatTok{18.0}\NormalTok{,}\FloatTok{30.8}\NormalTok{,}\FloatTok{10.4}\NormalTok{,}\FloatTok{32.9}\NormalTok{))}

\CommentTok{# Look at the dataframes}
\NormalTok{data1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   unit Time Weight
## 1    x    1    3.1
## 2    x    2    5.2
## 3    x    3    6.9
## 4    y    1    2.2
## 5    y    2    5.1
## 6    y    3    7.5
## 7    z    1    3.5
## 8    z    2    6.1
## 9    z    3    8.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   unit Time Height
## 1    x    1   12.1
## 2    x    2   24.4
## 3    y    2   18.0
## 4    y    3   30.8
## 5    z    1   10.4
## 6    z    3   32.9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Merge dataframes:}
\NormalTok{combdata <-}\StringTok{ }\KeywordTok{merge}\NormalTok{(data1, data2, }\DataTypeTok{by=}\KeywordTok{c}\NormalTok{(}\StringTok{"unit"}\NormalTok{,}\StringTok{"Time"}\NormalTok{))}

\CommentTok{# By default, only those times appear in the dataset that have measurements}
\CommentTok{# for both Weight (data1) and Height (data2)}
\NormalTok{combdata}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   unit Time Weight Height
## 1    x    1    3.1   12.1
## 2    x    2    5.2   24.4
## 3    y    2    5.1   18.0
## 4    y    3    7.5   30.8
## 5    z    1    3.5   10.4
## 6    z    3    8.0   32.9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# To include all data, use this command. This produces missing values for some times:}
\KeywordTok{merge}\NormalTok{(data1, data2, }\DataTypeTok{by=}\KeywordTok{c}\NormalTok{(}\StringTok{"unit"}\NormalTok{,}\StringTok{"Time"}\NormalTok{), }\DataTypeTok{all=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   unit Time Weight Height
## 1    x    1    3.1   12.1
## 2    x    2    5.2   24.4
## 3    x    3    6.9     NA
## 4    y    1    2.2     NA
## 5    y    2    5.1   18.0
## 6    y    3    7.5   30.8
## 7    z    1    3.5   10.4
## 8    z    2    6.1     NA
## 9    z    3    8.0   32.9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Compare this result with 'combdata' above!}
\end{Highlighting}
\end{Shaded}

\hypertarget{using-join-from-dplyr}{%
\subsection{\texorpdfstring{Using join from \texttt{dplyr}}{Using join from dplyr}}\label{using-join-from-dplyr}}

We showed how to use the \texttt{merge} function above, which is provided by base R. For larger datasets, it is advisable to use the \texttt{join*} functions from \texttt{dplyr}.

Instead of specifying which rows to keep with arguments \texttt{all.x}, \texttt{all}, etc., \texttt{dplyr} provides several functions that should make some intuitive sense. The table below compares \texttt{merge} and \texttt{join*}.

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.48\columnwidth}\raggedright
\texttt{merge()}\strut
\end{minipage} & \begin{minipage}[b]{0.42\columnwidth}\raggedright
\texttt{dplyr::join*}\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.48\columnwidth}\raggedright
\texttt{merge(dat1,\ dat2,\ all\ =\ FALSE)}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
\texttt{inner\_join(dat1,\ dat2)}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.48\columnwidth}\raggedright
\texttt{merge(dat1,\ dat2,\ all.x\ =\ TRUE)}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
\texttt{left\_join(dat1,\ dat2)}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.48\columnwidth}\raggedright
\texttt{merge(dat1,\ dat2,\ all.y\ =\ TRUE)}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
\texttt{right\_join(dat1,\ dat2)}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.48\columnwidth}\raggedright
\texttt{merge(dat1,\ dat2,\ all\ =\ TRUE)}\strut
\end{minipage} & \begin{minipage}[t]{0.42\columnwidth}\raggedright
\texttt{full\_join(dat1,\ dat2)}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

One other function is provided that has no simple equivalent in base R, \texttt{anti\_join}, which can be used to find all observations that have \emph{no match} between the two datasets. This can be handy for error-checking.

Consider the cereal dataset, which gives measurements of all sorts of contents of cereals. Suppose the measurements for `protein', `vitamins' and `sugars' were all produced by different laboratories, and each lab sent you a separate dataset. To make things worse, some measurements for sugars and vitamins are missing, because samples were lost in those labs.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Read the three datasets given to you from the three different labs:}
\KeywordTok{data}\NormalTok{(cereal1)}
\KeywordTok{data}\NormalTok{(cereal2)}
\KeywordTok{data}\NormalTok{(cereal3)}

\CommentTok{# As always, look at the first few rows of each dataset.}
\KeywordTok{head}\NormalTok{(cereal1, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      Cereal.name protein
## 1 Frosted_Flakes       1
## 2     Product_19       3
## 3  Count_Chocula       1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(cereal2, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     cerealbrand vitamins
## 1    Product_19      100
## 2 Count_Chocula       25
## 3    Wheat_Chex       25
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(cereal3, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             cerealname sugars
## 1       Frosted_Flakes     11
## 2           Product_19      3
## 3 Mueslix_Crispy_Blend     13
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# The name of the variable that ties the datasets together, }
\CommentTok{# the 'cereal name' differs between the datasets, as do the number of rows.}
\CommentTok{# We can use merge() three times, but the data are easiest to merge with dplyr:}
\KeywordTok{library}\NormalTok{(dplyr)}

\NormalTok{cereal_combined <-}\StringTok{ }\KeywordTok{full_join}\NormalTok{(cereal1, cereal2, }\DataTypeTok{by=}\KeywordTok{c}\NormalTok{(}\StringTok{"Cereal.name"}\NormalTok{ =}\StringTok{ "cerealbrand"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{                   }\KeywordTok{full_join}\NormalTok{(cereal3, }\DataTypeTok{by=}\KeywordTok{c}\NormalTok{(}\StringTok{"Cereal.name"}\NormalTok{ =}\StringTok{ "cerealname"}\NormalTok{))}

\NormalTok{cereal_combined}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                  Cereal.name protein vitamins sugars
## 1             Frosted_Flakes       1       NA     11
## 2                 Product_19       3      100      3
## 3              Count_Chocula       1       25     NA
## 4                 Wheat_Chex       3       25     NA
## 5                 Honey-comb       1       25     NA
## 6  Shredded_Wheat_spoon_size       3        0     NA
## 7       Mueslix_Crispy_Blend       3       25     13
## 8          Grape_Nuts_Flakes       3       25      5
## 9    Strawberry_Fruit_Wheats       2       NA      5
## 10                  Cheerios       6       25      1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Note that missing values (NA) have been inserted where some data were not available.}
\end{Highlighting}
\end{Shaded}

\hypertarget{rbind}{%
\subsection{Row-binding dataframes}\label{rbind}}

If we have the following dataset called \texttt{plantdat},

\includegraphics[width=0.33\linewidth]{screenshots/rbindinput}

and we have another dataset (\texttt{plantdatmore}), \emph{with exactly the same columns} (including the names and order of the columns),

\includegraphics[width=0.33\linewidth]{screenshots/moredataforrbind}

and execute the command

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rbind}\NormalTok{(plantdat, plantdatmore)}
\end{Highlighting}
\end{Shaded}

we get the result

\includegraphics[width=0.33\linewidth]{screenshots/rbindresult}

Using \texttt{merge}, we were able to glue dataframes together side-by-side based on one or more `index' variables. Sometimes you have multiple datasets that can be glued together top-to-bottom, for example when you have multiple very similar dataframes. We can use the \texttt{rbind} function, like so:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Some fake data}
\NormalTok{mydata1 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{var1=}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{, }\DataTypeTok{var2=}\DecValTok{5}\OperatorTok{:}\DecValTok{7}\NormalTok{) }
\NormalTok{mydata2 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{var1=}\DecValTok{4}\OperatorTok{:}\DecValTok{6}\NormalTok{, }\DataTypeTok{var2=}\DecValTok{8}\OperatorTok{:}\DecValTok{10}\NormalTok{) }

\CommentTok{# The dataframes have the same column names, in the same order:}
\NormalTok{mydata1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   var1 var2
## 1    1    5
## 2    2    6
## 3    3    7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   var1 var2
## 1    4    8
## 2    5    9
## 3    6   10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# So we can use rbind to row-bind them together:}
\KeywordTok{rbind}\NormalTok{(mydata1, mydata2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   var1 var2
## 1    1    5
## 2    2    6
## 3    3    7
## 4    4    8
## 5    5    9
## 6    6   10
\end{verbatim}

Let's look at the above \texttt{rbind} example again but with a modification where some observations are duplicated between dataframes. This might happen, for example, when working with files containing time-series data and where there is some overlap between the two datasets. The \texttt{union} function from the \texttt{dplyr} package only returns unique observations:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Some fake data}
\NormalTok{mydata1 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{var1=}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{, }\DataTypeTok{var2=}\DecValTok{5}\OperatorTok{:}\DecValTok{7}\NormalTok{) }
\NormalTok{mydata2 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{var1=}\DecValTok{2}\OperatorTok{:}\DecValTok{4}\NormalTok{, }\DataTypeTok{var2=}\DecValTok{6}\OperatorTok{:}\DecValTok{8}\NormalTok{) }

\CommentTok{# The dataframes have the same column names, in the same order:}
\NormalTok{mydata1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   var1 var2
## 1    1    5
## 2    2    6
## 3    3    7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   var1 var2
## 1    2    6
## 2    3    7
## 3    4    8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 'rbind' leads to duplicate observations, 'union' removes these:}
\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{union}\NormalTok{(mydata1, mydata2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   var1 var2
## 1    1    5
## 2    2    6
## 3    3    7
## 4    4    8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rbind}\NormalTok{(mydata1, mydata2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   var1 var2
## 1    1    5
## 2    2    6
## 3    3    7
## 4    2    6
## 5    3    7
## 6    4    8
\end{verbatim}

Sometimes, you want to \texttt{rbind} dataframes together but the column names do not exactly match. One option is to first process the dataframes so that they do match (using subscripting). Or, just use the \texttt{bind\_rows} function from \texttt{dplyr}. Look at this example where we have two dataframes that have only one column in common, but we want to keep all the columns (and fill with \texttt{NA} where necessary),

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Some fake data}
\NormalTok{mydata1 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{index=}\KeywordTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{,}\StringTok{"C"}\NormalTok{), }\DataTypeTok{var1=}\DecValTok{5}\OperatorTok{:}\DecValTok{7}\NormalTok{) }
\NormalTok{mydata2 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{var1=}\DecValTok{8}\OperatorTok{:}\DecValTok{10}\NormalTok{, }\DataTypeTok{species=}\KeywordTok{c}\NormalTok{(}\StringTok{"one"}\NormalTok{,}\StringTok{"two"}\NormalTok{,}\StringTok{"three"}\NormalTok{)) }

\CommentTok{# smartbind the dataframes together}
\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{bind_rows}\NormalTok{(mydata1, mydata2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   index var1 species
## 1     A    5    <NA>
## 2     B    6    <NA>
## 3     C    7    <NA>
## 4  <NA>    8     one
## 5  <NA>    9     two
## 6  <NA>   10   three
\end{verbatim}

\emph{Note:} an equivalent function to bind dataframes side-by-side is \texttt{cbind}, which can be used instead of \texttt{merge} when no index variables are present. However, in this book, the use of \texttt{cbind} is discouraged for dataframes as it can lead to problems that are difficult to fix, and in all practical applications a merge is preferable.

\hypertarget{reshaping}{%
\section{Reshaping data}\label{reshaping}}

\hypertarget{from-wide-to-long}{%
\subsection{From wide to long}\label{from-wide-to-long}}

In the majority of analyses in R, we like to have our data in `long' format (nowadays sometimes called the `tidy' format), where the data for some kind of measurement are in one column, and we have one or more factor variables distinguishing groups like individual, date, treatment, and so on. It is however common encounter data in `wide format', which can be converted to long format by reshaping appropriately.

The first example uses the dutch election data.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(dutchelection)}
\KeywordTok{head}\NormalTok{(dutchelection,}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         Date  VVD PvdA  PVV CDA   SP D66  GL  CU SGP PvdD FiftyPlus
## 1 2012-03-22 22.1 16.8 13.9 9.4 16.8 7.7 4.5 3.3 1.5  2.4       1.1
## 2 2012-04-05 23.6 17.1 13.3 8.8 16.3 8.7 4.1 3.2 1.4  2.0       0.8
## 3 2012-04-19 24.0 17.3 12.0 8.2 17.0 8.8 3.5 3.3 1.6  3.1       0.8
\end{verbatim}

The data include percentage votes for 11 Dutch political parties in a 2012 election, and somewhat intuitively the parties have been ordered as columns (so that each row adds up to ca. 100\%, ignoring some tiny parties). For purposes of analysis, we would like to reshape this dataset to long format, so that we have just columns `Date', `Party', and `Poll'. Right now `Party' is in the column names, and `Poll' represents the polling numbers; the actual data in the cells.

As is often the case, there are many ways to solve this. For most basic reshaping tasks we recommend the \texttt{tidyr} package, however some other methods may be needed for more complex tasks, as we find in further examples below.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyr)}
\CommentTok{# The new dataframe will have a column 'Party' with current columns,}
\CommentTok{# *except* Date (hence the -Date),}
\CommentTok{# and values will be stored in 'Poll'}
\NormalTok{elect_long <-}\StringTok{ }\KeywordTok{gather}\NormalTok{(dutchelection, Party, Poll, }\OperatorTok{-}\NormalTok{Date)}
\KeywordTok{head}\NormalTok{(elect_long,}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         Date Party Poll
## 1 2012-03-22   VVD 22.1
## 2 2012-04-05   VVD 23.6
## 3 2012-04-19   VVD 24.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Identical results can be had with melt() from reshape2,}
\CommentTok{# a function which otherwise includes more options.}
\CommentTok{# See `?melt.data.frame` for more options (not `?melt`, }
\CommentTok{# which is the generic function).}
\KeywordTok{library}\NormalTok{(reshape2)}
\NormalTok{elect_long <-}\StringTok{ }\KeywordTok{melt}\NormalTok{(dutchelection, }\DataTypeTok{variable.name=}\StringTok{"Party"}\NormalTok{, }\DataTypeTok{value.name=}\StringTok{"Poll"}\NormalTok{, }\DataTypeTok{id.vars=}\StringTok{"Date"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The advantage of \texttt{melt} is that we can include more than one ID variables, like in the following example. This example also shows the common need for some text processing after reshaping.

In this simple dataset, length of feet and hands was measured on two persons on three consecutive days. We want to reshape it to end up with columns `Day', `Person', `Length' and `BodyPart' (feet or hands).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{Day=}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{, }\DataTypeTok{each=}\DecValTok{2}\NormalTok{), }\DataTypeTok{Person=}\KeywordTok{rep}\NormalTok{(letters[}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{], }\DecValTok{3}\NormalTok{), }
                  \DataTypeTok{Length.feet =} \KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{), }\DecValTok{3}\NormalTok{),}
                  \DataTypeTok{Length.hands=}\KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{),}\DecValTok{3}\NormalTok{))}
\NormalTok{dat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Day Person Length.feet Length.hands
## 1   1      a           2            3
## 2   1      b           3            4
## 3   2      a           2            3
## 4   2      b           3            4
## 5   3      a           2            3
## 6   3      b           3            4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Now reshape to long format, using melt.data.frame}
\NormalTok{dat_long <-}\StringTok{ }\KeywordTok{melt}\NormalTok{(dat, }\DataTypeTok{id.vars=}\KeywordTok{c}\NormalTok{(}\StringTok{"Day"}\NormalTok{,}\StringTok{"Person"}\NormalTok{), }\DataTypeTok{value.name=}\StringTok{"Length"}\NormalTok{, }
    \DataTypeTok{variable.name=}\StringTok{"BodyPart"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{BodyPart =} \KeywordTok{gsub}\NormalTok{(}\StringTok{"Length."}\NormalTok{, }\StringTok{""}\NormalTok{, BodyPart))}

\NormalTok{dat_long}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Day Person BodyPart Length
## 1    1      a     feet      2
## 2    1      b     feet      3
## 3    2      a     feet      2
## 4    2      b     feet      3
## 5    3      a     feet      2
## 6    3      b     feet      3
## 7    1      a    hands      3
## 8    1      b    hands      4
## 9    2      a    hands      3
## 10   2      b    hands      4
## 11   3      a    hands      3
## 12   3      b    hands      4
\end{verbatim}

\hypertarget{from-long-to-wide}{%
\subsection{From long to wide}\label{from-long-to-wide}}

Occasionally we like to use wide format, where groups of data are placed next to each other instead of on top of each other. For the first example consider this simple dataset with a set of questions asked to two persons,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{survey <-}\StringTok{ }\KeywordTok{read.table}\NormalTok{(}\DataTypeTok{text=}\StringTok{"user question    answer}
\StringTok{a   question_1  hi}
\StringTok{a   question_2  hey}
\StringTok{a   question_3  oh}
\StringTok{a   question_4  no}
\StringTok{a   question_5  yes}
\StringTok{a   question_6  obv}
\StringTok{b   question_1  cool}
\StringTok{b   question_2  good}
\StringTok{b   question_3  yes}
\StringTok{b   question_4  sweet}
\StringTok{b   question_5  wow}
\StringTok{b   question_6  no"}\NormalTok{, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{)}

\NormalTok{survey}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    user   question answer
## 1     a question_1     hi
## 2     a question_2    hey
## 3     a question_3     oh
## 4     a question_4     no
## 5     a question_5    yes
## 6     a question_6    obv
## 7     b question_1   cool
## 8     b question_2   good
## 9     b question_3    yes
## 10    b question_4  sweet
## 11    b question_5    wow
## 12    b question_6     no
\end{verbatim}

In this case we actually want to have all data for each `user' in a single row, thus creating columns `question\_1', `question\_2' and so on. The first solution uses \texttt{spread} from \texttt{tidyr}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyr)}
\KeywordTok{spread}\NormalTok{(survey, question, answer)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   user question_1 question_2 question_3 question_4 question_5 question_6
## 1    a         hi        hey         oh         no        yes        obv
## 2    b       cool       good        yes      sweet        wow         no
\end{verbatim}

The second solution uses \texttt{dcast} from \texttt{reshape2}. I show this solution because unlike \texttt{spread}, \texttt{dcast} can be used for more complicated reshaping problems.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(reshape2)}
\KeywordTok{dcast}\NormalTok{(survey, user }\OperatorTok{~}\StringTok{ }\NormalTok{question, }\DataTypeTok{value.var=}\StringTok{"answer"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   user question_1 question_2 question_3 question_4 question_5 question_6
## 1    a         hi        hey         oh         no        yes        obv
## 2    b       cool       good        yes      sweet        wow         no
\end{verbatim}

Here, the formula indicates `user goes in rows, question in columns', and \texttt{value.var} is the name of the variable used to populate the cells.

For the second, more complex, example we use a small version of the \texttt{eucface\_gasexchange} dataset, which includes measurements of photosynthesis (\texttt{Photo}) on two experimental plots (\texttt{Plot}) on three Dates (\texttt{Date}), under two experimental treatments (\texttt{treatment}). Clearly we have multiple levels of nesting of our data, and each of these nesting levels is represented by a different variable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gas <-}\StringTok{ }\KeywordTok{read.table}\NormalTok{(}\DataTypeTok{text=}\StringTok{"Date    Plot    treatment   Photo}
\StringTok{A   1   Amb 14.4}
\StringTok{A   1   Ele 16.3}
\StringTok{A   2   Amb 17.8}
\StringTok{A   2   Ele 13.3}
\StringTok{B   1   Amb 16.4}
\StringTok{B   1   Ele 19}
\StringTok{B   2   Amb 15}
\StringTok{B   2   Ele 10.8}
\StringTok{C   1   Amb 17.5}
\StringTok{C   1   Ele 19.8}
\StringTok{C   2   Amb 13.5}
\StringTok{C   2   Ele 12.1}
\StringTok{"}\NormalTok{, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now we have two variables that describe which measurements `belong together' (experimental plot, and treatment). We can no longer use \texttt{spread} (which uses just one of those variables), but \texttt{dcast} does work nicely with multiple groupings:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dcast}\NormalTok{(gas, Date }\OperatorTok{+}\StringTok{ }\NormalTok{Plot }\OperatorTok{~}\StringTok{ }\NormalTok{treatment, }\DataTypeTok{value.var=}\StringTok{"Photo"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Date Plot  Amb  Ele
## 1    A    1 14.4 16.3
## 2    A    2 17.8 13.3
## 3    B    1 16.4 19.0
## 4    B    2 15.0 10.8
## 5    C    1 17.5 19.8
## 6    C    2 13.5 12.1
\end{verbatim}

We have another possibility here, to instead place the values for the individual plots and treatments next to each other. Note we now move \texttt{Plot} to the right-hand side of the formula in \texttt{dcast}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dcast}\NormalTok{(gas, Date }\OperatorTok{~}\StringTok{ }\NormalTok{Plot }\OperatorTok{+}\StringTok{ }\NormalTok{treatment, }\DataTypeTok{value.var=}\StringTok{"Photo"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Date 1_Amb 1_Ele 2_Amb 2_Ele
## 1    A  14.4  16.3  17.8  13.3
## 2    B  16.4  19.0  15.0  10.8
## 3    C  17.5  19.8  13.5  12.1
\end{verbatim}

\hypertarget{more-complex-dplyr-examples}{%
\section{\texorpdfstring{More complex \texttt{dplyr} examples}{More complex dplyr examples}}\label{more-complex-dplyr-examples}}

In this chapter, we have learned many new tools to work with data - filtering, summarizing, reshaping, and so on. One advantage of the \texttt{dplyr} package over functions in base R is that the various operations can be efficiently combined with the \texttt{\%\textgreater{}\%} operator, combining all your data converting and shaping steps into one.

This will become clear with some examples.

\hypertarget{tree-growth-data-filter-and-multiple-groupings}{%
\subsection{Tree growth data: filter and multiple groupings}\label{tree-growth-data-filter-and-multiple-groupings}}

The first example uses the \texttt{hfeifbytree} data from the \texttt{lgrdata} package. This dataset contains measurements of height and stem diameter on nearly 1200 Eucalyptus trees in Sydney, repeated 17 times. The trees grow in plots subjected to different treatments (control, fertilization, irrigation, or both).

On some of the dates, all trees were measured, while on other dates a small subsample was taken (ca. 10\% of all trees). We want to make a plot of average tree height by treatment over time, but use only the dates were all trees were measured. The following code makes Fig. \ref{fig:hfeifmeanplot}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(hfeifbytree)}

\KeywordTok{library}\NormalTok{(dplyr)}
\KeywordTok{library}\NormalTok{(ggplot2)   }
\KeywordTok{library}\NormalTok{(ggthemes)}

\NormalTok{hfeif_meanh <-}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(hfeifbytree, }\DataTypeTok{Date =} \KeywordTok{as.Date}\NormalTok{(Date)) }\OperatorTok{%>%}\StringTok{  }\CommentTok{# Convert to proper Date}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(Date) }\OperatorTok{%>%}\StringTok{              }\CommentTok{# Set up the grouping variable}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\KeywordTok{n}\NormalTok{() }\OperatorTok{>}\StringTok{ }\DecValTok{500}\NormalTok{) }\OperatorTok{%>%}\StringTok{           }\CommentTok{# Keep groups with more than 500 observations}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(Date, treat) }\OperatorTok{%>%}\StringTok{       }\CommentTok{# New grouping; to get average by Date and treatment}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{height =} \KeywordTok{mean}\NormalTok{(height, }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }\CommentTok{# Average height, discard NA.}
\StringTok{  }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{treatment =}\NormalTok{ treat)       }\CommentTok{# rename a variable}
  
\CommentTok{# It is possible to make the plot inside the data pipeline, but}
\CommentTok{# we recommend separating them!}
\KeywordTok{ggplot}\NormalTok{(hfeif_meanh, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Date, }\DataTypeTok{y =}\NormalTok{ height, }\DataTypeTok{col =}\NormalTok{ treatment)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size =} \DecValTok{2}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_colour_tableau}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{ylim}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{20}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{02-dataskills_files/figure-latex/hfeifmeanplot-1.pdf}
\caption{\label{fig:hfeifmeanplot}Average tree height by treatment over time, for the hfeifbytree data}
\end{figure}

\hypertarget{crude-oil-production-find-top-exporters}{%
\subsection{Crude oil production: find top exporters}\label{crude-oil-production-find-top-exporters}}

In the second example we will use the \texttt{oil} data, a dataset with annual crude oil production for the top 8 oil-producing countries since 1971. We want to find the top three countries for the period 1980-1985, sort them, and replace the country abbreviations with country names.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(oil)}

\CommentTok{# First we make a dataframe with the abbreviations.}
\CommentTok{# Very handy here is tribble from tibble; making it easier to write}
\CommentTok{# small dataframes directly into your script.}
\KeywordTok{library}\NormalTok{(tibble)}
\NormalTok{abb_key <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}\OperatorTok{~}\NormalTok{country, }\OperatorTok{~}\NormalTok{country_full,}
                      \StringTok{"MEX"}\NormalTok{,    }\StringTok{"Mexico"}\NormalTok{,}
                      \StringTok{"USA"}\NormalTok{,    }\StringTok{"USA"}\NormalTok{,}
                      \StringTok{"CHN"}\NormalTok{,    }\StringTok{"China"}\NormalTok{,}
                      \StringTok{"IRN"}\NormalTok{,    }\StringTok{"Iran"}\NormalTok{,}
                      \StringTok{"SAU"}\NormalTok{,    }\StringTok{"Saudi-Arabia"}\NormalTok{,}
                      \StringTok{"IRQ"}\NormalTok{,    }\StringTok{"Iraq"}\NormalTok{,}
                      \StringTok{"KWT"}\NormalTok{,    }\StringTok{"Kuwait"}\NormalTok{,}
                      \StringTok{"VEN"}\NormalTok{,    }\StringTok{"Venezuela"}\NormalTok{)}

\CommentTok{# To avoid a warning, we first convert country to character}
\CommentTok{# (not strictly necessary)}
\NormalTok{oil_top <-}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(oil, }
         \DataTypeTok{country =} \KeywordTok{as.character}\NormalTok{(country),}
         \DataTypeTok{production_M =}\NormalTok{ production }\OperatorTok{/}\StringTok{ }\DecValTok{1000}\NormalTok{) }\OperatorTok{%>%}\StringTok{  }\CommentTok{# Convert to million tonnes.}
\StringTok{  }\KeywordTok{full_join}\NormalTok{(abb_key, }\DataTypeTok{by=}\StringTok{"country"}\NormalTok{) }\OperatorTok{%>%}\StringTok{          }\CommentTok{# Add full country name}
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{%in%}\StringTok{ }\DecValTok{1980}\OperatorTok{:}\DecValTok{1985}\NormalTok{) }\OperatorTok{%>%}\StringTok{               }\CommentTok{# Subset for years between 1980-1985}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(country_full) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{production_M =} \KeywordTok{mean}\NormalTok{(production_M)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(production_M)) }\OperatorTok{%>%}\StringTok{               }\CommentTok{# Sort by production; in descending order}
\StringTok{  }\NormalTok{as.data.frame }\OperatorTok{%>%}\StringTok{                             }\CommentTok{# To be consistent, output a dataframe}
\StringTok{  }\KeywordTok{head}\NormalTok{(., }\DecValTok{3}\NormalTok{)                                    }\CommentTok{# Only show the top 32}

\CommentTok{# Finally make a table that looks nice in an rmarkdown document}
\KeywordTok{library}\NormalTok{(pander)}
\NormalTok{oil_top }\OperatorTok{%>%}\StringTok{ }\KeywordTok{pander}\NormalTok{(., }
                   \DataTypeTok{caption =} \StringTok{"Top three oil producing countries, 1980-1985."}\NormalTok{,}
                   \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{"Country"}\NormalTok{, }\StringTok{"Annual production (MTOE)"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}cc@{}}
\caption{Top three oil producing countries, 1980-1985.}\tabularnewline
\toprule
\begin{minipage}[b]{0.20\columnwidth}\centering
Country\strut
\end{minipage} & \begin{minipage}[b]{0.35\columnwidth}\centering
Annual production (MTOE)\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.20\columnwidth}\centering
Country\strut
\end{minipage} & \begin{minipage}[b]{0.35\columnwidth}\centering
Annual production (MTOE)\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.20\columnwidth}\centering
USA\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\centering
443.5\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.20\columnwidth}\centering
Saudi-Arabia\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\centering
335.1\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.20\columnwidth}\centering
Mexico\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\centering
138.8\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{weight-loss-data-make-an-irregular-timeseries-regular}{%
\subsection{Weight loss data: make an irregular timeseries regular}\label{weight-loss-data-make-an-irregular-timeseries-regular}}

In this example we will use the \texttt{weightloss} data, again from the \texttt{lgrdata} package. A person recorded his weight on irregular intervals (1-3 days), to check if his diet was having the desired effect. Because the dataset is irregular, it is not easy to calculate daily weight loss for the entire dataset. We can use a combination of \texttt{dplyr}, \texttt{zoo} and \texttt{padr} to clean up this dataset.

The \texttt{pad} function is quite powerful: it takes a dataframe, figures the time-indexing variable (in our case, Date), and stretches the dataset to include all Dates along the dataset, filling NA where no data were available.

The \texttt{zoo} package contains many useful functions for timeseries data. Here we use \texttt{na.approx} to linearly interpolate missing values. We also make a plot of the weight loss data, clarifying which data were interpolated. The following code make Fig. \ref{weightlossinterp}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lubridate)}
\KeywordTok{library}\NormalTok{(dplyr)}
\KeywordTok{library}\NormalTok{(zoo)}
\KeywordTok{library}\NormalTok{(padr)}

\KeywordTok{data}\NormalTok{(weightloss)}

\NormalTok{weightloss2 <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(weightloss, }
                      \DataTypeTok{Date =} \KeywordTok{dmy}\NormalTok{(Date),                }\CommentTok{# proper Date class}
                      \DataTypeTok{Weight =}\NormalTok{ Weight }\OperatorTok{*}\StringTok{ }\FloatTok{0.4536}\NormalTok{) }\OperatorTok{%>%}\StringTok{    }\CommentTok{# convert to kg}
\StringTok{               }\KeywordTok{pad}\NormalTok{(}\DataTypeTok{interval =}\StringTok{"day"}\NormalTok{) }\OperatorTok{%>%}\StringTok{                }\CommentTok{# timeseries is now regular}
\StringTok{               }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{measured =} \OperatorTok{!}\KeywordTok{is.na}\NormalTok{(Weight),  }\CommentTok{# FALSE when the value was interpolated}
                      \DataTypeTok{Weight =} \KeywordTok{na.approx}\NormalTok{(Weight))      }\CommentTok{# linear interpolation (zoo)}
  
\KeywordTok{ggplot}\NormalTok{(weightloss2, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Date, }\DataTypeTok{y =}\NormalTok{ Weight)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{colour =} \KeywordTok{ifelse}\NormalTok{(weightloss2}\OperatorTok{$}\NormalTok{measured, }\StringTok{"darkgrey"}\NormalTok{, }\StringTok{"red2"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{02-dataskills_files/figure-latex/weightlossinterp-1.pdf}
\caption{\label{fig:weightlossinterp}The weightloss data, with linearly interpolated missing values (red).}
\end{figure}

\hypertarget{reporting}{%
\chapter{Visualizing data and making reports}\label{reporting}}

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

Data visualization is an integral part of any data analytical project. We use data viz to spot patterns in data, check model assumptions, communicate findings, and to convince the audience that our analysis and conclusions make sense. Data viz is not something you only do at the end, but we switch cycle between analysis and visualization. It is therefore not only an important skill to make beautiful visualizations in the final communication of your results, but also to be able to make quick \& dirty graphs at any step in the analysis.

We do not only communicate with visualizations, but like to combine text, tables, figures, images, and well-formatted text in reports. We now have a powerful tool available in R, the \texttt{rmarkdown} document - a flexible toolkit to generate documents containing all results from R (with or without the code). These reports ensure that the results you see are made from the code in the document, we never have to ask: which version of my code produced those results? We already used \texttt{rmarkdown} in Chapter \ref{intro}, but go a few steps further here and provide useful tips \& tricks.

This chapter is different from the rest: we do not provide a complete beginners guide to either data visualization with \texttt{ggplot2}, or reporting with \texttt{rmarkdown}. We point to online resources for getting started, including comprehensive manuals, and galleries of examples. Instead, we focus on pointing out typical difficulties when getting started with these tools.

For data visualization, also be aware that the entire book in front of you includes many figures produced with \texttt{ggplot2} or base graphics. As always, learning from example is the best way.

\hypertarget{visualizing}{%
\section{Visualizing data}\label{visualizing}}

\hypertarget{base-graphics-or-ggplot2}{%
\subsection{\texorpdfstring{Base graphics or \texttt{ggplot2}?}{Base graphics or ggplot2?}}\label{base-graphics-or-ggplot2}}

R comes with two graphics systems, that cannot be used together. The \texttt{base} graphics system has been part of R from the start, and continues to be used today. The second system is the \texttt{grid} system, and the most popular package that uses this system is \texttt{ggplot2}, a package in development for over 10 years that now sees very wide application, and numerous add-ons and extensions.

Personally, I have used base graphics since 2001, and resisted switching to \texttt{ggplot2} for a very long time. I now use \texttt{ggplot2} for visualizing data, but continue to use base graphics as well, for a few reasons - especially because many add-on packaged include some quick plotting function that returns a base plot.

You can read around the web for many opinionated accounts on why we should use \texttt{ggplot2} or the other (\href{http://varianceexplained.org/r/why-I-use-ggplot2/}{for example here}).

A few points to consider:

\begin{itemize}
\tightlist
\item
  Use \texttt{ggplot2} if you are a newcomer, because it is easier to make more complex graphs. For example, it is much easier to make multi-panel, multi-line, multi-everything figures than with base graphics. Notable examples include multi-panel figures with grouped bar plots, adding regression and smoothed lines \emph{with} confidence bands to plots, overlapping area plots, histograms and ribbons. All of these plots are possible with base, but usually require more code and more programming.
\item
  It is generally easier to achieve consistent figure formatting with \texttt{ggplot2}, through the use of themes.
\item
  Many packages include some built-in plotting function, more often than not these use base graphics. It is usually much easier to use those functions directly than to implement the figure from scratch in \texttt{ggplot2}. A basic understanding of base graphics is therefore useful in practice.
\item
  Sometimes, base graphics are easier, especially when you are experimenting and want to make quick and dirty plots. To plot a mathematical function, we can do \texttt{curve(x\^{}3,\ from=-1,\ to=1)} - this is not so easy in \texttt{ggplot2}.
\item
  There is no support for 3D graphics in \texttt{ggplot2}, base has a number of possibilities. That said, you probably do not want to make many 3D plots.
\item
  Use base graphics when you are making a simple plot, and wish to avoid \emph{dependencies}. Keeping dependencies to a minimum will make it more likely your code works in the future, and on someone else's machine. The \texttt{ggplot2} package is rather stable these days, but has changed dramatically in the past - often breaking old code.
\end{itemize}

For the reasons mentioned above, in this book we mostly use ggplot2, except when base graphics are a lot easier (that is, use less code).

\hypertarget{base-graphics}{%
\subsection{Base graphics}\label{base-graphics}}

In base graphics, we can choose from the following main plotting functions (this list is not complete, especially if you consider add-on packages):

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.21\columnwidth}\raggedright
Function\strut
\end{minipage} & \begin{minipage}[b]{0.73\columnwidth}\raggedright
Key functions\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\texttt{plot}\strut
\end{minipage} & \begin{minipage}[t]{0.73\columnwidth}\raggedright
Scatter plots, line plots, various others.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\texttt{barplot}\strut
\end{minipage} & \begin{minipage}[t]{0.73\columnwidth}\raggedright
Bar plot (including stacked and grouped bar plots)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\texttt{hist}\strut
\end{minipage} & \begin{minipage}[t]{0.73\columnwidth}\raggedright
Histograms and (relative) frequency diagrams\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\texttt{curve}\strut
\end{minipage} & \begin{minipage}[t]{0.73\columnwidth}\raggedright
Curves of mathematical expressions\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\texttt{pie}\strut
\end{minipage} & \begin{minipage}[t]{0.73\columnwidth}\raggedright
Pie charts (for less scientific uses)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\texttt{boxplot}\strut
\end{minipage} & \begin{minipage}[t]{0.73\columnwidth}\raggedright
Box-and-whisker plots\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\texttt{symbols}\strut
\end{minipage} & \begin{minipage}[t]{0.73\columnwidth}\raggedright
Like scatter plot, but symbols are sized by another variable\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Here it is useful to know that \texttt{plot} is a so-called \emph{generic function}, which has \emph{methods} for many special objects in R. For example, if we fit a linear regression:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lmfit <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(disp }\OperatorTok{~}\StringTok{ }\NormalTok{hp, }\DataTypeTok{data =}\NormalTok{ mtcars)}
\end{Highlighting}
\end{Shaded}

We can use the very brief command \texttt{plot(lmfit)} to produce four diagnostic plots. This works because a function called \texttt{plot.lm} is actually used when you send an \texttt{lm} object to the \texttt{plot} function (thus we can look at useful options in this case in the help page \texttt{?plot.lm}).

Similarly, \texttt{plot} will make different plots based on what type of data you use. In Fig. \ref{fig:plotdefault} four examples are shown; each of these is the result from a call to \texttt{plot()}, but with different data types.

\includegraphics{03-reporting_files/figure-latex/plotdefault-1.pdf} \includegraphics{03-reporting_files/figure-latex/plotdefault-2.pdf} \includegraphics{03-reporting_files/figure-latex/plotdefault-3.pdf} \includegraphics{03-reporting_files/figure-latex/plotdefault-4.pdf}

The way that \texttt{plot} gives different results depending on data types is both a good thing (for basic plots, you need very little code), and a bad thing because reading the code often does not tell you what sort of plot will be produced, and where to read the documentation (\texttt{?plot}, \texttt{?plot.default}, \texttt{?plot.factor}?).

\hypertarget{ggplot2}{%
\subsection{ggplot2}\label{ggplot2}}

The \texttt{ggplot2} package is an incredibly rich and powerful toolkit to construct plots. It is far beyond the scope of this book to provide a complete overview of the package, but luckily lots of free online resources are available (see Section \ref{ggplotresources}).

We will show the functionality of \texttt{ggplot2} by providing two examples, one scatterplot, and one barplot. Since we use \texttt{ggplot2} throughout this book, you can find many more examples. The following three examples were chosen because they highlight a few key options.

\hypertarget{preparing-the-data-for-plotting}{%
\subsubsection{Preparing the data for plotting}\label{preparing-the-data-for-plotting}}

To use \texttt{ggplot2}, our data have to always be in \emph{long format}, where each row represents an observation, and each column in the dataframe represents a type of measurement. Most of the datasets included in the \texttt{lgrdata} package are already in long format. One exception is the \texttt{dutchelection} dataset:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(dutchelection)}
\KeywordTok{head}\NormalTok{(dutchelection, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         Date  VVD PvdA  PVV CDA   SP D66  GL  CU SGP PvdD FiftyPlus
## 1 2012-03-22 22.1 16.8 13.9 9.4 16.8 7.7 4.5 3.3 1.5  2.4       1.1
## 2 2012-04-05 23.6 17.1 13.3 8.8 16.3 8.7 4.1 3.2 1.4  2.0       0.8
## 3 2012-04-19 24.0 17.3 12.0 8.2 17.0 8.8 3.5 3.3 1.6  3.1       0.8
\end{verbatim}

We cannot really use \texttt{ggplot2} when the data are formatted like this. Instead we want to have a dataframe with columns `Date', `party', and `vote\_percent', so that we can label the graph by political party. As we will see in Section \ref{reshaping}, quite magically we can use \texttt{melt} from \texttt{reshape2} :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(reshape2)}
\NormalTok{dutchlong <-}\StringTok{ }\KeywordTok{melt}\NormalTok{(dutchelection, }\DataTypeTok{variable.name =} \StringTok{"party"}\NormalTok{, }\DataTypeTok{value.name=}\StringTok{"vote_percent"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(dutchlong, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         Date party vote_percent
## 1 2012-03-22   VVD         22.1
## 2 2012-04-05   VVD         23.6
## 3 2012-04-19   VVD         24.0
\end{verbatim}

\hypertarget{scatterplot-example}{%
\subsubsection{Scatterplot example}\label{scatterplot-example}}

Here we show two examples of a scatter plot. In practice you start with the simplest plot you can think of, then gradually add `layers' and other elements. Here, the quickest way to make a scatter plot is like this,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Minimal}
\KeywordTok{data}\NormalTok{(automobiles)}

\KeywordTok{ggplot}\NormalTok{(automobiles, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ horsepower, }\DataTypeTok{y =}\NormalTok{ fuel_efficiency)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Removed 6 rows containing missing values (geom_point).
\end{verbatim}

\includegraphics{03-reporting_files/figure-latex/unnamed-chunk-5-1.pdf}

Next, we want to extend this example by including various other elements:

\begin{itemize}
\tightlist
\item
  Plotting symbols colored by Region
\item
  A linear regression line, one for each of the three Regions
\item
  Text labels identifying outliers
\item
  A legend
\item
  Better axis labels
\end{itemize}

Study the example below how each of these was included:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extended}
\KeywordTok{data}\NormalTok{(automobiles)}

\KeywordTok{library}\NormalTok{(ggrepel)}
\KeywordTok{library}\NormalTok{(dplyr)}

\NormalTok{automobiles2 <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(automobiles, }
       \DataTypeTok{resid =} \KeywordTok{residuals}\NormalTok{(}\KeywordTok{lm}\NormalTok{(fuel_efficiency }\OperatorTok{~}\StringTok{ }\NormalTok{horsepower, }
                            \DataTypeTok{na.action=}\NormalTok{na.exclude)))}

\KeywordTok{ggplot}\NormalTok{(automobiles2, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ horsepower, }\DataTypeTok{y =}\NormalTok{ fuel_efficiency,}
                        \DataTypeTok{col =}\NormalTok{ origin, }
                        \DataTypeTok{label =}\NormalTok{ car_name)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{pch =} \KeywordTok{ifelse}\NormalTok{(}\KeywordTok{abs}\NormalTok{(automobiles2}\OperatorTok{$}\NormalTok{resid) }\OperatorTok{>}\StringTok{ }\DecValTok{6}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{1}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_text_repel}\NormalTok{(}\DataTypeTok{data =} \KeywordTok{subset}\NormalTok{(automobiles2, }\KeywordTok{abs}\NormalTok{(resid) }\OperatorTok{>}\StringTok{ }\DecValTok{6}\NormalTok{),}
                  \DataTypeTok{show.legend=}\OtherTok{FALSE}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{lims}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{300}\NormalTok{), }\DataTypeTok{y =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{40}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{stat_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{, }\DataTypeTok{se =} \OtherTok{FALSE}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale_colour_tableau}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Horse power (hp)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Fuel use (liters / 100km)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{03-reporting_files/figure-latex/unnamed-chunk-6-1.pdf}

\hypertarget{area-plot-example}{%
\subsubsection{Area plot example}\label{area-plot-example}}

A `stacked area chart' can be quickly implemented with the \texttt{geom\_area} function, like so:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(oil)}
\KeywordTok{ggplot}\NormalTok{(oil, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{year, }\DataTypeTok{y=}\NormalTok{production}\OperatorTok{/}\DecValTok{1000}\NormalTok{, }\DataTypeTok{fill=}\NormalTok{country)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_area}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{""}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Crude Oil Production (MOE)"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_fill_economist}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{03-reporting_files/figure-latex/unnamed-chunk-7-1.pdf}

\hypertarget{barplot-example}{%
\subsubsection{Barplot example}\label{barplot-example}}

More complex barplots is one area where \texttt{ggplot2} is much, much easier to use than base graphics. If you want to represent count data as bars - a common application of barplots - \texttt{ggplot2} does the counting for you automatically, saving a step where such tables of counts have to be constructed.

If instead you want to make a barplot of data \emph{as they are} (that is, don't make tables first), use the setting \texttt{geom\_bar(stat\ =\ "identity")}, instead of \texttt{stat\ =\ "count"}, as in the example below.

In the following example we use the \texttt{titanic} data, available in the \texttt{lgrdata} package.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lgrdata)}
\KeywordTok{data}\NormalTok{(titanic)}

\CommentTok{# Important to convert factor variables to factors!}
\CommentTok{# 'Survived' is coded as 0,1 - but this is really a factor.}
\NormalTok{titanic}\OperatorTok{$}\NormalTok{Survived <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{Survived)}

\KeywordTok{library}\NormalTok{(ggplot2)}
\KeywordTok{library}\NormalTok{(ggthemes)}
\end{Highlighting}
\end{Shaded}

The following code is the minimal code needed to make a barplot with two panels (one for female passengers, one for male), counting passengers that have survived or died, for each of the three passenger classes.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Result not shown - see next example}
\KeywordTok{ggplot}\NormalTok{(titanic, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{PClass, }\DataTypeTok{fill=}\NormalTok{Survived)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{stat=}\StringTok{"count"}\NormalTok{, }\DataTypeTok{position=}\KeywordTok{position_dodge}\NormalTok{()) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{Sex)}
\end{Highlighting}
\end{Shaded}

You can run the code above yourself to see what is produced. It does not look great, so instead we re-format the legend, the colors, etc., and end up with Fig. \ref{fig:titanicplot1}. For both of these figures, \emph{make sure that \texttt{Survived} is a factor variable}, otherwise the plot won't look right.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(titanic, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{PClass, }\DataTypeTok{fill=}\NormalTok{Survived)) }\OperatorTok{+}\StringTok{        }\CommentTok{# bars by passenger class,}
\StringTok{                                                       }\CommentTok{# split by 'Survived'  }
\StringTok{  }\KeywordTok{scale_fill_manual}\NormalTok{(}\DataTypeTok{labels=}\KeywordTok{c}\NormalTok{(}\StringTok{"Died"}\NormalTok{, }\StringTok{"Survived"}\NormalTok{),      }\CommentTok{# labels for legend}
                    \DataTypeTok{values=}\KeywordTok{c}\NormalTok{(}\StringTok{"red2"}\NormalTok{,}\StringTok{"grey"}\NormalTok{)) }\OperatorTok{+}\StringTok{         }\CommentTok{# colors for bars (and legend)}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{stat=}\StringTok{"count"}\NormalTok{, }\DataTypeTok{position=}\KeywordTok{position_dodge}\NormalTok{()) }\OperatorTok{+}\StringTok{  }\CommentTok{# count data, bars side by side}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{Sex) }\OperatorTok{+}\StringTok{                                   }\CommentTok{# panels by Sex}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.title=}\KeywordTok{element_blank}\NormalTok{())                  }\CommentTok{# no legend title}
\end{Highlighting}
\end{Shaded}

\includegraphics{03-reporting_files/figure-latex/titanicplot1-1.pdf}

Same figure but stacked bars, expressed as percent of total (Fig. \ref{fig:titanicplot2}).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(titanic, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{PClass, }\DataTypeTok{fill=}\KeywordTok{as.factor}\NormalTok{(Survived))) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_fill_manual}\NormalTok{(}\DataTypeTok{labels=}\KeywordTok{c}\NormalTok{(}\StringTok{"Died"}\NormalTok{, }\StringTok{"Survived"}\NormalTok{),      }\CommentTok{# labels for legend}
                    \DataTypeTok{values=}\KeywordTok{c}\NormalTok{(}\StringTok{"red2"}\NormalTok{,}\StringTok{"grey"}\NormalTok{)) }\OperatorTok{+}\StringTok{         }\CommentTok{# colors for bars (and legend)}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{stat=}\StringTok{"count"}\NormalTok{, }\DataTypeTok{position=}\KeywordTok{position_fill}\NormalTok{()) }\OperatorTok{+}\StringTok{   }\CommentTok{# count the data, stack the bars}
\StringTok{  }\KeywordTok{scale_y_continuous}\NormalTok{(}\DataTypeTok{labels=}\NormalTok{scales}\OperatorTok{::}\NormalTok{percent) }\OperatorTok{+}\StringTok{         }\CommentTok{# express y-axis as % }
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{Sex) }\OperatorTok{+}\StringTok{                                   }\CommentTok{# two panels for each sex}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.title=}\KeywordTok{element_blank}\NormalTok{())                  }\CommentTok{# no legend title}
\end{Highlighting}
\end{Shaded}

\includegraphics{03-reporting_files/figure-latex/titanicplot2-1.pdf}

\hypertarget{ggplotresources}{%
\subsubsection{Resources}\label{ggplotresources}}

The web is bursting with great \texttt{ggplot2} tutorials and collections of examples. If you are stuck on some aspect, simply type your question into Google, and you will usually end up at a useful Stackoverflow post.

A selection of useful resources is:

\begin{itemize}
\tightlist
\item
  My favorite resources with lots of small examples: \url{http://www.cookbook-r.com/Graphs/}
\item
  A very practical gallery guide at \url{http://www.sthda.com/english/wiki/ggplot2-essentials}
\item
  Official page with (extensive) documentation: \url{https://ggplot2.tidyverse.org/}
\item
  A more gentle introduction to \texttt{ggplot2} at \url{https://r4ds.had.co.nz/data-visualisation.html}
\item
  An attractive gallery of useful plots, with all code at \url{http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html}
\end{itemize}

The \texttt{ggplot2} package has many extensions, packages that offer additional options, themes, plotting layouts, etc. In this book, we only use a couple of add-on packages for reasons of brevity. These include:

\begin{itemize}
\tightlist
\item
  \texttt{ggthemes} : an excellent collection of themes and color palettes
\item
  \texttt{scales} : useful functions for formatting axes, adjusting colors
\item
  \texttt{gridExtra} : to arrange multiple, separate plots, on one page
\end{itemize}

\hypertarget{rmarkdown}{%
\section{Making reports}\label{rmarkdown}}

Script files are good for simple analyses, and they are great for storing small amounts of code that you would like to use in lots of different projects. They are also the right solution if you want to produce R scripts that are executed as part of a larger project, for example from the command line, or executed on a schedule (e.g.~daily data quality checking). In Section \ref{scripts} we give a few more tips.

But, scripts are not the best way to share your results with others. Instead, we strongly suggest you use R markdown - a document format that includes both text with markup, and \emph{code chunks}, bits of R code that is executed, and the results placed in the document.

Markdown is a simple set of rules for formatting text files so that they are both human-readable and processable by software, and is used not just by \texttt{rmarkdown} but in many applications (like Github and Stackoverflow). R Markdown simply adds R, by allowing code chunks with various options.

\hypertarget{getting-started}{%
\subsection{Getting started}\label{getting-started}}

RStudio offers a handy editor for markdown files, and starts with an example file that shows many of the features. Start a new markdown file by choosing File \textgreater{} New File \textgreater{} R Markdown\ldots{}. For now, leave the default settings. The new R markdown document (which is just a text file with the extension \texttt{.Rmd}) already contains some example code. Run this example by clicking the button just above the markdown document (Knit HTML). The example code will generate a new document (an HTML page), which opens in your browser You can see that the output contains text, R code, and even a plot.

\BeginKnitrBlock{rmdtry}
Try `knitting' the example rmarkdown file (the one you see when you open your first \texttt{rmarkdown} file). First install the \texttt{knitr} and \texttt{rmarkdown} packages. Next, click the `Knit' button in the upper-right hand corner just above the file. An HTML file was created. Find it and open it.
\EndKnitrBlock{rmdtry}

\hypertarget{tips}{%
\subsection{Tips}\label{tips}}

\hypertarget{start-with-an-example-document}{%
\subsubsection*{Start with an example document}\label{start-with-an-example-document}}
\addcontentsline{toc}{subsubsection}{Start with an example document}

When you open a new rmarkdown file (see previous section), the first step is to delete everything in the example document, \emph{except the top section and the first code chunk}. Your rmarkdown document will now look like this:

\begin{verbatim}
---
title: "Untitled"
output: html_document
---
\end{verbatim}

\texttt{\{r\ setup,\ include=FALSE\}\ knitr::opts\_chunk\$set(echo\ =\ TRUE)}

\hypertarget{modify-the-output-style}{%
\subsubsection*{Modify the output style}\label{modify-the-output-style}}
\addcontentsline{toc}{subsubsection}{Modify the output style}

You can add lots of options to the header (the bit between \texttt{-\/-}), that affect how the conversion to HTML works (including style, settings for the table of contents, author, date, etc.). See the Rstudio help page for the HTML version of \texttt{rmarkdown} \href{https://bookdown.org/yihui/rmarkdown/html-document.html}{by following this link}.

We list a few useful options; to see how these can be used search for them on the link above.

\begin{itemize}
\tightlist
\item
  \texttt{code\_folding:\ hide}, hides the code in the document, but adds a button to reveal the code.
\item
  \texttt{toc\_float:\ true}, a very nice floating table of contents (the contents are always visible in a menu to the left)
\item
  \texttt{theme:\ cosmo}, or lots of other choices to be \href{https://bootswatch.com/3/}{picked from this gallery}, changes the colors, fonts, and general appearance of the document.
\end{itemize}

\hypertarget{learn-markdown-syntax-for-text-formatting}{%
\subsubsection*{Learn markdown syntax for text formatting}\label{learn-markdown-syntax-for-text-formatting}}
\addcontentsline{toc}{subsubsection}{Learn markdown syntax for text formatting}

As mentioned, the rest of the document contains two types of input: text with markup, and code chunks. Open a new rmarkdown document to see what the text with input looks like, and note the use of sections, formatting (bold, italic, etc.), weblinks, and so on. \href{https://rmarkdown.rstudio.com/lesson-2.html}{Follow the Rstudio \texttt{rmarkdown} lessons to learn more}.

\hypertarget{set-options-for-individual-code-chunks}{%
\subsubsection*{Set options for individual code chunks}\label{set-options-for-individual-code-chunks}}
\addcontentsline{toc}{subsubsection}{Set options for individual code chunks}

The code chunks contain R code, which will be executed, and the results will be visible in the eventual document (in our case, an HTML page). An R code chunk may look like this,

\texttt{\{r\ titanicglm,\ echo\ =\ TRUE,\ eval\ =\ TRUE\}\ fit\ \textless{}-\ glm(Survived\ \textasciitilde{}\ Age,\ data\ =\ titanic)}

Here, \texttt{titanicglm} is a label for the chunk (you don't need to set it), and \texttt{echo\ =\ TRUE} make the code visible in the document, and \texttt{eval=TRUE} actually runs the code in the chunk. Both these options are used a lot. You use \texttt{echo=FALSE} to not show code, for example when there is too much messy code to share for this particular block. You use \texttt{eval\ =\ FALSE} to disable execution of a single code chunk. This is very useful when you have some code that simply does not work yet, but you hate using comments (\texttt{\#}) to disable it, instead you can place the code in its own chunk and set \texttt{echo=FALSE,\ eval=FALSE}.

\hypertarget{set-options-for-figure-output}{%
\subsubsection*{Set options for figure output}\label{set-options-for-figure-output}}
\addcontentsline{toc}{subsubsection}{Set options for figure output}

An important step is to control the output of figures. The documentation (see @Section(rmarkdownresources)) is a bit overwhelming, but here is an example with some useful settings:

\texttt{\{r\ titanicplot1,\ fig.cap="Number\ of\ passengers\ by\ Sex\ and\ PClass",\ fig.width=4,\ fig.height=4,\ dev="svg",\ echo\ =\ -1\}\textasciigrave{}r\textquotesingle{}\textquotesingle{}\textasciigrave{}\ par(bg="azure")\ with(titanic,\ spineplot(Sex,\ PClass))}

Here, \texttt{fig.cap} makes a figure caption (but figures will not be automatically numbered, see below for an alternative), \texttt{fig.width} and \texttt{fig.height} set the figure size in inches, \texttt{dev="svg"} sets the graphic device to SVG (an outstanding format for the web) - you need to install \texttt{svglite} for this to work. Finally \texttt{echo=-1} hides the first row of the code in the output (in this case, we don't want the reader to be bothered by graphical settings in \texttt{par()}).

\hypertarget{set-options-for-all-code-chunks}{%
\subsubsection*{Set options for all code chunks}\label{set-options-for-all-code-chunks}}
\addcontentsline{toc}{subsubsection}{Set options for all code chunks}

The section shown above that contains \texttt{knitr::opts\_chunk\$set(echo\ =\ TRUE)} sets \emph{chunk options for the entire document}. An often used feature here is to hide all code from the eventual document by setting \texttt{echo=FALSE}, or set the figure size for all chunks with \texttt{fig.width\ =\ 5,\ fig.height\ =\ 5}, or use a particular graphics device (\texttt{dev\ =\ \textquotesingle{}svg\textquotesingle{}}).

\hypertarget{auto-numbering-of-figures-and-tables}{%
\subsubsection*{Auto-numbering of figures and tables}\label{auto-numbering-of-figures-and-tables}}
\addcontentsline{toc}{subsubsection}{Auto-numbering of figures and tables}

In the example above, we set a caption for a figure, but the figures are not automatically numbered in \texttt{rmarkdown}. To enable this, all you have to do is install the \texttt{bookdown} package, and replace the header with this example:

\begin{verbatim}
---
title: "Untitled"
output: bookdown::html_document2
---
\end{verbatim}

Everything else should work as expected, but now figures that contain a \texttt{fig.cap} setting will be automatically numbered!

\hypertarget{make-r-output-pretty}{%
\subsubsection*{Make R output pretty}\label{make-r-output-pretty}}
\addcontentsline{toc}{subsubsection}{Make R output pretty}

One thing you notice quickly is that R output that is usually printed to the screen, will look exactly the same in an rmarkdown document - ugly. For example, try this code chunk:

\begin{verbatim}
summary(titanic) 
\end{verbatim}

The output in the HTML is not attractive, to say the least.

A number of packages will convert raw R output to markdown or HTML output, which can be used effectively in rmarkdown documents. Here we recommend using the \texttt{pander} package to convert many R objects to readable output for use in rmarkdown documents, and the \texttt{kable} function from the \texttt{knitr} package to convert things that look like dataframes. Both packages are very easy to use.

\begin{verbatim}
library(pander)    # for pander()
library(knitr)     # for kable()
library(magrittr)  # for %>%

summary(titanic) %>% pander
summary(titanic) %>% kable
\end{verbatim}

Try the \texttt{pander} function on many outputs from statistical analyses as well, for example:

\begin{verbatim}
test_output <- t.test(Age ~ Sex, data = titanic)
pander(test_output)
\end{verbatim}

\hypertarget{rmarkdownresources}{%
\subsection{Resources}\label{rmarkdownresources}}

The documentation for \texttt{rmarkdown} based documents is a little scattered across various sources. The reason for this is that multiple packages are involved in making an HTML page from an \texttt{.Rmd} file.

\begin{itemize}
\tightlist
\item
  The \texttt{knitr} package handles the \emph{execution} of the R code in the document, and the \emph{integration} of the R output into the document. It provides all options that are set at the top of each code chunk, for example to show or hide the code, to control figure size and resolution, captions for tables. All chunk options are \href{https://yihui.name/knitr/options/}{listed on the \texttt{knitr} website}.
\item
  The \texttt{rmarkdown} package (from Rstudio) handles the \emph{conversion} to the desired output format, for example HTML or PDF. To do so, it uses Pandoc (see below), which is installed automatically with Rstudio. The \texttt{rmarkdown} package provides all options at the top of the \texttt{Rmd} document (the so-called YAML header), including the desired output format, and to control many options like the table of contents, format style, custom CSS, and so on. All options for \texttt{rmarkdown} \href{https://rmarkdown.rstudio.com/}{are described on Rstudio's website}. (Make sure to scroll down and select an output format to read about available options).
\item
  Finally, Pandoc is the actual engine to convert our raw text file (including R output formatted by \texttt{knitr}) to an HTML page, or some other format. Normally you don't have to learn much about Pandoc's options, since many settings are already provided by \texttt{rmarkdown}, but \href{https://pandoc.org/MANUAL.html}{the various formatting rules and conversion options are described here}.
\end{itemize}

\BeginKnitrBlock{rmdreading}
A comprehensive list of useful and more advanced features in rmarkdown can be read here: \url{https://holtzy.github.io/Pimp-my-rmd/}
\EndKnitrBlock{rmdreading}

\hypertarget{linmodel}{%
\chapter{Basic statistics and linear modelling}\label{linmodel}}

\hypertarget{introduction-2}{%
\section{Introduction}\label{introduction-2}}

This book is not an \emph{Introduction to statistics}. There are many books focused on \emph{statistics}, with or without example R code. The focus throughout this book is on the R code itself, as we try to present clear and short solutions to common analysis tasks. In the following, we assume you have a basic understanding of linear regression, Student's \(t\)-tests, ANOVA, and confidence intervals for the mean.

Linear modelling is a general technique that includes linear regression, but also basic means testing, comparing samples, and more complex combinations of class and numeric predictors.

In linear modelling we are interested in understanding variation in a single \emph{numeric response variable} (or sometimes binary). We can include all sorts of \emph{predictors} (`explanatory variables', `independent variables'), depending on what we chose we end up with various techniques:

\begin{itemize}
\tightlist
\item
  factor variable(s), test difference in mean in our predictor across the factor (``Analysis of variance'', ``t-test'')
\item
  a single numeric predictor (simple linear regression)
\item
  multiple numeric predictors, and interactions (multiple linear regression)
\item
  mixture of factors and numeric predictors (in the simplest case, analysis of covariance - ANCOVA)
\end{itemize}

There are many more complicated possibilities, but the above is what this chapter is all about.

\textbf{Packages used in this chapter}

The examples will generally let you know which packages are used, but for your convenience, here is a complete list of the packages used.

For plotting, we often use \texttt{ggplot2}, \texttt{ggthemes}, \texttt{scales} and \texttt{ggpubr} (these are frequently omitted from the examples):

Otherwise:

\begin{itemize}
\tightlist
\item
  \texttt{lgrdata} (for the example datasets)
\item
  \texttt{pastecs} (for descriptive statistics)
\item
  \texttt{dplyr} (for various data skills and the pipe operator \texttt{\%\textgreater{}\%})
\item
  \texttt{pander} (to format R output for use in rmarkdown documents)
\item
  \texttt{broom} (for tidy printing of fitted models)
\item
  \texttt{multcomp} (for multiple comparisons)
\item
  \texttt{visreg} (for visualizing regression models)
\item
  \texttt{car} (for various functions used in regression)
\item
  \texttt{emmeans} (for computing marginal effects from regression models)
\end{itemize}

\hypertarget{distributions}{%
\section{Probability distributions}\label{distributions}}

You will have encountered a number of probability distributions before. For example, the \emph{Binomial} distribution is a model for the distribution of the number of \emph{successes} in a sequence of independent trials, for example, the number of heads in a coin tossing experiment. Another commonly used discrete distribution is the \emph{Poisson}, which is a useful model for many kinds of count data. Of course, the most important distribution of all is the \emph{Normal} or Gaussian distribution.

R provides sets of functions to find densities, cumulative probabilities, quantiles, and to draw random numbers from many important distributions. The names of the functions all consist of a one letter prefix that specifies the type of function and a stem which specifies the distribution. Look at the examples in the table below.

\begin{tabular}{l|l}
\hline
Prefix & Meaning\\
\hline
`d` & density\\
\hline
`p` & cumulative probability\\
\hline
`q` & quantile\\
\hline
`r` & simulate\\
\hline
\end{tabular}

\begin{tabular}{l|l}
\hline
Suffix & Meaning\\
\hline
`binom` & Binomial\\
\hline
`pois` & Poisson\\
\hline
`norm` & Normal\\
\hline
`t` & Student's t\\
\hline
`chisq` & Chi-squared\\
\hline
`f` & F\\
\hline
\end{tabular}

Using the prefix and the suffix, we can construct each desired function. For example,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Calculate the probability of 3 heads out of 10 tosses of a fair coin.}
\CommentTok{# This is a (d)ensity of a (binom)ial distribution.}
\KeywordTok{dbinom}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{10}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1171875
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Calculate the probability that a normal random variable (with }
\CommentTok{# mean of 3 and standard deviation of 2) is less than or equal to 4.}
\CommentTok{# This is a cumulative (p)robability of a (norm)al variable.}
\KeywordTok{pnorm}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.6914625
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Find the t-value that corresponds to a 2.5% right-hand tail probability}
\CommentTok{# with 5 degrees of freedom.}
\CommentTok{# This is a (q)uantile of a (t)distribution.}
\KeywordTok{qt}\NormalTok{(}\FloatTok{0.975}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.570582
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Simulate 5 Poisson random variables with a mean of 3. }
\CommentTok{# This is a set of (r)andom numbers from a (pois)son distribution.}
\KeywordTok{rpois}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 3 3 3 5
\end{verbatim}

See the help page \texttt{?Distributions} for more details.

To make a quick plot of a distribution, we can use the density function in combination with \texttt{curve}. The following code makes Fig. \ref{fig:distplot}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# A standard normal distribution}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{dnorm}\NormalTok{(x, }\DataTypeTok{sd=}\DecValTok{1}\NormalTok{, }\DataTypeTok{mean=}\DecValTok{0}\NormalTok{), }\DataTypeTok{from=}\OperatorTok{-}\DecValTok{3}\NormalTok{, }\DataTypeTok{to=}\DecValTok{3}\NormalTok{,}
      \DataTypeTok{ylab=}\StringTok{"Density"}\NormalTok{, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}

\CommentTok{# Add a t-distribution with 3 degrees of freedom.}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{dt}\NormalTok{(x, }\DataTypeTok{df=}\DecValTok{3}\NormalTok{), }\DataTypeTok{from =}\OperatorTok{-}\DecValTok{3}\NormalTok{, }\DataTypeTok{to=}\DecValTok{3}\NormalTok{, }\DataTypeTok{add=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{)}

\CommentTok{# Add a legend (with a few options, see ?legend)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"Standard normal"}\NormalTok{,}\StringTok{"t-distribution, df=3"}\NormalTok{), }\DataTypeTok{lty=}\DecValTok{1}\NormalTok{, }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{,}\StringTok{"red"}\NormalTok{),}
       \DataTypeTok{bty=}\StringTok{'n'}\NormalTok{, }\DataTypeTok{cex=}\FloatTok{0.8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05-linearregression_files/figure-latex/distplot-1.pdf}
\caption{\label{fig:distplot}Two univariate distributions plotted with curve()}
\end{figure}

\BeginKnitrBlock{rmdtry}
Make a histogram of a sample of random numbers from a distribution of your choice. use \texttt{hist} and one of the functions starting with \texttt{r} from above.
\EndKnitrBlock{rmdtry}

\hypertarget{descstat}{%
\section{Descriptive Statistics}\label{descstat}}

Descriptive statistics summarise some of the properties of a given data set. Generally, we are interested in measures of location (central tendency, such as mean and median) and scale (variance or standard deviation). Other descriptions can include the sample size, the range, and so on. We already encountered a number of functions that can be used to summarize a vector.

Let's look at some examples for the Pupae dataset.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Read data}
\KeywordTok{data}\NormalTok{(pupae)}

\CommentTok{# Extract the weights (for convenience)}
\NormalTok{weight <-}\StringTok{ }\NormalTok{pupae}\OperatorTok{$}\NormalTok{PupalWeight}

\CommentTok{# Find the number of observations}
\KeywordTok{length}\NormalTok{(weight)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 84
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Find the average (mean) weight}
\KeywordTok{mean}\NormalTok{(weight)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3110238
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Find the Variance}
\KeywordTok{var}\NormalTok{(weight)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.004113951
\end{verbatim}

Note that R will compute the sample variance (not the population variance). The standard deviation can be calculated as the square root of the variance, or use the \texttt{sd} function directly.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Standard Deviation}
\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{var}\NormalTok{(weight))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.06414009
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Standard Deviation}
\KeywordTok{sd}\NormalTok{(weight)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.06414009
\end{verbatim}

Robust measures of the location and scale are the median and inter-quartile range; R has functions for these.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# median and inter-quartile range}
\KeywordTok{median}\NormalTok{(weight)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2975
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{IQR}\NormalTok{(weight)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.09975
\end{verbatim}

The median is the 50th percentile or the second quartile. The \texttt{quantile} function can compute quartiles as well as arbitrary percentiles/quantiles.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Default: computes quartiles.}
\KeywordTok{quantile}\NormalTok{(weight)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      0%     25%     50%     75%    100% 
## 0.17200 0.25625 0.29750 0.35600 0.47300
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Or set any quantiles}
\KeywordTok{quantile}\NormalTok{(weight, }\DataTypeTok{probs=}\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\FloatTok{0.1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     0%    10%    20%    30%    40%    50%    60%    70%    80%    90% 
## 0.1720 0.2398 0.2490 0.2674 0.2892 0.2975 0.3230 0.3493 0.3710 0.3910 
##   100% 
## 0.4730
\end{verbatim}

\textbf{Missing Values}: All of the above functions will return \texttt{NA} if the data contains \emph{any} missing values. However, they also provide an option to remove missing values (\texttt{NA}s) before their computations (see also Section \ref{workingmissing}).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(pupae}\OperatorTok{$}\NormalTok{Frass)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(pupae}\OperatorTok{$}\NormalTok{Frass, }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.846446
\end{verbatim}

The \texttt{summary} function provides a lot of the above information in a single command:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(weight)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.1720  0.2562  0.2975  0.3110  0.3560  0.4730
\end{verbatim}

The \texttt{moments} package provides `higher moments' if required, for example,
the \texttt{skewness} and \texttt{kurtosis}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# load the moments package}
\KeywordTok{library}\NormalTok{(moments)}
\KeywordTok{skewness}\NormalTok{(weight)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3851656
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{kurtosis}\NormalTok{(weight)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.579144
\end{verbatim}

The \texttt{pastecs} package includes a useful function that calculates many descriptive statistics for numeric vectors, including the standard error for the mean (for which R has no built-in function).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(pastecs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Attaching package: 'pastecs'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:magrittr':
## 
##     extract
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:dplyr':
## 
##     first, last
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# see ?stat.desc for description of the abbreviations}
\KeywordTok{stat.desc}\NormalTok{(weight)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      nbr.val     nbr.null       nbr.na          min          max 
## 84.000000000  0.000000000  0.000000000  0.172000000  0.473000000 
##        range          sum       median         mean      SE.mean 
##  0.301000000 26.126000000  0.297500000  0.311023810  0.006998258 
## CI.mean.0.95          var      std.dev     coef.var 
##  0.013919253  0.004113951  0.064140091  0.206222446
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# conveniently, the output is a character vector which we can index by name,}
\CommentTok{# for example extracting the standard error for the mean}
\KeywordTok{stat.desc}\NormalTok{(weight)[}\StringTok{"SE.mean"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     SE.mean 
## 0.006998258
\end{verbatim}

Sometimes you may wish to calculate descriptive statistics for subgroups in the data. We will come back to this extensively in Section \ref{tapplyaggregate} and later sections.

\hypertarget{testing-differences-between-groups}{%
\section{Testing differences between groups}\label{testing-differences-between-groups}}

\hypertarget{singlesample}{%
\subsection{Testing a single sample}\label{singlesample}}

In some applications we simply want to know whether the mean of our data (the sample) is equal to some hypothesized value, or whether it is clearly higher or lower. The simplest approach is to compute a 95\% \emph{confidence interval for the mean}, and then check whether the hypothesized value falls inside this interval (in which case you cannot conclude the value is different).

One way to get confidence intervals in R is to use the quantile functions for the relevant distribution. A \(100(1-\alpha)\)\% confidence interval for the mean on normal population is given by,

\[\bar{x} \pm t_{\alpha/2, n-1} \frac{s}{\sqrt{n}}\]

where \(\bar{x}\) is the sample mean, \(s\) the sample standard deviation and \(n\) is the sample size. \(t_{\alpha/2, n-1}\) is the \(\alpha/2\) tail point of a \(t\)-distribution on \(n-1\) degrees of freedom. That is, if \(T\) has a \(t\)-distribution on \(n-1\) degrees of freedom.

\[P(T \leq t_{\alpha/2, n-1}) = 1-\alpha/2 \]

The R code for this confidence interval can be written as,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Sample data - the pupae data.}
\KeywordTok{data}\NormalTok{(pupae)}
\NormalTok{weight <-}\StringTok{ }\NormalTok{pupae}\OperatorTok{$}\NormalTok{PupalWeight}

\CommentTok{# 95% confidence interval - set to 0.1 for a 90% interval}
\NormalTok{alpha <-}\StringTok{ }\FloatTok{0.05} 
\NormalTok{xbar <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(weight)}
\NormalTok{s <-}\StringTok{ }\KeywordTok{sd}\NormalTok{(weight)}
\NormalTok{n <-}\StringTok{ }\KeywordTok{length}\NormalTok{(weight)}
\NormalTok{half.width <-}\StringTok{ }\KeywordTok{qt}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{alpha}\OperatorTok{/}\DecValTok{2}\NormalTok{, n}\DecValTok{-1}\NormalTok{)}\OperatorTok{*}\NormalTok{s}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n)}

\CommentTok{# Confidence Interval }
\KeywordTok{c}\NormalTok{(xbar }\OperatorTok{-}\StringTok{ }\NormalTok{half.width, xbar }\OperatorTok{+}\StringTok{ }\NormalTok{half.width)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2971046 0.3249431
\end{verbatim}

Here, we assumed a normal distribution for the population. You may have been taught that if \texttt{n} is \emph{large}, say n\textgreater{}30, then you can use a normal approximation. That is, replace \texttt{qt(1-alpha/2,\ n-1)} with \texttt{qnorm(1-alpha/2)}, but there is no need, R can use the t-distribution for any \emph{n} (and the results will be the same, as the t-distribution converges to a normal distribution when the df is large).

\BeginKnitrBlock{rmdtry}
Confirm that the \(t\)-distribution converges to a normal distribution when \emph{n} is large (using \texttt{qt} and \texttt{qnorm}).
\EndKnitrBlock{rmdtry}

\hypertarget{hypothesis-testing}{%
\subsection{Hypothesis testing}\label{hypothesis-testing}}

There may be a reason to ask whether a dataset is consistent with a certain mean. For example, are the pupae weights consistent with a population mean of 0.29? For normal populations, we can use Student's \(t\)-test, available in R as the \texttt{t.test} function. In all following results, we use the \texttt{pander} function (from the \texttt{pander}) package to make the output short and readable (and in markdown format). For best results, use it in an rmarkdown document (though it works fine otherwise as well). We assume you have loaded these two packages:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(pander)}
\KeywordTok{library}\NormalTok{(dplyr)}
\end{Highlighting}
\end{Shaded}

Let's test the null hypothesis that the population mean is 0.29:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t.test}\NormalTok{(weight, }\DataTypeTok{mu=}\FloatTok{0.29}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }\NormalTok{pander}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}ccccc@{}}
\caption{One Sample t-test: \texttt{weight}}\tabularnewline
\toprule
\begin{minipage}[b]{0.20\columnwidth}\centering
Test statistic\strut
\end{minipage} & \begin{minipage}[b]{0.06\columnwidth}\centering
df\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\centering
P value\strut
\end{minipage} & \begin{minipage}[b]{0.29\columnwidth}\centering
Alternative hypothesis\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\centering
mean of x\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.20\columnwidth}\centering
Test statistic\strut
\end{minipage} & \begin{minipage}[b]{0.06\columnwidth}\centering
df\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\centering
P value\strut
\end{minipage} & \begin{minipage}[b]{0.29\columnwidth}\centering
Alternative hypothesis\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\centering
mean of x\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.20\columnwidth}\centering
3.004\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\centering
83\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\centering
0.00352 * *\strut
\end{minipage} & \begin{minipage}[t]{0.29\columnwidth}\centering
two.sided\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\centering
0.311\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Note that we get the t-statistic, degrees of freedom (n-1) and a P value for the test, with the specified alternative hypothesis (not equal, i.e.~two-sided). In addition, \texttt{t.test} gives us the estimated mean of the sample.

We can use \texttt{t.test} to do one-sided tests,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t.test}\NormalTok{(weight, }\DataTypeTok{mu=}\FloatTok{0.29}\NormalTok{, }\DataTypeTok{alternative=}\StringTok{"greater"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }\NormalTok{pander}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}ccccc@{}}
\caption{One Sample t-test: \texttt{weight}}\tabularnewline
\toprule
\begin{minipage}[b]{0.20\columnwidth}\centering
Test statistic\strut
\end{minipage} & \begin{minipage}[b]{0.06\columnwidth}\centering
df\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\centering
P value\strut
\end{minipage} & \begin{minipage}[b]{0.29\columnwidth}\centering
Alternative hypothesis\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\centering
mean of x\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.20\columnwidth}\centering
Test statistic\strut
\end{minipage} & \begin{minipage}[b]{0.06\columnwidth}\centering
df\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\centering
P value\strut
\end{minipage} & \begin{minipage}[b]{0.29\columnwidth}\centering
Alternative hypothesis\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\centering
mean of x\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.20\columnwidth}\centering
3.004\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\centering
83\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\centering
0.00176 * *\strut
\end{minipage} & \begin{minipage}[t]{0.29\columnwidth}\centering
greater\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\centering
0.311\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

The \texttt{t.test} is appropriate for data that is approximately normally distributed. You can check this using a histogram or a QQ-plot (see Sections sec:hist and sec:diagplots). If the data is not very close to a normal distribution then the \texttt{t.test} is often still appropriate, as long as the sample is large.

If the data is not normal and the sample size is small, there are a couple of alternatives: transform the data (often a log transform is enough) or use a \emph{nonparametric} test, in this case the Wilcoxon signed rank test. We can use the \texttt{wilcox.test} function for the latter, its interface is similar to \texttt{t.test} and it tests the hypothesis that the data is symmetric about the hypothesized population mean. For example,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{wilcox.test}\NormalTok{(weight, }\DataTypeTok{mu=}\FloatTok{0.29}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }\NormalTok{pander}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}ccc@{}}
\caption{Wilcoxon signed rank test with continuity correction: \texttt{weight}}\tabularnewline
\toprule
\begin{minipage}[b]{0.22\columnwidth}\centering
Test statistic\strut
\end{minipage} & \begin{minipage}[b]{0.19\columnwidth}\centering
P value\strut
\end{minipage} & \begin{minipage}[b]{0.32\columnwidth}\centering
Alternative hypothesis\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.22\columnwidth}\centering
Test statistic\strut
\end{minipage} & \begin{minipage}[b]{0.19\columnwidth}\centering
P value\strut
\end{minipage} & \begin{minipage}[b]{0.32\columnwidth}\centering
Alternative hypothesis\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.22\columnwidth}\centering
2316\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\centering
0.009279 * *\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\centering
two.sided\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{test-for-proportions}{%
\subsubsection{Test for proportions}\label{test-for-proportions}}

Sometimes you want to test whether observed proportions are consistent with a hypothesized population proportion. For example, consider a coin tossing experiment where you want to test the hypothesis that you have a fair coin (one with an equal probability of landing heads or tails). In your experiment, you get 60 heads out of 100 coin tosses. Do you have a fair coin? We can use the \texttt{prop.test} function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 60 'successes' out of a 100 trials, the hypothesized probability is 0.5.}
\KeywordTok{prop.test}\NormalTok{(}\DataTypeTok{x=}\DecValTok{60}\NormalTok{, }\DataTypeTok{n=}\DecValTok{100}\NormalTok{, }\DataTypeTok{p=}\FloatTok{0.5}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }\NormalTok{pander}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}ccccc@{}}
\caption{1-sample proportions test with continuity correction: \texttt{60\ out\ of\ 100,\ null\ probability\ 0.5}}\tabularnewline
\toprule
\begin{minipage}[b]{0.20\columnwidth}\centering
Test statistic\strut
\end{minipage} & \begin{minipage}[b]{0.06\columnwidth}\centering
df\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering
P value\strut
\end{minipage} & \begin{minipage}[b]{0.30\columnwidth}\centering
Alternative hypothesis\strut
\end{minipage} & \begin{minipage}[b]{0.07\columnwidth}\centering
p\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.20\columnwidth}\centering
Test statistic\strut
\end{minipage} & \begin{minipage}[b]{0.06\columnwidth}\centering
df\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering
P value\strut
\end{minipage} & \begin{minipage}[b]{0.30\columnwidth}\centering
Alternative hypothesis\strut
\end{minipage} & \begin{minipage}[b]{0.07\columnwidth}\centering
p\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.20\columnwidth}\centering
3.61\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\centering
1\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering
0.05743\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\centering
two.sided\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\centering
0.6\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Likewise, we can perform one-sided tests with the argument \texttt{alternative="greater"} (not shown).

\hypertarget{inference-for-two-populations}{%
\subsection{Inference for two populations}\label{inference-for-two-populations}}

Commonly, we wish to compare two (or more) populations. For example, the \texttt{pupae} dataset has pupal weights for female and male pupae. We may wish to compare the weights of males (\texttt{gender=0}) and females (\texttt{gender=1}).

To compare the pupal weights of males and females, we use the \emph{formula} interface for \texttt{t.test}. The formula interface is important because we will use it in many other functions, like linear regression and linear modelling.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# (output not shown)}
\CommentTok{# We assume equal variance between the groups, giving slightly more power,}
\CommentTok{# but see section 'unequal variances' further below.}
\KeywordTok{t.test}\NormalTok{(PupalWeight }\OperatorTok{~}\StringTok{ }\NormalTok{Gender, }\DataTypeTok{data=}\NormalTok{pupae, }\DataTypeTok{var.equal=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{paired-data}{%
\subsubsection{Paired data}\label{paired-data}}

The \texttt{t.test} can also be used when the data are paired, for example, measurements taken before and after some treatment on the same subjects. For this example, we will use the pulse data - data on pulse rates of individuals before and after exercise. We will test the simple idea that pulse rate is different after exercise. To do this, we first extract only those subjects that exercised (\texttt{Ran=1}),

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# (output not shown)}
\NormalTok{pulse <-}\StringTok{ }\KeywordTok{read.table}\NormalTok{(}\StringTok{"ms212.txt"}\NormalTok{, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{)}
\NormalTok{pulse.before <-}\StringTok{ }\KeywordTok{with}\NormalTok{(pulse, Pulse1[Ran}\OperatorTok{==}\DecValTok{1}\NormalTok{])}
\NormalTok{pulse.after <-}\StringTok{ }\KeywordTok{with}\NormalTok{(pulse, Pulse2[Ran}\OperatorTok{==}\DecValTok{1}\NormalTok{])}
\KeywordTok{t.test}\NormalTok{(pulse.after, pulse.before, }\DataTypeTok{paired=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{unequal-variances}{%
\subsubsection{Unequal variances}\label{unequal-variances}}

The default for the two-sample \texttt{t.test} is actually to \emph{not} assume equal variances. The theory for this kind of test is quite complex, and the resulting \(t\)-test is now only approximate, with an adjustment called the `Satterthwaite' or `Welch' approximation made to the degrees of freedom.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t.test}\NormalTok{(PupalWeight }\OperatorTok{~}\StringTok{ }\NormalTok{Gender,  }\DataTypeTok{data=}\NormalTok{pupae) }\OperatorTok{%>%}\StringTok{ }\NormalTok{pander}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}cccc@{}}
\caption{Welch Two Sample t-test: \texttt{PupalWeight} by \texttt{Gender} (continued below)}\tabularnewline
\toprule
\begin{minipage}[b]{0.21\columnwidth}\centering
Test statistic\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\centering
df\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\centering
P value\strut
\end{minipage} & \begin{minipage}[b]{0.31\columnwidth}\centering
Alternative hypothesis\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.21\columnwidth}\centering
Test statistic\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\centering
df\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\centering
P value\strut
\end{minipage} & \begin{minipage}[b]{0.31\columnwidth}\centering
Alternative hypothesis\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.21\columnwidth}\centering
-7.413\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\centering
74.63\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
1.587e-10 * * *\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\centering
two.sided\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\begin{longtable}[]{@{}cc@{}}
\toprule
\begin{minipage}[b]{0.24\columnwidth}\centering
mean in group 0\strut
\end{minipage} & \begin{minipage}[b]{0.24\columnwidth}\centering
mean in group 1\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.24\columnwidth}\centering
0.2725\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\centering
0.3513\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Since this modified t-test makes fewer assumptions, you could ask why we ever use the equal variances form. If the assumption is reasonable, then this (equal variances) form will have more power, i.e.~will reject the null hypothesis more often when it is actually false.

\hypertarget{testing-many-groups-at-once-anova}{%
\subsection{Testing many groups at once (ANOVA)}\label{testing-many-groups-at-once-anova}}

One-way ANOVA (ANalysis Of VAriance) can be used to compare means across two or more populations. We will not go into the theory here, but the foundation of ANOVA is comparing the variation \emph{between} the group means to the variation \emph{within} the groups (using an F-statistic).

We can use either the \texttt{aov} function or \texttt{lm} to perform ANOVAs. We will focus exclusively on the latter as it can be generalized more easily to other models. The use of \texttt{aov} is only appropriate when you have a balanced design (i.e., the same sample sizes in each of your groups).

To use \texttt{lm} for an ANOVA, we need a dataframe containing a (continuous) response variable and a factor variable that defines the groups. For example, in the Coweeta dataset, the species variable is a factor that defines groups by species. We can compute (for example) the mean height by species. Let's look at an example using the Coweeta data, but with only four species to simplify the output.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr)}

\CommentTok{# Take a subset and drop empty levels with droplevels.}
\KeywordTok{data}\NormalTok{(coweeta)}
\NormalTok{cowsub <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(coweeta, species }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"bele"}\NormalTok{,}\StringTok{"cofl"}\NormalTok{,}\StringTok{"oxar"}\NormalTok{,}\StringTok{"quru"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{droplevels}

\CommentTok{# # Quick summary table (uses dplyr)}
\KeywordTok{group_by}\NormalTok{(cowsub, species) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{height =} \KeywordTok{mean}\NormalTok{(height))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 2
##   species height
##   <fct>    <dbl>
## 1 bele     21.9 
## 2 cofl      6.80
## 3 oxar     16.5 
## 4 quru     21.1
\end{verbatim}

We might want to ask, does the mean height vary by species? Before you do any test for significance, a graphical summary of the data is always useful. For this type of data, box plots are preferred since they visualize not just the means but also the spread of the data (Fig. \ref{fig:allombox}).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{boxplot}\NormalTok{(height}\OperatorTok{~}\NormalTok{species, }\DataTypeTok{data=}\NormalTok{cowsub)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05-linearregression_files/figure-latex/allombox-1.pdf}
\caption{\label{fig:allombox}Simple box plot for the Coweeta data.}
\end{figure}

It seems like some of the species differences are quite large. We can fit a one-way ANOVA with \texttt{lm}, like so:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit1 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(height }\OperatorTok{~}\StringTok{ }\NormalTok{species, }\DataTypeTok{data=}\NormalTok{cowsub)}
\end{Highlighting}
\end{Shaded}

The fitted coefficients can be seen in \texttt{summary(fit1)}, or more concisely with \texttt{coef(fit1)}, but we prefer the use of the \texttt{broom} package, especially the functions \texttt{tidy} and \texttt{glance} :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(broom)}
\KeywordTok{tidy}\NormalTok{(fit1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 5
##   term        estimate std.error statistic  p.value
##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>
## 1 (Intercept)   21.9        1.56    14.0   7.02e-14
## 2 speciescofl  -15.1        2.93    -5.15  2.04e- 5
## 3 speciesoxar   -5.36       2.35    -2.28  3.04e- 2
## 4 speciesquru   -0.761      2.27    -0.335 7.40e- 1
\end{verbatim}

Here, \texttt{tidy} gives the table of coefficients. Notice the four estimated \texttt{Coefficients}, these represent the so-called \emph{contrasts}. In this case, \texttt{Intercept} represents the mean of the \emph{first} species, \texttt{bele}. The next three coefficients are the differences between each species and the first (e.g., species \texttt{cofl} has a mean that is -15.07 lower than \texttt{bele}). Also shown are the \emph{t}-statistic (and p-value) for each coefficient, for a test where the value is compared to zero. Not surprisingly the \texttt{Intercept} (i.e., the mean for the first species) is significantly different from zero (as indicated by the very small p-value). Two of the next three coefficients are also significantly different from zero.

We can get more details of the fit using \texttt{glance}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glance}\NormalTok{(fit1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 11
##   r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC
##       <dbl>         <dbl> <dbl>     <dbl>   <dbl> <int>  <dbl> <dbl> <dbl>
## 1     0.533         0.481  4.95      10.3 1.11e-4     4  -91.4  193.  200.
## # ... with 2 more variables: deviance <dbl>, df.residual <int>
\end{verbatim}

Here we see various useful statistics including the R squared (goodness of fit), and the p-value of the overall model. This p-value tells us whether the whole model is significant. In this case, it is comparing a model with four coefficients (one for each species) to a model that just has the same mean for all groups. In this case, the model is highly significant -- i.e.~there is evidence of different means for each group. In other words, a model where the mean varies between the four species performs much better than a model with a single grand mean.

\hypertarget{multcomp}{%
\subsection{Multiple comparisons}\label{multcomp}}

The ANOVA, as used in the previous section, gives us a single p-value for the overall `species effect'. The summary statement further shows whether individual species are different from the first level in the model, which is not always useful. If we want to know whether the four species were all different from each other, we can use a multiple comparison test.

\BeginKnitrBlock{rmdcaution}
Multiple comparisons on linear models where you have more than one factor variable are tricky, and probably best left alone. Read the help page ?\texttt{glht} for more information.
\EndKnitrBlock{rmdcaution}

We will use the \texttt{glht} function from the \texttt{multcomp} package (as a side note, base R includes the \texttt{TukeyHSD} function, but that does not work with \texttt{lm}, only with \texttt{aov}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# First fit the linear model again (a one-way ANOVA, }
\CommentTok{# because species is a factor)}
\NormalTok{lmSpec <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(height }\OperatorTok{~}\StringTok{ }\NormalTok{species, }\DataTypeTok{data=}\NormalTok{cowsub)}

\CommentTok{# Load package}
\KeywordTok{library}\NormalTok{(multcomp)}

\CommentTok{# Make a 'general linear hypothesis' object, Tukey style.}
\CommentTok{# (Note many other options in ?glht)}
\NormalTok{tukey_Spec <-}\StringTok{ }\KeywordTok{glht}\NormalTok{(lmSpec, }\DataTypeTok{linfct=}\KeywordTok{mcp}\NormalTok{(}\DataTypeTok{species=}\StringTok{"Tukey"}\NormalTok{))}

\CommentTok{# Print a summary. This shows p-values for the null hypotheses}
\CommentTok{# that species A is no different from species B, and so on.}
\KeywordTok{summary}\NormalTok{(tukey_Spec)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: lm(formula = height ~ species, data = cowsub)
## 
## Linear Hypotheses:
##                  Estimate Std. Error t value Pr(>|t|)    
## cofl - bele == 0 -15.0695     2.9268  -5.149   <0.001 ***
## oxar - bele == 0  -5.3620     2.3467  -2.285   0.1247    
## quru - bele == 0  -0.7614     2.2731  -0.335   0.9866    
## oxar - cofl == 0   9.7075     3.0295   3.204   0.0169 *  
## quru - cofl == 0  14.3081     2.9729   4.813   <0.001 ***
## quru - oxar == 0   4.6006     2.4039   1.914   0.2434    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## (Adjusted p values reported -- single-step method)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Some of the species are different from each other, but not all.}
\end{Highlighting}
\end{Shaded}

\BeginKnitrBlock{rmdtry}
In the above summary of the multiple comparison (\texttt{summary(tukey\_Spec)}), the p-values are adjusted for multiple comparisons with the so-called `single-step method'. To use a different method for the correction (there are many), try the following example: \texttt{summary(tukey\_Spec,\ test=adjusted("Shaffer"))}
Also look at the other options in the help pages for \texttt{?adjusted} and \texttt{?p.adjust}.
\EndKnitrBlock{rmdtry}

We can also produce a quick plot of the multiple comparison, which shows the pair-wise differences between the species with confidence intervals.

This code produces Fig. \ref{fig:tukeyplot}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# A plot of a fitted 'glht' object (multiple comparison)}
\KeywordTok{plot}\NormalTok{(tukey_Spec)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05-linearregression_files/figure-latex/tukeyplot-1.pdf}
\caption{\label{fig:tukeyplot}A standard plot of a multiple comparison.}
\end{figure}

\hypertarget{twoway}{%
\subsection{Comparing many groups by two predictors (two-way ANOVA)}\label{twoway}}

Sometimes there are two (or more) \emph{treatment} factors. The `age and memory' dataset (see \texttt{?memory}) includes the number of words remembered from a list for two age groups and five memory techniques.

This dataset is balanced, as shown below. in a table of counts for each of the combinations. First we fit a linear model of the \emph{main effects}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(memory)}

\CommentTok{# To make the later results easier to interpret, reorder the Process}
\CommentTok{# factor by the average number of words remembered.}
\NormalTok{memory <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(memory, }
                 \DataTypeTok{Process =} \KeywordTok{reorder}\NormalTok{(Process, Words, mean))}

\CommentTok{# Count nr of observations}
\KeywordTok{xtabs}\NormalTok{( }\OperatorTok{~}\StringTok{ }\NormalTok{Age }\OperatorTok{+}\StringTok{ }\NormalTok{Process, }\DataTypeTok{data=}\NormalTok{memory)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          Process
## Age       Counting Rhyming Adjective Imagery Intentional
##   Older         10      10        10      10          10
##   Younger       10      10        10      10          10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Fit linear model}
\NormalTok{fit2 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(Words }\OperatorTok{~}\StringTok{ }\NormalTok{Age }\OperatorTok{+}\StringTok{ }\NormalTok{Process, }\DataTypeTok{data=}\NormalTok{memory)}

\CommentTok{# Full output (not shown)}
\CommentTok{# summary(fit2)}

\CommentTok{# Instead, show just coefficient summary table in nice format}
\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{(fit2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 5
##   term               estimate std.error statistic  p.value
##   <chr>                 <dbl>     <dbl>     <dbl>    <dbl>
## 1 (Intercept)            5.20     0.763     6.81  8.99e-10
## 2 AgeYounger             3.10     0.623     4.97  2.94e- 6
## 3 ProcessRhyming         0.5      0.985     0.507 6.13e- 1
## 4 ProcessAdjective       6.15     0.985     6.24  1.24e- 8
## 5 ProcessImagery         8.75     0.985     8.88  4.41e-14
## 6 ProcessIntentional     8.90     0.985     9.03  2.10e-14
\end{verbatim}

The \texttt{summary} of the fitted model displays the individual t-statistics for each estimated coefficient. As with the one-way ANOVA, the significance tests for each coefficient are performed relative to the base level (by default, the first level of the factor). In this case, for the \texttt{Age} factor, the \texttt{Older} is the first level, and for the \texttt{Process} factor, \texttt{Adjective} is the first level. Thus all other coefficients are tested relative to the ``Older/Adjective'' group. The \(F\)-statistic at the end is for the overall model, it tests whether the model is significantly better than a model that includes only a mean count.

If we want to see whether \texttt{Age} and/or \texttt{Process} have an effect, we need F-statistics for these terms. Throughout this book, to compute p-values for terms in linear models, we use the \texttt{Anova} function from the \texttt{car} package.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Perform an ANOVA on a fitted model, giving F-statistics}
\KeywordTok{library}\NormalTok{(car)}
\KeywordTok{Anova}\NormalTok{(fit2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Anova Table (Type II tests)
## 
## Response: Words
##            Sum Sq Df F value    Pr(>F)    
## Age        240.25  1  24.746 2.943e-06 ***
## Process   1514.94  4  39.011 < 2.2e-16 ***
## Residuals  912.60 94                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

In this form, the \(F\)-statistic is formed by comparing models that do not include the term, but include all others. For example, \texttt{Age} is tested by comparing the full model against a model that includes all other terms (in this case, just \texttt{Process}).

\hypertarget{interactions}{%
\subsection{Interactions}\label{interactions}}

An important question when we have more than one factor in an experiment is whether there are any interactions. For example, do \texttt{Process} effects differ for the two \texttt{Age} groups, or are they simply additive? We can add interactions to a model by modifying the formula. An interaction is indicated using a ``\texttt{:}''. We can also include all \emph{main effects and interactions} using the \texttt{*} operator.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Two equivalent ways of specifying a linear model that includes all main effects}
\CommentTok{# and interactions:}
\NormalTok{fit3 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(Words }\OperatorTok{~}\StringTok{ }\NormalTok{Age }\OperatorTok{+}\StringTok{ }\NormalTok{Process }\OperatorTok{+}\StringTok{ }\NormalTok{Age}\OperatorTok{:}\NormalTok{Process, }\DataTypeTok{data=}\NormalTok{memory)}

\CommentTok{# Is the same as:}
\NormalTok{fit3}\FloatTok{.2}\NormalTok{ <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(Words }\OperatorTok{~}\StringTok{ }\NormalTok{Age }\OperatorTok{*}\StringTok{ }\NormalTok{Process, }\DataTypeTok{data=}\NormalTok{memory)}
\KeywordTok{Anova}\NormalTok{(fit3}\FloatTok{.2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Anova Table (Type II tests)
## 
## Response: Words
##              Sum Sq Df F value    Pr(>F)    
## Age          240.25  1 29.9356 3.981e-07 ***
## Process     1514.94  4 47.1911 < 2.2e-16 ***
## Age:Process  190.30  4  5.9279 0.0002793 ***
## Residuals    722.30 90                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

The \texttt{Anova} table shows that the interaction is significant. When an interaction is significant, this tells you nothing about the direction or magnitude of the interaction term. You can inspect the estimated coefficients in the \texttt{summary} output, but we recommend to first visualize the interaction with simple plots, as the coefficients can be easily misinterpreted. One way to visualize the interaction is to use the \texttt{interaction.plot} function, as in the following example.

This code produces Fig. \ref{fig:interactionplot}. If there were no interaction between the two factor variables, you would expect to see a series of parallel lines (because the effects of \texttt{Process} and \texttt{Age} would simply be additive).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Plot the number of words rememberd by Age and Process}
\CommentTok{# This standard plot can be customized in various ways, see ?interaction.plot}
\KeywordTok{with}\NormalTok{(memory, }\KeywordTok{interaction.plot}\NormalTok{(Age, Process, Words))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05-linearregression_files/figure-latex/interactionplot-1.pdf}
\caption{\label{fig:interactionplot}An interaction plot for the memory data, indicating a strong interaction (because the lines are not parallel).}
\end{figure}

\BeginKnitrBlock{rmdtry}
When there is a signficant interaction term, we might want to know under what levels of one factor is the effect of another factor signficant. This can be done easily using functions in the \texttt{emmeans} package. Load the \texttt{emmeans} package, and run the code \texttt{fit3.emm\ \textless{}-\ emmeans(fit3,\ \textasciitilde{}\ Age\ \textbar{}\ Process)}, followed by \texttt{pairs(fit3.emm)}. You can now inspect in great detail differences between levels of your predictors.
\EndKnitrBlock{rmdtry}

\hypertarget{comparing-models}{%
\subsection{Comparing models}\label{comparing-models}}

In the above example, we fitted two models for the Memory dataset: one without, and one with the interaction between \texttt{Process} and \texttt{Age}. We assessed the significance of the interaction by inspecting the p-value for the \texttt{Age:Process} term in the \texttt{Anova} statement. Another possibility is to perform a likelihood ratio test on two `nested' models, the model that includes the term, and a model that excludes it. We can perform a likelihood ratio test with the \texttt{anova} function, not to be confused with \texttt{Anova} from the \texttt{car} package!\footnote{You may have seen the use of `anova` on a single model, which also gives an ANOVA table but is confusing because a sequential (Type-I) test is performed, which we strongly advise against as it is never the most intuitive test of effects.}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# We can perform an anova on two models to compare the fit.}
\CommentTok{# Note that one model must be a subset of the other model. }
\CommentTok{# In this case, the second model has the same predictors as the first plus}
\CommentTok{# the interaction, and the likelihood ratio test thus tests the interaction.}
\KeywordTok{anova}\NormalTok{(fit2,fit3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Model 1: Words ~ Age + Process
## Model 2: Words ~ Age + Process + Age:Process
##   Res.Df   RSS Df Sum of Sq      F    Pr(>F)    
## 1     94 912.6                                  
## 2     90 722.3  4     190.3 5.9279 0.0002793 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

A second common way to compare different models is by the AIC (\emph{Akaike's Information Criterion}), which is calculated based on the likelihood (a sort of goodness of fit), and penalized for the number of parameters (i.e.~number of predictors in the model). The model with the lowest AIC is the preferred model. Calculating the \texttt{AIC} is simple,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{AIC}\NormalTok{(fit2, fit3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      df      AIC
## fit2  7 518.9005
## fit3 11 503.5147
\end{verbatim}

We once again conclude that the interaction improved the model fit substantially.

\hypertarget{diagnostics}{%
\subsection{Diagnostics}\label{diagnostics}}

The standard ANOVA assumes normality of the residuals, and we should always check this assumption with some diagnostic plots (Fig. \ref{fig:anovadiag1}). Although R has built-in diagnostic plots, we prefer the use of \texttt{qqPlot} and \texttt{residualPlot}, both from the \texttt{car} package.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}

\KeywordTok{library}\NormalTok{(car)}

\CommentTok{# Residuals vs. fitted}
\KeywordTok{residualPlot}\NormalTok{(fit3)}

\CommentTok{# QQ-plot of the residuals}
\KeywordTok{qqPlot}\NormalTok{(fit3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 26 86
\end{verbatim}

\begin{figure}
\centering
\includegraphics{05-linearregression_files/figure-latex/anovadiag1-1.pdf}
\caption{\label{fig:anovadiag1}Simple diagnostic plots for the Memory ANOVA.}
\end{figure}

The QQ-plot shows some slight non-normality in the upper right. The non-normality probably stems from the fact that the \texttt{Words} variable is a `count' variable.

\BeginKnitrBlock{rmdtry}
Check whether a log-transformation of \texttt{Words} makes the residuals closer to normally distributed.
\EndKnitrBlock{rmdtry}

\hypertarget{linear-regression}{%
\section{Linear regression}\label{linear-regression}}

\hypertarget{icecream}{%
\subsection{Icecream sales: a motivating example}\label{icecream}}

It is well known that ice cream sales are higher during warm weather. As an ice cream salesman, you hardly have to apply regression analysis to know this - it is just obvious. Suppose that one year, you sell icecream at Oosterpark in Amsterdam. Sales are pretty good, the summer is nice and warm. The next year you try your luck at the Dappermarkt, a busy market in the east of Amsterdam. You tally your sales every week, and finally make a plot comparing average weekly sales:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(icecream)}

\KeywordTok{library}\NormalTok{(ggplot2)}
\KeywordTok{library}\NormalTok{(ggthemes)}

\KeywordTok{ggplot}\NormalTok{(icecream, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ location, }\DataTypeTok{y =}\NormalTok{ sales, }\DataTypeTok{fill =}\NormalTok{ location)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale_fill_manual}\NormalTok{(}\DataTypeTok{values=}\KeywordTok{c}\NormalTok{(}\StringTok{"white"}\NormalTok{,}\StringTok{"grey"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{aspect.ratio =} \DecValTok{2}\NormalTok{, }\DataTypeTok{legend.position=}\StringTok{"none"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{lims}\NormalTok{(}\DataTypeTok{y=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1200}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05-linearregression_files/figure-latex/unnamed-chunk-38-1.pdf}
\caption{\label{fig:unnamed-chunk-38}Average weekly ice cream sales at two locations, over two years}
\end{figure}

Based on this simple boxplot, you would either conclude that there is no difference in sales, or that perhaps sales were slightly better in Oosterpark. We can also perform a \emph{t}-test for two samples, which tests the hypothesis that the two means are not different (in other words, location has no effect on sales).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t.test}\NormalTok{(sales }\OperatorTok{~}\StringTok{ }\NormalTok{location, }\DataTypeTok{data=}\NormalTok{icecream)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Welch Two Sample t-test
## 
## data:  sales by location
## t = -1.3227, df = 36.442, p-value = 0.1942
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -183.16655   38.51966
## sample estimates:
## mean in group Dappermarkt  mean in group Oosterpark 
##                  660.4856                  732.8090
\end{verbatim}

\BeginKnitrBlock{rmdnote}
The example above - as all other examples in this chapter - shows the raw output produced by R. To produce attractive output for use in an rmarkdown document, use the \texttt{pander} package: \texttt{pander::pander(t.test(sales\ \textasciitilde{}\ location,\ data=icecream))}. The \texttt{pander} function also works for many other R objects.
\EndKnitrBlock{rmdnote}

From this test we conclude no difference: the P value is very large (meaning the observed sample difference is not unusual, and could have easily arisen by chance).

Of course, there is something rather fishy about this experiment. We are testing the difference between two locations - but both locations were `tested' in different years, when other conditions may have been different. In other words, we have not performed a proper experiment at all - changing just one variable at a time - location is \emph{confounded} by the year.

We do not need to get into detail here to design a proper scientific ice cream sales experiment, instead we are going to make the point that we can account for some \emph{confounding variables} via regression analysis. How about temperature? As an astute ice cream salesman, you downloaded weekly average air temperature for Amsterdam, and added these to the data. Now let's make a plot using \emph{air temperature as a covariate}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Assuming you have loaded ggplot2 and ggthemes}
\KeywordTok{ggplot}\NormalTok{(icecream, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ temperature, }\DataTypeTok{y =}\NormalTok{ sales, }\DataTypeTok{fill =}\NormalTok{ location)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{shape =} \DecValTok{21}\NormalTok{, }\DataTypeTok{size=}\DecValTok{3}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_fill_manual}\NormalTok{(}\DataTypeTok{values =} \KeywordTok{c}\NormalTok{(}\StringTok{"white"}\NormalTok{,}\StringTok{"dimgrey"}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{lims}\NormalTok{(}\DataTypeTok{y=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1200}\NormalTok{), }\DataTypeTok{x=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{35}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05-linearregression_files/figure-latex/unnamed-chunk-41-1.pdf}
\caption{\label{fig:unnamed-chunk-41}Ice cream sales by location, and varying with temperature.}
\end{figure}

In this figure we arrive at a completely different conclusion - but only because we have taken into account the covariate weekly temperature. Now, \emph{at a given temperature}, ice cream sales were higher at the new location - Dappermarkt. This is an example of how a confounding variable can mask (or even reverse) effects of some other variable. It seems obvious from the figure that temperature was overall lower when you sold ice cream at the Dappermarkt, explaining why average weekly sales were in the end no different.

\BeginKnitrBlock{rmdtry}
Use a \emph{t}-test to test that temperature was lower at the Dappermarkt location.
\EndKnitrBlock{rmdtry}

Using regression analysis, we can test the assertion that ice cream sales are higher at Dappermarkt, \emph{at a given temperature}. But before we do that, we first introduce the tools to test difference between means (as we just did with a simple two-sample t-test), and introduce basic linear regression. We return to the icecream problem in Section \ref{icecreamtest}.

\hypertarget{simple-and-multiple-linear-regression}{%
\subsection{Simple and multiple linear regression}\label{simple-and-multiple-linear-regression}}

To fit linear models of varying complexity, we can use the \texttt{lm} function. The simplest model is a straight-line relationship between an \texttt{x} and a \texttt{y} variable. In this situation, the assumption is that the \texttt{y}-variable (the response) is a linear function of the \texttt{x}-variable (the independent variable), plus some random noise or measurement error. For the simplest case, both \texttt{x} and \texttt{y} are assumed to be continuous variables.

We use this method to study the relationship between two continuous variables: a \emph{response} (`y variable') and a \emph{predictor} (or independent variable) (`x variable'). We can use multiple regression to study the relationship between one response and more than one predictor.

We are going to use the Cereals data to inspect the ``health rating'' (\texttt{rating}), and two predictors: fibre content (\texttt{fiber}) and sugar content (\texttt{sugar}). To start with, let's make two scatter plots, side by side.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Read the data, if you haven't already}
\KeywordTok{data}\NormalTok{(cereals)}

\KeywordTok{library}\NormalTok{(scales)}
\KeywordTok{library}\NormalTok{(gridExtra)}

\CommentTok{# Two simple scatter plots on a log-log scale}
\NormalTok{g1 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(cereals, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ rating, }\DataTypeTok{x =}\NormalTok{ fiber)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{pch=}\DecValTok{15}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{lims}\NormalTok{(}\DataTypeTok{y=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{100}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{'lm'}\NormalTok{)}

\NormalTok{g2 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(cereals, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ rating, }\DataTypeTok{x =}\NormalTok{ sugars)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{col=}\StringTok{"dimgrey"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{lims}\NormalTok{(}\DataTypeTok{y=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{100}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{'lm'}\NormalTok{)}

\KeywordTok{grid.arrange}\NormalTok{(g1, g2, }\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05-linearregression_files/figure-latex/allomdiamheight-1.pdf}
\caption{\label{fig:allomdiamheight}Leaf area as a function of height and diameter (note the log-log scale).}
\end{figure}

Here we make use of \texttt{ggplot2}'s built-in regression lines, which are easily added to the plot. The default behaviour is to add a 95\% confidence band as well. In this case we immediately see that \texttt{fiber} is a worse predictor than \texttt{sugars} for the health rating, given the wider confidence interval for the location of the mean response (i.e.~the regression line).

We are going to fit a model that looks like, using statistical notation,
\begin{equation}
y = \alpha+\beta_1 x_1 +\beta_2 x_2 +\varepsilon
\label{eq:multiplelin}
\end{equation}

where \(\alpha\) is the intercept, \(x_1\) and \(x_2\) are the two predictors (fiber and sugars), and the \emph{two} slopes are \(\beta_1\) and \(\beta_2\). We are particularly interested in testing for significant effect of both predictors, which is akin to saying that we are testing the values of the two slopes against zero.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Fit a multiple regression without interactions, and inspect the summary}
\NormalTok{fit4 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(rating }\OperatorTok{~}\StringTok{ }\NormalTok{sugars }\OperatorTok{+}\StringTok{ }\NormalTok{fiber, }\DataTypeTok{data=}\NormalTok{cereals)}

\CommentTok{# A detailed summary (not shown for brevity)}
\CommentTok{# summary(fit4)}

\CommentTok{# A clean summary, especially for in an rmarkdown file}
\NormalTok{fit4 }\OperatorTok{%>%}\StringTok{ }\NormalTok{pander}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}ccccc@{}}
\caption{Fitting linear model: rating \textasciitilde{} sugars + fiber}\tabularnewline
\toprule
\begin{minipage}[b]{0.21\columnwidth}\centering
~\strut
\end{minipage} & \begin{minipage}[b]{0.13\columnwidth}\centering
Estimate\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\centering
Std. Error\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering
t value\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\centering
Pr(\textgreater{}\textbar{}t\textbar{})\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.21\columnwidth}\centering
~\strut
\end{minipage} & \begin{minipage}[b]{0.13\columnwidth}\centering
Estimate\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\centering
Std. Error\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering
t value\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\centering
Pr(\textgreater{}\textbar{}t\textbar{})\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.21\columnwidth}\centering
\textbf{(Intercept)}\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\centering
52.17\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\centering
1.556\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering
33.54\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\centering
4.266e-46\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\centering
\textbf{sugars}\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\centering
-2.244\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\centering
0.1632\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering
-13.75\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\centering
5.975e-22\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\centering
\textbf{fiber}\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\centering
2.867\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\centering
0.2979\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering
9.623\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\centering
1.276e-14\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

As you can see, we again use the \texttt{pander} package to give super clean results, which can be used in an \texttt{rmarkdown} document. We see here that overall we have an R\textsuperscript{2} of 81\% (not bad), and that both predictors contribute significantly (the P values are very low for both).

Next, we perform some diagnostic plots (shown in Fig. \ref{fig:cerealdiag}). The standard errors (and confidence intervals, and hypothesis tests) will be unreliable if the assumptions of normality (right panel) or linearity (left panel) are seriously violated. If you are only interested in the mean response against your predictors, but not so much their uncertainties, you can usually ignore these plots.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Basic diagnostic plots.}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{car}\OperatorTok{::}\KeywordTok{residualPlot}\NormalTok{(fit4)}
\NormalTok{car}\OperatorTok{::}\KeywordTok{qqPlot}\NormalTok{(fit4)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05-linearregression_files/figure-latex/cerealdiag-1.pdf}
\caption{\label{fig:cerealdiag}Diagnostic plots for linear regression of the Cereals data.}
\end{figure}

\begin{verbatim}
## [1] 27 31
\end{verbatim}

Now that we have a fitted model, what do its predictions actually look like? What relationship have we learned between health rating, sugars, and fiber content? The \texttt{visreg} package provides a very concise method to visualize (many kinds of) fitted regression models.

In this case, the command \texttt{visreg::visreg(fit4)} would show two plots very similar to the ones above - which does not really add much information. What if we can show the effects of both predictors, in just one plot? The following code produces Fig. \ref{fig:visregcereal}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(visreg)}

\KeywordTok{visreg}\NormalTok{(fit4, }\StringTok{"sugars"}\NormalTok{, }\DataTypeTok{by =} \StringTok{"fiber"}\NormalTok{, }\DataTypeTok{overlay =} \OtherTok{TRUE}\NormalTok{, }
       \DataTypeTok{gg =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{lims}\NormalTok{(}\DataTypeTok{y =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{100}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05-linearregression_files/figure-latex/visregcereal-1.pdf}
\caption{\label{fig:visregcereal}Visualizing linear regression of the Cereals data with visreg.}
\end{figure}

Here we clearly, and in one panel, visualize the negative effect of adding more sugar in a cereal, and the positive effect of adding more fiber. The \texttt{visreg} function plots the \emph{predictions} from our model at an arbitrary selection of predictor values (here, 0, 1.5 and 5).

\BeginKnitrBlock{rmdtry}
In the call to \texttt{visreg}, use the argument \texttt{breaks=c(1,5)} to set the predictor values to those of your choice.
\EndKnitrBlock{rmdtry}

We can also make 3D plots, though these are not always useful, and I personally prefer a `pseudo-3D' plot as in the example above to visualize the contribution of two variables.

Of course, we are not restricted to just two predictors, and we can include interactions as well. In the previous model (\texttt{fit4}) the effects of \texttt{fiber} and \texttt{sugars} were \emph{additive}, in other words the effect of fiber was independent of the amount of sugars. We can test this assumption by adding the interaction to the model.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# A multiple regression that includes all main effects as wel as interactions}
\NormalTok{fit5 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(rating }\OperatorTok{~}\StringTok{ }\NormalTok{sugars }\OperatorTok{+}\StringTok{ }\NormalTok{fiber }\OperatorTok{+}\StringTok{ }\NormalTok{fiber}\OperatorTok{:}\NormalTok{sugars, }\DataTypeTok{data=}\NormalTok{cereals)}
\KeywordTok{summary}\NormalTok{(fit5) }\OperatorTok{%>%}\StringTok{ }\NormalTok{pander}\OperatorTok{::}\KeywordTok{pander}\NormalTok{(.)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}ccccc@{}}
\toprule
\begin{minipage}[b]{0.23\columnwidth}\centering
~\strut
\end{minipage} & \begin{minipage}[b]{0.13\columnwidth}\centering
Estimate\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\centering
Std. Error\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering
t value\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\centering
Pr(\textgreater{}\textbar{}t\textbar{})\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.23\columnwidth}\centering
\textbf{(Intercept)}\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\centering
51.38\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\centering
1.695\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering
30.31\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\centering
9.996e-43\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.23\columnwidth}\centering
\textbf{sugars}\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\centering
-2.097\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\centering
0.2056\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering
-10.2\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\centering
1.277e-15\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.23\columnwidth}\centering
\textbf{fiber}\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\centering
3.226\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\centering
0.428\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering
7.537\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\centering
1.12e-10\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.23\columnwidth}\centering
\textbf{sugars:fiber}\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\centering
-0.07363\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\centering
0.06316\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering
-1.166\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\centering
0.2475\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\begin{longtable}[]{@{}cccc@{}}
\caption{Fitting linear model: rating \textasciitilde{} sugars + fiber + fiber:sugars}\tabularnewline
\toprule
\begin{minipage}[b]{0.18\columnwidth}\centering
Observations\strut
\end{minipage} & \begin{minipage}[b]{0.27\columnwidth}\centering
Residual Std. Error\strut
\end{minipage} & \begin{minipage}[b]{0.11\columnwidth}\centering
\(R^2\)\strut
\end{minipage} & \begin{minipage}[b]{0.21\columnwidth}\centering
Adjusted \(R^2\)\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.18\columnwidth}\centering
Observations\strut
\end{minipage} & \begin{minipage}[b]{0.27\columnwidth}\centering
Residual Std. Error\strut
\end{minipage} & \begin{minipage}[b]{0.11\columnwidth}\centering
\(R^2\)\strut
\end{minipage} & \begin{minipage}[b]{0.21\columnwidth}\centering
Adjusted \(R^2\)\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.18\columnwidth}\centering
76\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\centering
6.112\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\centering
0.8198\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\centering
0.8123\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

(\emph{Note}: the formula can also be written as \texttt{fiber*sugars})

In this case, the interaction is not significant: note the large P value for the \emph{sugars:fiber} interaction. We can also inspect the \texttt{AIC}, and notice that the total model AIC has not decreased, which also indicates the model has not improved by adding an interaction term.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{AIC}\NormalTok{(fit4, fit5)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      df      AIC
## fit4  4 496.1572
## fit5  5 496.7359
\end{verbatim}

\hypertarget{lmfaccont}{%
\section{Linear models with factors and continuous variables}\label{lmfaccont}}

So far we have looked at ANOVA, including two-way ANOVA, where a response variable is modelled as dependent on two treatments or factors, and \emph{regression} including multiple linear regression where a response variable is modelled as dependent on two continuous variables. These are just special cases of the \emph{linear model}, and we can extend these simple models by including a mix of factors and continuous predictors. The situation where we have one continuous variable and one factor variable was classically\texttt{known\ as\ ANCOVA\ (analysis\ of\ covariance),\ but\ using\ the}lm` function we can specify any model with a combination of predictors.

In the following example, we inspect the height of trees against the stem diameter (\texttt{DBH}) for the Coweeta example dataset. When plotting all data, we are led to believe that the overall response of height to DBH is highly non-linear (left panel). However, when we fit a simple linear model for each species separately (right panel), the relationship appears to consist of a combination of linear responses.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(coweeta)}

\NormalTok{g1 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(coweeta, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ DBH, }\DataTypeTok{y =}\NormalTok{ height)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{"loess"}\NormalTok{, }\DataTypeTok{se=}\OtherTok{FALSE}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_colour_tableau}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{lims}\NormalTok{(}\DataTypeTok{x=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{60}\NormalTok{), }\DataTypeTok{y=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{30}\NormalTok{))}

\NormalTok{g2 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(coweeta, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ DBH, }\DataTypeTok{y=}\NormalTok{height, }\DataTypeTok{col=}\NormalTok{species)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{"lm"}\NormalTok{, }\DataTypeTok{se=}\OtherTok{FALSE}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_colour_tableau}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{lims}\NormalTok{(}\DataTypeTok{x=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{60}\NormalTok{), }\DataTypeTok{y=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{30}\NormalTok{))}

\KeywordTok{grid.arrange}\NormalTok{(g1, g2, }\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-linearregression_files/figure-latex/coweeta_twoplots-1.pdf}

To fit a model that allows a different response for each species, we use the notation from before:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit6 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(height }\OperatorTok{~}\StringTok{ }\NormalTok{species }\OperatorTok{*}\StringTok{ }\NormalTok{DBH, }\DataTypeTok{data=}\NormalTok{coweeta)}
\end{Highlighting}
\end{Shaded}

\hypertarget{predictedeffects}{%
\subsection{Visualizing fitted regression models}\label{predictedeffects}}

The coefficients associated with a factor predictor in a linear model are given as contrasts (i.e.~differences between factor levels).

While this is useful for comparisons of treatments, it is often more instructive to visualize the predictions at various combinations of factor levels.

A number of options exist to extract and visualize fitted regression models - to make sense of differences between groups, the effects of covariates, and the impact of interactions. We prefer the \texttt{visreg} package, which can be used to make attractive plots of the predictions of a linear model.

The following example makes Fig. \ref{fig:visreg1}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(visreg)}

\CommentTok{# Load data (lgrdata package needed)}
\KeywordTok{data}\NormalTok{(memory)}

\CommentTok{# To make the later results easier to interpret, reorder the Process}
\CommentTok{# factor by the average number of words rememberer (we did this earlier in }
\CommentTok{# the chapter already for this dataset, it is repeated here).}
\NormalTok{memory <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(memory, }
                 \DataTypeTok{Process =} \KeywordTok{reorder}\NormalTok{(Process, Words, mean))}

\CommentTok{# Two linear models: one without, and one with an interaction}
\NormalTok{fit7 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(Words }\OperatorTok{~}\StringTok{ }\NormalTok{Age }\OperatorTok{+}\StringTok{ }\NormalTok{Process, }\DataTypeTok{data=}\NormalTok{memory)}
\NormalTok{fit8 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(Words }\OperatorTok{~}\StringTok{ }\NormalTok{Age}\OperatorTok{*}\NormalTok{Process, }\DataTypeTok{data=}\NormalTok{memory)}

\CommentTok{# Here we specify which variable should be on the X axis (Process),}
\CommentTok{# and which variable should be added with different colours (Age).}
\KeywordTok{visreg}\NormalTok{(fit7, }\StringTok{"Process"}\NormalTok{, }\DataTypeTok{by=}\StringTok{"Age"}\NormalTok{, }\DataTypeTok{overlay=}\OtherTok{TRUE}\NormalTok{)}
\KeywordTok{visreg}\NormalTok{(fit8, }\StringTok{"Process"}\NormalTok{, }\DataTypeTok{by=}\StringTok{"Age"}\NormalTok{, }\DataTypeTok{overlay=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05-linearregression_files/figure-latex/visreg1-1.pdf}
\caption{\label{fig:visreg1}Visualization of two fitted linear model with the visreg package. The model on the right includes an interaction between Process and Age, the model on the left does not.}
\end{figure}

You can test for yourself that the interaction is a highly significant predictor in the model.

\hypertarget{icecreamtest}{%
\subsection{Group differences in regression models: back to ice cream sales}\label{icecreamtest}}

At the beginning of this chapter (Section \ref{icecream}), we looked at an example where including a covariate drastically changed our conclusions about an effect. Simply testing the difference between two locations where we sold ice creams showed no effect, but including temperature at a covariate, it appeared that \emph{at a given temperature}, there was a difference between the locations.

Here, we continue this example as it shows that we need to closely inspect a fitted model before making any conclusions - and that estimated coefficients of a regression model can lead to wrong conclusions, if not carefully examined.

To continue, first read in the icecream data as shown in Section \ref{icecream}.
We now fit a linear model with one numeric, and one factor variable. We immediately include all effects, including the interaction.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_ice1 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(sales }\OperatorTok{~}\StringTok{ }\NormalTok{location }\OperatorTok{*}\StringTok{ }\NormalTok{temperature, }\DataTypeTok{data=}\NormalTok{icecream)}
\end{Highlighting}
\end{Shaded}

You can inspect all details in the summary of this model yourself (\texttt{summary(lm\_ice1)}) - here we just look at the estimated coefficients from the model. Recall that in a linear model, the intercept is assigned to the first level of the factor variable in the model, in this case \texttt{levels(icecream\$location)} shows that this is `Dappermarkt'.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pander}\NormalTok{(lm_ice1)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}ccccc@{}}
\caption{Fitting linear model: sales \textasciitilde{} location * temperature}\tabularnewline
\toprule
\begin{minipage}[b]{0.38\columnwidth}\centering
~\strut
\end{minipage} & \begin{minipage}[b]{0.11\columnwidth}\centering
Estimate\strut
\end{minipage} & \begin{minipage}[b]{0.13\columnwidth}\centering
Std. Error\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\centering
t value\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering
Pr(\textgreater{}\textbar{}t\textbar{})\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.38\columnwidth}\centering
~\strut
\end{minipage} & \begin{minipage}[b]{0.11\columnwidth}\centering
Estimate\strut
\end{minipage} & \begin{minipage}[b]{0.13\columnwidth}\centering
Std. Error\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\centering
t value\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering
Pr(\textgreater{}\textbar{}t\textbar{})\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.38\columnwidth}\centering
\textbf{(Intercept)}\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\centering
78.41\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\centering
27.72\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\centering
2.829\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering
0.00759\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.38\columnwidth}\centering
\textbf{locationOosterpark}\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\centering
99.64\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\centering
42.53\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\centering
2.343\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering
0.02477\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.38\columnwidth}\centering
\textbf{temperature}\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\centering
37.48\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\centering
1.704\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\centering
22\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering
1.837e-22\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.38\columnwidth}\centering
\textbf{locationOosterpark:temperature}\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\centering
-11.19\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\centering
2.255\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\centering
-4.963\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering
1.683e-05\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Four coefficients are shown, these are:

\begin{itemize}
\tightlist
\item
  \emph{Intercept} : ice cream sales for the first level of `Location' (Dappermarkt), when temperature equals zero (i.e.~the intersection of the regression line with the y-axis when x = 0).
\item
  \emph{locationOosterpark} : The difference in intercept for Oosterpark location, compared to the first level (Dappermarkt). A positive value here seems to indicate higher sales at the Oosterpark location (when temperature is zero - read further below!).
\item
  \emph{temperature} : The slope of sales per unit temperature (i.e.~for every degree increase in temperature, sales go up this much), for Dappermarkt.
\item
  \emph{locationOosterpark:temperature} : the difference in \emph{slope} for the Oosterpark, compared to Dappermarkt. This shows the slope is lower for Oosterpark.
\end{itemize}

Based on the above, it seems difficult to draw conclusions about the difference between locations. This is because the intercept is not at all informative: it quantifies ice cream sales when temperature equals zero, but we do not even try to sell ice cream when it is cold outside. To visualize what is going on, we modify the standard \texttt{visreg} plot to draw the regression lines all the way to zero. We also show how to adjust the appearance of the plot (see \texttt{?plot.visreg} for details).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{visreg}\NormalTok{(lm_ice1, }\StringTok{"temperature"}\NormalTok{, }\DataTypeTok{by=}\StringTok{"location"}\NormalTok{, }
       \DataTypeTok{overlay =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{xlim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{40}\NormalTok{),}
       \DataTypeTok{line.par=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"dimgrey"}\NormalTok{,}\StringTok{"grey"}\NormalTok{)),}
       \DataTypeTok{fill.par=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"#BEBEBE80"}\NormalTok{,}\StringTok{"#BEBEBE80"}\NormalTok{)),}
       \DataTypeTok{points.par=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"dimgrey"}\NormalTok{,}\StringTok{"grey"}\NormalTok{), }\DataTypeTok{cex=}\FloatTok{1.2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-linearregression_files/figure-latex/unnamed-chunk-49-1.pdf}

We now see that the regression lines `cross over' around a temperature of 10, giving a higher intercept for Oosterpark.

A meaningful test in situations like this is to test for group differences \emph{at a given value of our covariate(s)}. A number of approaches exist in various add-on packages, but we prefer to first show the basic approach using \texttt{predict} - a function that has methods for practically all models we use. It also offers great flexibility, and we don't have to wonder what exactly we are testing.

Somewhat arbitrarily, we want to test for location differences at a temperature of 25 degrees. To do this, I will construct confidence intervals for both locations, as follows. In the call to \texttt{predict}, it is important to list values for all variables in the model. This makes this approach less practical for models with many more regressors (see below for another approach).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Predict from model, at temperature =25.}
\NormalTok{pred_ice <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(lm_ice1, }
                    \DataTypeTok{newdata =} \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{temperature =} \DecValTok{25}\NormalTok{, }
                                         \DataTypeTok{location =} \KeywordTok{levels}\NormalTok{(icecream}\OperatorTok{$}\NormalTok{location)),}
                    \DataTypeTok{se =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

If you inspect this object, you will find that sales at Dappermarkt are 1015.4 with a standard error of 18.1, and sales at Oosterpark are 835.2 (SE 10.1). The standard errors may be used to construct approximate 95\% confidence intervals (by using twice the standard error).

A more convenient approach is to use the \texttt{emmeans} package to extract \emph{marginal effects} of our fitted model. The default approach in this package is to test for group differences at the average level of other predictors. This approach is also called `least-square means'. However, we can adjust what value we want to use.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(emmeans)}
\KeywordTok{emmeans}\NormalTok{(lm_ice1, }\DataTypeTok{specs =} \StringTok{"location"}\NormalTok{, }\DataTypeTok{at =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{temperature =} \DecValTok{25}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## NOTE: Results may be misleading due to involvement in interactions
\end{verbatim}

\begin{verbatim}
##  location    emmean   SE df lower.CL upper.CL
##  Dappermarkt   1015 18.1 36      979     1052
##  Oosterpark     835 10.1 36      815      856
## 
## Confidence level used: 0.95
\end{verbatim}

You can ignore the warning in this case, since we have used both the predictors in our model - there are no other `hidden' predictors that may complicate matters. As you can see for yourself, the \texttt{emmeans} package gives the same results as the basic \texttt{predict} approach, but it is certainly much more practical.

\hypertarget{logtransform}{%
\subsection{Logarithmic transformation}\label{logtransform}}

For data that are very heteroscedasctic, that is, have quickly increasing variance with the value of the predictor, it is usually necessary to use a logarithm transformation of the data. In extreme cases, not applying the log-transform leads to very poor model fits, with very large influence of a few points, and possibly a fit that does not describe the data well at all.

See Fig. \ref{fig:cowtransform} for an example where a log-transform is used.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(coweeta)}
\KeywordTok{library}\NormalTok{(scales)}

\NormalTok{g1 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(coweeta, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ biomass, }\DataTypeTok{y =}\NormalTok{ folmass)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Mass of tree (kg)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Mass of leaves (kg)"}\NormalTok{)}
    
\NormalTok{g2 <-}\StringTok{ }\NormalTok{g1 }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale_x_log10}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale_y_log10}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{annotation_logticks}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{expand_limits}\NormalTok{(}\DataTypeTok{x=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{10}\OperatorTok{^}\DecValTok{4}\NormalTok{), }\DataTypeTok{y=}\DecValTok{100}\NormalTok{)}

\KeywordTok{grid.arrange}\NormalTok{(g1, g2, }\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05-linearregression_files/figure-latex/cowtransform-1.pdf}
\caption{\label{fig:cowtransform}An example of a dataset that screams for a logarithmic transformation. Left panel: untransformed data, showing very non-constant variance, indicating larger variation in the response variable for larger individuals. Right panel: both variables have been log-transformed, giving a nice linear relationship with constant variance.}
\end{figure}

\BeginKnitrBlock{rmdtry}
Redo the above plot, using \texttt{origin} (i.e.~American, Japanese or European) to color the symbols. This is another good example that you should always consider covariates in a linear model.
\EndKnitrBlock{rmdtry}

The following code fits two linear models to the data above, one to the raw, untransformed data, and one after log10-transforming both the predictor and the response variable. In previous examples we used \texttt{residualPlot} from the \texttt{car} package to quickly make plots of residuals versus fitted values, here we implement a simple version using \texttt{ggplot2} (and note that we jump ahead and define our own function, a topic we return to in Chapter @()).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm1 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(folmass }\OperatorTok{~}\StringTok{ }\NormalTok{biomass, }\DataTypeTok{data =}\NormalTok{ coweeta)}
\NormalTok{lm2 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\KeywordTok{log10}\NormalTok{(folmass) }\OperatorTok{~}\StringTok{ }\KeywordTok{log10}\NormalTok{(biomass), }\DataTypeTok{data =}\NormalTok{ coweeta)}

\NormalTok{residPlot <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(model)\{}
  \KeywordTok{ggplot}\NormalTok{(model, }\KeywordTok{aes}\NormalTok{(.fitted, .resid)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{0}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{    }\KeywordTok{stat_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{"loess"}\NormalTok{, }\DataTypeTok{span=}\FloatTok{0.8}\NormalTok{)}
\NormalTok{\}}

\KeywordTok{grid.arrange}\NormalTok{(}\KeywordTok{residPlot}\NormalTok{(lm1), }\KeywordTok{residPlot}\NormalTok{(lm2), }\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05-linearregression_files/figure-latex/cowdiagnostics-1.pdf}
\caption{\label{fig:cowdiagnostics}Residuals versus fitted for the Coweeta biomass regression model, either without (left panel) or with (right panel) log-transformation of x and y variables.}
\end{figure}

As Fig. \ref{fig:cowdiagnostics} shows, the log-transformation results in much better model diagnostics. We can expect that the model will give an overall better fit to the data, because when we did not transform, the location of the regression line will be overly influenced by values far away from the line. After transformation, this effect will be much reduced, and the model will be more robust.

Second, the standard errors of the coefficients in the untransformed fit are very much biased, leading to confidence intervals that are much too narrow. In this case, a log-transformation could be used to remedy this problem, but in other cases we want to avoid transformations, or they are simply not adequate. In that case, we might use the bootstrap.

This well known and often used transformation does have some consequences for interpreting the linear model fit that are often misunderstood. The key aspect to understand is that the model is no longer \emph{additive} as the usual linear model (where effects of predicts are simply added), but rather \emph{multiplicative} (effects of various predictors are \emph{multiplied}). This has consequences for understanding interactions in the model as well.

\hypertarget{quadlm}{%
\subsection{Adding quadratic and polynomial terms}\label{quadlm}}

So far we have seen models with just linear terms, but it is straightforward and often necessary to add quadratic (\(x^2\)) or higher-order terms (e.g.~\(x^3\)) when the response variable is far from linear in the predictors. You can add any transformation of the predictors in an \texttt{lm} model by nesting the transformation inside the \texttt{I()} function, like so:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(allometry)}
\NormalTok{lmq1 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(height }\OperatorTok{~}\StringTok{ }\NormalTok{diameter }\OperatorTok{+}\StringTok{ }\KeywordTok{I}\NormalTok{(diameter}\OperatorTok{^}\DecValTok{2}\NormalTok{), }\DataTypeTok{data=}\NormalTok{allometry)}
\end{Highlighting}
\end{Shaded}

This model fits both the linear (\texttt{diameter}) and squared terms (\texttt{I(diameter\textbackslash{}\^{}2)}) of the predictor, as well as the usual intercept term. If you want to fit all polynomial terms up to some order, you can use the \texttt{poly} function like so,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lmq1 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(height }\OperatorTok{~}\StringTok{ }\KeywordTok{poly}\NormalTok{(diameter, }\DecValTok{2}\NormalTok{), }\DataTypeTok{data=}\NormalTok{allometry)}
\end{Highlighting}
\end{Shaded}

This model specification is exactly equivalent to the above, and is more convenient when you have multiple quadratic / polynomial terms and interactions with factor variables.

The following example quickly tests whether a quadratic term improves the model fit of \texttt{height} vs.~\texttt{diameter} for the species \texttt{PIPO} in the allometry dataset.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(allometry)}
\NormalTok{pipo <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(allometry, species }\OperatorTok{==}\StringTok{ "PIPO"}\NormalTok{)}

\CommentTok{# Fit model with the quadratic term:}
\NormalTok{lmq2 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(height }\OperatorTok{~}\StringTok{ }\NormalTok{diameter }\OperatorTok{+}\StringTok{ }\KeywordTok{I}\NormalTok{(diameter}\OperatorTok{^}\DecValTok{2}\NormalTok{), }\DataTypeTok{data=}\NormalTok{pipo)}

\CommentTok{# The very small p-value for the quadratic terms shows that the }
\CommentTok{# relationship is clearly not linear, but better described with a }
\CommentTok{# quadratic model.}
\KeywordTok{Anova}\NormalTok{(lmq2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Anova Table (Type II tests)
## 
## Response: height
##               Sum Sq Df F value    Pr(>F)    
## diameter      821.25  1  53.838 5.905e-07 ***
## I(diameter^2) 365.78  1  23.980 0.0001001 ***
## Residuals     289.83 19                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

When fitting a quadratic model, it is again very useful to use \texttt{visreg} to inspect the model that is estimated, since it becomes even more difficult to make sense of the various linear, quadratic, and intercept terms, especially when interactions with factor variables are added. Consider this example for the allometry dataset, which makes Fig. \ref{fig:allomquad}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Fit a linear model with linear, quadratic terms, and all species interactions.}
\NormalTok{allomquadfit <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(height }\OperatorTok{~}\StringTok{ }\KeywordTok{poly}\NormalTok{(diameter, }\DecValTok{2}\NormalTok{)}\OperatorTok{*}\NormalTok{species, }\DataTypeTok{data=}\NormalTok{allometry)}

\CommentTok{# Inspect summary(allomquadfit) to confirm you cannot possibly make sense of this}
\CommentTok{# many coefficients.}

\CommentTok{# But plotting the predictions is much easier to understand:}
\KeywordTok{visreg}\NormalTok{(allomquadfit, }\StringTok{"diameter"}\NormalTok{, }\DataTypeTok{by=}\StringTok{"species"}\NormalTok{, }\DataTypeTok{overlay=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05-linearregression_files/figure-latex/allomquad-1.pdf}
\caption{\label{fig:allomquad}Height modelled as a quadratic function of diameter, by species.}
\end{figure}

\hypertarget{which-predictors-are-more-important}{%
\subsection{Which predictors are more important?}\label{which-predictors-are-more-important}}

Frequently we are interested in knowing which of the predictor variables explain more variation in the response variable, in other words are more strongly correlated with the response.

One often-seen approach is to compute all correlations between the response and each of the predictors, and conclude that those with higher correlation coefficients will be most important. The flaw in this approach is that predictor variables are very often correlated with each other, making the approach potentially misleading. Cross-correlations between variables can easily hide important predictor variables. Nonetheless it can be a useful start, as we do here with the \texttt{automobiles} data. The following code makes Fig. \ref{fig:mobilecorplot}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(automobiles)}

\CommentTok{# A modern implementation of a correlation plot in the corrplot package.}
\KeywordTok{library}\NormalTok{(corrplot)}
\NormalTok{auto_cor <-}\StringTok{ }\KeywordTok{cor}\NormalTok{(automobiles[,}\DecValTok{4}\OperatorTok{:}\DecValTok{9}\NormalTok{], }\DataTypeTok{use =} \StringTok{"complete.obs"}\NormalTok{)}
\KeywordTok{corrplot}\NormalTok{(auto_cor, }\DataTypeTok{method =} \StringTok{"ellipse"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05-linearregression_files/figure-latex/mobilecorplot-1.pdf}
\caption{\label{fig:mobilecorplot}Correlation plot for the automobiles data.}
\end{figure}

As we can see in Fig. \ref{fig:mobilecorplot}, the response variable (fuel\_efficiency) seems well correlated with four of the response variables, but weaker with \texttt{acceleration}.

Sometimes we see the use of the absolute value of the t-statistic to rank variables by `importance' in the regression model. Within a single model, the t-statistic will be exactly related to the p-value (low p-values mean large t-statistic). Both t-statistics and p-values are very poor measures of importance. A large t-statistic may also arise when the sample size is large, the measurements are accurate, or there is low variability overall.

Instead what we are often interested in is how much variation is explained by each variable in the model. This calculation is complicated by the fact that predictor variables tend to be correlated with each other, so you cannot simply add up the R\textsuperscript{2} due to each predictor separately.

The \texttt{relaimpo} package includes a number of importance measures - the recommended version can be interpreted as the \% variation explained by each predictor variable:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# A model with five predictors}
\NormalTok{fit_fuel1 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(fuel_efficiency }\OperatorTok{~}\StringTok{ }\NormalTok{cylinders }\OperatorTok{+}\StringTok{ }\NormalTok{engine_volume }\OperatorTok{+}
\StringTok{                                  }\NormalTok{horsepower }\OperatorTok{+}\StringTok{ }\NormalTok{weight }\OperatorTok{+}\StringTok{ }\NormalTok{acceleration,}
                \DataTypeTok{data =}\NormalTok{ automobiles)}

\CommentTok{# For importance measures}
\KeywordTok{library}\NormalTok{(relaimpo)}

\CommentTok{# recommended method lmg in relaimpo}
\NormalTok{imp_fitfuel <-}\StringTok{ }\KeywordTok{calc.relimp}\NormalTok{(fit_fuel1, }\DataTypeTok{type=}\StringTok{"lmg"}\NormalTok{)}

\CommentTok{# The resulting object is a bit complicated.}
\CommentTok{# If you print the object (simply type imp_fitfuel), lots of information is given.}
\CommentTok{# Instead we just need this:}
\KeywordTok{sort}\NormalTok{(imp_fitfuel}\OperatorTok{$}\NormalTok{lmg, }\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        weight    horsepower engine_volume     cylinders  acceleration 
##    0.21667697    0.19895781    0.18619931    0.17158534    0.04737539
\end{verbatim}

The values mean that \texttt{weight} explains 21\% of the variation, but acceleration only 4\%. Note that the sum of these values adds up (nearly precisely) to the R\textsuperscript{2} of the model (look at \texttt{summary(fit\_fuel1)}).

\BeginKnitrBlock{rmdtry}
A more common approach is to test how mucb the R\textsuperscript{2} decreases if a predictor is dropped from the model. When important variables are removed, the model fits a lot worse overall. This can be achieved via:

\texttt{drop1(fit\_fuel1)}

Where RSS is the `residual sum of squares' after dropping the term; higher means the variable is `more important'.
\EndKnitrBlock{rmdtry}

\hypertarget{programming}{%
\chapter{Functions, lists and loops}\label{programming}}

\hypertarget{introduction-3}{%
\section{Introduction}\label{introduction-3}}

This chapter demonstrates some building blocks of programming with R. The main purpose here is to allow batch analyses - repeating similar tasks for many subsets of data. To do this, we first have to know how to write our own functions, so that we can apply the custom function to any new subset of data. This approach results in far less, and much more readable code than copy-pasting similar code for different datasets.

We also delve into ``lists'' in R, a versatile data object that you have worked with already - even if you didn't know it. Understanding lists well in R is the key to more complex analyses, and more readable workflows.

Finally we take a brief look at `for loops', a basic programming utility that we rarely need in R, since almost all functions are vectorized. Sometimes it is however more convenient to use loops, or makes the code just a little more easy to work with.

\textbf{Packages used in this chapter}

We use no new packages in this chapter except the \texttt{wrapr} package. All other functionality is included in base R, or commonly used packages \texttt{dplyr}, \texttt{ggplot2}, \texttt{lubridate}, and \texttt{lgrdata} for the example data.

\hypertarget{writefunctions}{%
\section{Writing simple functions}\label{writefunctions}}

We have already used many built-in functions throughout this tutorial, but you can become very efficient at complex data tasks when you write your own simple functions. Writing your own functions can help with tasks that are carried out many times, which would otherwise result in a lot of code.

For example, suppose you frequently convert units from pounds to kilograms. It would be useful to have a function that does this, so you don't have to type the conversion factor every time. This is also good practice, as it reduces the probability of making typos.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# This function takes a 'weight' argument and multiplies it with some number }
\CommentTok{# to return kilograms.}
\NormalTok{poundsToKg <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(weight)\{}
\NormalTok{  weight }\OperatorTok{*}\StringTok{ }\FloatTok{0.453592}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

We can use this \texttt{function} just like any other in R, for example, let's convert `weight' to kilograms in the weightloss data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Read data}
\KeywordTok{library}\NormalTok{(lgrdata)}
\KeywordTok{data}\NormalTok{(weightloss)}

\CommentTok{# Convert weight to kg.}
\NormalTok{weightloss}\OperatorTok{$}\NormalTok{Weight <-}\StringTok{ }\KeywordTok{poundsToKg}\NormalTok{(weightloss}\OperatorTok{$}\NormalTok{Weight)}
\end{Highlighting}
\end{Shaded}

Let's write a function for the standard error of the mean, a function that is not built-in in R.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Compute the standard error of the mean for a vector}
\NormalTok{SEmean <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x)\{}
\NormalTok{  se <-}\StringTok{ }\KeywordTok{sd}\NormalTok{(x) }\OperatorTok{/}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{length}\NormalTok{(x))}
  \KeywordTok{return}\NormalTok{(se)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Here, the \texttt{function} SEmean takes one `argument' called \texttt{x} (i.e., input), which is a numeric vector. The standard error for the mean is calculated in the first line, and stored in an object called \texttt{se}, which is then returned as output. We can now use the function on a numeric vector like this:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# A numeric vector}
\NormalTok{unifvec <-}\StringTok{ }\KeywordTok{runif}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}

\CommentTok{# The sample mean}
\KeywordTok{mean}\NormalTok{(unifvec)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.38083
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Standard error for the mean}
\KeywordTok{SEmean}\NormalTok{(unifvec)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.0767329
\end{verbatim}

\BeginKnitrBlock{rmdtry}
You can use functions that you defined yourself just like any other function, for example in \texttt{summaryBy}. First read in the \texttt{SEmean} function defined in the example above, and then use the cereal data to calculate the mean and SE of \texttt{rating} by \texttt{Manufacturer} (or use data of your choosing).
\EndKnitrBlock{rmdtry}

\hypertarget{functions-with-many-arguments}{%
\subsection{Functions with many arguments}\label{functions-with-many-arguments}}

Functions can also have multiple arguments. The following very simple function takes two numbers, and finds the absolute difference between them, using \texttt{abs}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Define function}
\NormalTok{absDiff <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(num1,num2)}\KeywordTok{abs}\NormalTok{(num1 }\OperatorTok{-}\StringTok{ }\NormalTok{num2)}

\CommentTok{# Test it with two numbers:}
\KeywordTok{absDiff}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# As in many functions in R, you can also give multiple values}
\CommentTok{# as an argument.}
\CommentTok{# The following returns the absolute difference between }
\CommentTok{# 1 and 3, then 5 and 6, and 9 and 0 (in that order).}
\KeywordTok{absDiff}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{9}\NormalTok{), }\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2 1 9
\end{verbatim}

\hypertarget{functions-can-return-many-results}{%
\subsection{Functions can return many results}\label{functions-can-return-many-results}}

What if a function should return not just one result, as in the examples above, but many results?

For example, this function computes the standard deviation and standard error of a vector, and returns both stored in a vector. Note that we also use the \texttt{SEmean} function, which we defined above.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# An function that computes the SE and SD of a vector}
\NormalTok{seandsd <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x)\{}
  
\NormalTok{  seresult <-}\StringTok{ }\KeywordTok{SEmean}\NormalTok{(x)}
\NormalTok{  sdresult <-}\StringTok{ }\KeywordTok{sd}\NormalTok{(x)}

  \CommentTok{# Store results in a vector with names}
\NormalTok{  vec <-}\StringTok{ }\KeywordTok{c}\NormalTok{(seresult, sdresult)}
  \KeywordTok{names}\NormalTok{(vec) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"SE"}\NormalTok{,}\StringTok{"SD"}\NormalTok{)}

\KeywordTok{return}\NormalTok{(vec)}
\NormalTok{\}}

\CommentTok{# Test it:}
\NormalTok{x <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DataTypeTok{mean=}\DecValTok{20}\NormalTok{, }\DataTypeTok{sd=}\DecValTok{4}\NormalTok{)}
\KeywordTok{seandsd}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        SE        SD 
## 0.3553867 3.5538671
\end{verbatim}

\hypertarget{functions-without-arguments}{%
\subsection{Functions without arguments}\label{functions-without-arguments}}

Sometimes, a function takes no arguments (input) at all. Consider this very helpful example.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sayhello <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{()}\KeywordTok{message}\NormalTok{(}\StringTok{"Hello!"}\NormalTok{)}

\KeywordTok{sayhello}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Hello!
\end{verbatim}

We will return to defining our own functions when we look at applying functions many times to sections of a dataframe (Section \ref{lapply}).

\hypertarget{wrapfunctions}{%
\subsection{Wrapper functions}\label{wrapfunctions}}

We often need to write simple functions that adjust one or two arguments to other functions. For example, suppose we often make plots with filled circles, with our favorit color (``dimgrey'') :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lgrdata)}
\KeywordTok{data}\NormalTok{(howell)}
\KeywordTok{plot}\NormalTok{(age, height, }\DataTypeTok{data=}\NormalTok{howell, }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{col=}\StringTok{"dimgrey"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We could of course \emph{always} specify these arguments, or we can write a function that sets those defaults. It would look like the following, except this function is incomplete, since we have \emph{hardcoded} the other plotting arguments (the dataset, and the x and y variables):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# This function is not how we want it yet!}
\NormalTok{plot_filled_grey <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{()\{}
  \KeywordTok{plot}\NormalTok{(age, height, }\DataTypeTok{data=}\NormalTok{howell, }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{col=}\StringTok{"dimgrey"}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

We would like to be able to call the function via \texttt{plot\_filled\_grey(age,\ height,\ data=howell)}, in other words all arguments to our \emph{wrapper function} should be passed to the underlying function. We have a very handy utility in R to do this, the three dots (\texttt{...}) :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot_filled_grey <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(...)\{}
  \KeywordTok{plot}\NormalTok{(..., }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{col=}\StringTok{"dimgrey"}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The function now works as intended. It can be further improved if we realize that the plotting color cannot be changed - it is always ``dimgrey''. We want the \emph{default} value to be ``dimgrey'', but with an option to change it. This can be achieved like so,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot_filled_grey <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(..., }\DataTypeTok{col=}\StringTok{"dimgrey"}\NormalTok{)\{}
  \KeywordTok{plot}\NormalTok{(..., }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{col=}\NormalTok{col)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Here, \texttt{col=col} sets the color in the call to \texttt{plot} with the default value specified in the wrapper function (``dimgrey''), but the user can also change it as usual.

\BeginKnitrBlock{rmdtry}
Take the \texttt{plot\_filled\_grey} function above, test it on some data, and modify it so that the plotting symbol can also be changed, but has a default value of 19.
\EndKnitrBlock{rmdtry}

\hypertarget{wrapper-functions-to-ggplot2-or-dplyr}{%
\subsection{\texorpdfstring{Wrapper functions to \texttt{ggplot2} or \texttt{dplyr}}{Wrapper functions to ggplot2 or dplyr}}\label{wrapper-functions-to-ggplot2-or-dplyr}}

In the previous section we saw how to write wrapper functions, functions that change a few arguments to some other function. These sort of functions are very helpful because we can save a lot of space by reusing a certain template. Suppose we want to make a plot with \texttt{ggplot2}, a scatter plot with a loess smoother line. We can achieve this via (result not shown),

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(howell)}
\KeywordTok{library}\NormalTok{(ggplot2)}

\KeywordTok{ggplot}\NormalTok{(howell, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ weight, }\DataTypeTok{y =}\NormalTok{ height)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size =} \FloatTok{0.8}\NormalTok{, }\DataTypeTok{col =} \StringTok{"dimgrey"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{stat_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"loess"}\NormalTok{, }\DataTypeTok{span =} \FloatTok{0.7}\NormalTok{, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We already used quite a bit of code for this simple plot, but imagine you have set various other options, formatting changes, axis limits and so on - you end up with a lot of code for one plot. If we want to reuse the code for another plot, for two other variables from the same dataframe, copy-pasting the code and modifying leads to even more code. Writing wrapper functions for \texttt{ggplot2} (or \texttt{dplyr}, see below, or many other cases) is more difficult because the arguments in the \texttt{ggplot2} code we want to change (height and weight) \emph{are not quoted} - they are variables inside a dataframe (\texttt{howell} in our case). We avoid a more technical explanation of this problem, but simply present a solution with the \texttt{wrapr} package.

Using \texttt{let} from \texttt{wrapr}, we can turn our unquoted variables into quoted ones, like so:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(wrapr)}

\KeywordTok{let}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DataTypeTok{xvar =} \StringTok{"weight"}\NormalTok{, }\DataTypeTok{yvar =} \StringTok{"height"}\NormalTok{), \{}
  \KeywordTok{ggplot}\NormalTok{(howell, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ xvar, }\DataTypeTok{y =}\NormalTok{ yvar)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size =} \FloatTok{0.8}\NormalTok{, }\DataTypeTok{col =} \StringTok{"dimgrey"}\NormalTok{)}
\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

The point of placing our plotting code inside \texttt{let} is that we can now write our simple wrapper function like before:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Make a scatter plot with the howell data.}
\NormalTok{plot_scatter_howell <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(xcol, ycol)\{}
  \KeywordTok{let}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DataTypeTok{xvar =}\NormalTok{ xcol, }\DataTypeTok{yvar =}\NormalTok{ ycol), \{}
    \KeywordTok{ggplot}\NormalTok{(howell, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ xvar, }\DataTypeTok{y =}\NormalTok{ yvar)) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size =} \FloatTok{0.8}\NormalTok{, }\DataTypeTok{col =} \StringTok{"dimgrey"}\NormalTok{)}
\NormalTok{  \})}
\NormalTok{\}}

\CommentTok{# The function can be used with quoted names:}
\KeywordTok{plot_scatter}\NormalTok{(}\StringTok{"height"}\NormalTok{, }\StringTok{"weight"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

It is important to understand that, in this example, \texttt{let} is used \emph{only to turn character arguments into unquoted names}, in this case ``height'' turns into \texttt{height} for use in \texttt{ggplot}, and so on. We cannot pass \texttt{height} and \texttt{weight} as unquoted names, because R would look for those objects directly (from the `global environment'), rather than as variables in the \texttt{howell} dataset.

To also pass the dataset as an argument (making the function more general), we do not have to use \texttt{let}, but can immediately set it as an argument (because it is available in the global environment).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Our function now also takes a dataset as an argument}
\NormalTok{plot_scatter <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(xcol, ycol, dataset)\{}
  \KeywordTok{let}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DataTypeTok{xvar =}\NormalTok{ xcol, }\DataTypeTok{yvar =}\NormalTok{ ycol), \{}
    \KeywordTok{ggplot}\NormalTok{(dataset, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ xvar, }\DataTypeTok{y =}\NormalTok{ yvar)) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size =} \FloatTok{0.8}\NormalTok{, }\DataTypeTok{col =} \StringTok{"dimgrey"}\NormalTok{)}
\NormalTok{  \})}
\NormalTok{\}}

\CommentTok{# We can use it as,}
\KeywordTok{plot_scatter}\NormalTok{(}\StringTok{"height"}\NormalTok{, }\StringTok{"weight"}\NormalTok{, howell)}
\end{Highlighting}
\end{Shaded}

\hypertarget{workinglists}{%
\section{Working with lists}\label{workinglists}}

Sofar, we have worked a lot with vectors, with are basically strings of numbers or bits of text. In a vector, each element has to be of the same data type. Lists are a more general and powerful type of vector, where each element of the \texttt{list} can be anything at all. This way, lists are a very flexible type of object to store a lot of information that may be in different formats.

Lists can be somewhat daunting for the beginning \texttt{R} user, which is why most introductory texts and tutorials skip them altogether. However, with some practice, lists can be mastered from the start. Mastering a few basic skills with lists can really help increase your efficiency in dealing with more complex data analysis tasks.

To make a list from scratch, you simply use the \texttt{list} function. Here is a list that contains a numeric vector, a character vector, and a dataframe:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mylist <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{a=}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{, }\DataTypeTok{txt=}\KeywordTok{c}\NormalTok{(}\StringTok{"hello"}\NormalTok{,}\StringTok{"world"}\NormalTok{), }\DataTypeTok{dfr=}\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{),}\DataTypeTok{y=}\KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\hypertarget{indexing-lists}{%
\subsection{Indexing lists}\label{indexing-lists}}

To extract an element from this list, you may do this by its name (`a',`txt' or `dfr' in this case), or by the element number (1,2,3). For lists, we use a double square bracket for indexing. Consider these examples,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extract the dataframe:}
\NormalTok{mylist[[}\StringTok{"dfr"}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   x y
## 1 2 5
## 2 3 6
## 3 4 7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Is the same as:}
\NormalTok{mylist}\OperatorTok{$}\NormalTok{dfr}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   x y
## 1 2 5
## 2 3 6
## 3 4 7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extract the first element:}
\NormalTok{mylist[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}

Note that in these examples, the contents of the elements of the list are returned (for `dfr', a dataframe), but the result itself is not a list anymore. If we select multiple elements, the result should still be a list. To do this, use the single square bracket.

Look at these examples:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extract the 'a' vector, result is a vector:}
\NormalTok{mylist[[}\StringTok{'a'}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extract the 'a' vector, result is a list:}
\NormalTok{mylist[}\StringTok{'a'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $a
##  [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Extract multiple elements (result is still a list):}
\NormalTok{mylist[}\DecValTok{2}\OperatorTok{:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $txt
## [1] "hello" "world"
## 
## $dfr
##   x y
## 1 2 5
## 2 3 6
## 3 4 7
\end{verbatim}

\hypertarget{converting-lists-to-dataframes-or-vectors}{%
\subsection{Converting lists to dataframes or vectors}\label{converting-lists-to-dataframes-or-vectors}}

Although lists are the most flexible way to store data and other objects in larger, more complex, analyses, ultimately you would prefer to output as a dataframe or vector.

Let's look at some examples using \texttt{do.call(rbind,...)} and \texttt{unlist}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# A list of dataframes:}
\NormalTok{dfrlis <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{data1=}\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{a=}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{,}\DataTypeTok{b=}\DecValTok{2}\OperatorTok{:}\DecValTok{4}\NormalTok{), }\DataTypeTok{data2=}\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{a=}\DecValTok{9}\OperatorTok{:}\DecValTok{11}\NormalTok{,}\DataTypeTok{b=}\DecValTok{15}\OperatorTok{:}\DecValTok{17}\NormalTok{))}
\NormalTok{dfrlis}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $data1
##   a b
## 1 1 2
## 2 2 3
## 3 3 4
## 
## $data2
##    a  b
## 1  9 15
## 2 10 16
## 3 11 17
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Since both dataframes in the list have the same number of columns and names, }
\CommentTok{# we can 'successively row-bind' the list like this:}
\KeywordTok{do.call}\NormalTok{(rbind, dfrlis)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          a  b
## data1.1  1  2
## data1.2  2  3
## data1.3  3  4
## data2.1  9 15
## data2.2 10 16
## data2.3 11 17
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# A list of vectors:}
\NormalTok{veclis <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{a=}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{, }\DataTypeTok{b=}\DecValTok{2}\OperatorTok{:}\DecValTok{4}\NormalTok{, }\DataTypeTok{f=}\DecValTok{9}\OperatorTok{:}\DecValTok{11}\NormalTok{)}

\CommentTok{# In this case, we can use the 'unlist' function, which will }
\CommentTok{# successively combine the three vectors into one:}
\KeywordTok{unlist}\NormalTok{(veclis)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## a1 a2 a3 b1 b2 b3 f1 f2 f3 
##  1  2  3  2  3  4  9 10 11
\end{verbatim}

In real-world applications, some trial-and-error will be necessary to convert lists to more pretty formats.

\hypertarget{combining-lists}{%
\subsection{Combining lists}\label{combining-lists}}

Combining two lists can be achieved using \texttt{c()}, like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{veclis <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{a=}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{, }\DataTypeTok{b=}\DecValTok{2}\OperatorTok{:}\DecValTok{4}\NormalTok{, }\DataTypeTok{f=}\DecValTok{9}\OperatorTok{:}\DecValTok{11}\NormalTok{)}
\NormalTok{qlis <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{q=}\DecValTok{17}\OperatorTok{:}\DecValTok{15}\NormalTok{)}
\KeywordTok{c}\NormalTok{(veclis,qlis)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $a
## [1] 1 2 3
## 
## $b
## [1] 2 3 4
## 
## $f
## [1]  9 10 11
## 
## $q
## [1] 17 16 15
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# But be careful when you like to quickly add a vector}
\CommentTok{# the 'veclis'. You must specify list() like this}
\NormalTok{veclis <-}\StringTok{ }\KeywordTok{c}\NormalTok{(veclis, }\KeywordTok{list}\NormalTok{(}\DataTypeTok{r=}\DecValTok{3}\OperatorTok{:}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{extracting-output-from-built-in-functions}{%
\subsection{Extracting output from built-in functions}\label{extracting-output-from-built-in-functions}}

One reason to gain a better understanding of lists is that many built-in functions return not just single numbers, but a diverse collection of outputs, organized in lists. Think of the linear model function (\texttt{lm}), it returns a lot of things at the same time (not just the p-value).

Let's take a closer look at the \texttt{lm} output to see if we can extract the adjusted R\(^2\).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Read data}
\KeywordTok{data}\NormalTok{(allometry)}

\CommentTok{# Fit a linear model}
\NormalTok{lmfit <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(height }\OperatorTok{~}\StringTok{ }\NormalTok{diameter, }\DataTypeTok{data=}\NormalTok{allometry)}

\CommentTok{# And save the summary statement of the model:}
\NormalTok{lmfit_summary <-}\StringTok{ }\KeywordTok{summary}\NormalTok{(lmfit)}

\CommentTok{# We already know that simply typing 'summary(lmfit)' will give }
\CommentTok{# lots of text output. How to extract numbers from there?}
\CommentTok{# Let's look at the structure of lmfit:}
\KeywordTok{str}\NormalTok{(lmfit_summary)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## List of 11
##  $ call         : language lm(formula = height ~ diameter, data = allometry)
##  $ terms        :Classes 'terms', 'formula'  language height ~ diameter
##   .. ..- attr(*, "variables")= language list(height, diameter)
##   .. ..- attr(*, "factors")= int [1:2, 1] 0 1
##   .. .. ..- attr(*, "dimnames")=List of 2
##   .. .. .. ..$ : chr [1:2] "height" "diameter"
##   .. .. .. ..$ : chr "diameter"
##   .. ..- attr(*, "term.labels")= chr "diameter"
##   .. ..- attr(*, "order")= int 1
##   .. ..- attr(*, "intercept")= int 1
##   .. ..- attr(*, "response")= int 1
##   .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv> 
##   .. ..- attr(*, "predvars")= language list(height, diameter)
##   .. ..- attr(*, "dataClasses")= Named chr [1:2] "numeric" "numeric"
##   .. .. ..- attr(*, "names")= chr [1:2] "height" "diameter"
##  $ residuals    : Named num [1:63] -8.84 1.8 0.743 2.499 4.37 ...
##   ..- attr(*, "names")= chr [1:63] "1" "2" "3" "4" ...
##  $ coefficients : num [1:2, 1:4] 7.5967 0.5179 1.4731 0.0365 5.157 ...
##   ..- attr(*, "dimnames")=List of 2
##   .. ..$ : chr [1:2] "(Intercept)" "diameter"
##   .. ..$ : chr [1:4] "Estimate" "Std. Error" "t value" "Pr(>|t|)"
##  $ aliased      : Named logi [1:2] FALSE FALSE
##   ..- attr(*, "names")= chr [1:2] "(Intercept)" "diameter"
##  $ sigma        : num 5.55
##  $ df           : int [1:3] 2 61 2
##  $ r.squared    : num 0.768
##  $ adj.r.squared: num 0.764
##  $ fstatistic   : Named num [1:3] 202 1 61
##   ..- attr(*, "names")= chr [1:3] "value" "numdf" "dendf"
##  $ cov.unscaled : num [1:2, 1:2] 7.05e-02 -1.54e-03 -1.54e-03 4.32e-05
##   ..- attr(*, "dimnames")=List of 2
##   .. ..$ : chr [1:2] "(Intercept)" "diameter"
##   .. ..$ : chr [1:2] "(Intercept)" "diameter"
##  - attr(*, "class")= chr "summary.lm"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# The output of lm is a list, so we can look at the names of # that list as well:}
\KeywordTok{names}\NormalTok{(lmfit_summary)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "call"          "terms"         "residuals"     "coefficients" 
##  [5] "aliased"       "sigma"         "df"            "r.squared"    
##  [9] "adj.r.squared" "fstatistic"    "cov.unscaled"
\end{verbatim}

So, now we can extract results from the summary of the fitted regression. Also look at the help file \texttt{?summary.lm}, in the section `Values' for a description of the fields contained here.

To extract the adjusted R\(^2\), for example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lmfit_summary[[}\StringTok{"adj.r.squared"}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7639735
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Is the same as:}
\NormalTok{lmfit_summary}\OperatorTok{$}\NormalTok{adj.r.squared}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7639735
\end{verbatim}

This sort of analysis will be very useful when we do many regressions, and want to summarize the results in a table.

\BeginKnitrBlock{rmdtry}
Run the code in the above examples, and practice extracting some other elements from the linear regression. Compare the output to the summary of the \texttt{lm} fit (that is, compare it to what \texttt{summary(lmfit)} shows on screen).
\EndKnitrBlock{rmdtry}

\hypertarget{dfrlists}{%
\subsection{Creating lists from dataframes}\label{dfrlists}}

For more advanced analyses, it is often necessary to repeat a particular analysis many times, for example for sections of a dataframe.

Using the \texttt{allom} data for example, we might want to split the dataframe into three dataframes (one for each species), and repeat some analysis for each of the species. One option is to make three subsets (using \texttt{subset}), and repeating the analysis for each of them. But what if we have hundreds of species?

A more efficient approach is to \texttt{split} the dataframe into a list, so that the first element of the list is the dataframe for species 1, the 2nd element species 2, and so on. In case of the allom dataset, the resulting list will have three components.

Let's look at an example on how to construct a list of dataframes from the allom dataset, one per species:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Read allom data and make sure 'species' is a factor:}
\KeywordTok{data}\NormalTok{(allometry)}
\KeywordTok{is.factor}\NormalTok{(allometry}\OperatorTok{$}\NormalTok{species)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# The levels of the factor variable 'species'}
\KeywordTok{levels}\NormalTok{(allometry}\OperatorTok{$}\NormalTok{species)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "PIMO" "PIPO" "PSME"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Now use 'split' to construct a list:}
\NormalTok{allomsp <-}\StringTok{ }\KeywordTok{split}\NormalTok{(allometry, allometry}\OperatorTok{$}\NormalTok{species)}

\CommentTok{# The length of the list should be 3, with the names equal to the }
\CommentTok{# original factor levels:}
\KeywordTok{length}\NormalTok{(allomsp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(allomsp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "PIMO" "PIPO" "PSME"
\end{verbatim}

\BeginKnitrBlock{rmdtry}
Run the code in the above example, and confirm that \texttt{allomsp{[}{[}2{]}{]}} is identical to taking a subset of \texttt{allom} of the second species in the dataset (where `second' refers to the second level of the factor variable \texttt{species}, which you can find out with \texttt{levels}).
\EndKnitrBlock{rmdtry}

Let's look at an example using the \texttt{hydro} data. The data contains water levels of a hydrodam in Tasmania, from 2005 to 2011.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Read hydro data, and convert Date to a proper date class.}
\KeywordTok{data}\NormalTok{(hydro)}

\KeywordTok{library}\NormalTok{(lubridate)}
\KeywordTok{library}\NormalTok{(dplyr)}

\NormalTok{hydro <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(hydro, }
                \DataTypeTok{Date =} \KeywordTok{dmy}\NormalTok{(Date),}
                \DataTypeTok{year =} \KeywordTok{year}\NormalTok{(Date))}

\CommentTok{# Look at the Date range:}
\KeywordTok{range}\NormalTok{(hydro}\OperatorTok{$}\NormalTok{Date)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2005-08-08" "2011-08-08"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Let's get rid of the first and last years (2005 and 2011) since they are incomplete}
\NormalTok{hydro <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(hydro, }\OperatorTok{!}\NormalTok{year }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2005}\NormalTok{,}\DecValTok{2011}\NormalTok{))}

\CommentTok{# Now split the dataframe by year. This results in a list, where every}
\CommentTok{# element contains the data for one year:}
\NormalTok{hydrosp <-}\StringTok{ }\KeywordTok{split}\NormalTok{(hydro, hydro}\OperatorTok{$}\NormalTok{year)}

\CommentTok{# Properties of this list:}
\KeywordTok{length}\NormalTok{(hydrosp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(hydrosp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2006" "2007" "2008" "2009" "2010"
\end{verbatim}

To extract one element of the two lists that we created (\texttt{allomsp} and \texttt{hydrosp}), recall the section on indexing lists.

\hypertarget{lapply}{%
\subsection{Applying functions to lists}\label{lapply}}

We will introduce two basic tools that we use to apply functions to each element of a list: \texttt{sapply} and \texttt{lapply}. The \texttt{lapply} function always returns a list, whereas \texttt{sapply} will attempt to \texttt{s}implify the result. When the function returns a single value, or a vector, \texttt{sapply} can often be used. In practice, try both and see what happens!

\hypertarget{using-sapply}{%
\subsubsection{\texorpdfstring{Using \texttt{sapply}}{Using sapply}}\label{using-sapply}}

First let's look at some simple examples:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Let's make a simple list with only numeric vectors (of varying length)}
\NormalTok{numlis <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{x=}\DecValTok{1000}\NormalTok{, }\DataTypeTok{y=}\KeywordTok{c}\NormalTok{(}\FloatTok{2.1}\NormalTok{,}\FloatTok{0.1}\NormalTok{,}\OperatorTok{-}\DecValTok{19}\NormalTok{), }\DataTypeTok{z=}\KeywordTok{c}\NormalTok{(}\DecValTok{100}\NormalTok{,}\DecValTok{200}\NormalTok{,}\DecValTok{100}\NormalTok{,}\DecValTok{100}\NormalTok{))}

\CommentTok{# For the numeric list, let's get the mean for every element, and count }
\CommentTok{# the length of the three vectors.}
\CommentTok{# Here, sapply takes a list and a function as its two arguments,}
\CommentTok{# and applies that function to each element of the list.}
\KeywordTok{sapply}\NormalTok{(numlis, mean)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      x      y      z 
## 1000.0   -5.6  125.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sapply}\NormalTok{(numlis, length)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## x y z 
## 1 3 4
\end{verbatim}

You can of course also define your own functions, and use them here. Let's look at another simple example using the \texttt{numlis} object defined above.

For example,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Let's find out if any diameters are duplicated in the allom dataset.}
\CommentTok{# A function that does this would be the combination of 'any' and 'duplicated',}
\NormalTok{anydup <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(vec)}\KeywordTok{any}\NormalTok{(}\KeywordTok{duplicated}\NormalTok{(vec))}
\CommentTok{# This function returns TRUE or FALSE}

\CommentTok{# Apply this function to numlis (see above):}
\KeywordTok{sapply}\NormalTok{(numlis, anydup)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     x     y     z 
## FALSE FALSE  TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# You can also define the function on the fly like this:}
\KeywordTok{sapply}\NormalTok{(numlis, }\ControlFlowTok{function}\NormalTok{(x)}\KeywordTok{any}\NormalTok{(}\KeywordTok{duplicated}\NormalTok{(x)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     x     y     z 
## FALSE FALSE  TRUE
\end{verbatim}

Now, you can use any function in \texttt{sapply} as long as it returns a single number based on the element of the list that you used it on. Consider this example with \texttt{strsplit}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Recall that the 'strsplit' (string split) function usually returns a list of values. }
\CommentTok{# Consider the following example, where the data provider has included the units in }
\CommentTok{# the measurements of fish lengths. How do we extract the number bits?}
\NormalTok{fishlength <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"120 mm"}\NormalTok{, }\StringTok{"240 mm"}\NormalTok{, }\StringTok{"159 mm"}\NormalTok{, }\StringTok{"201 mm"}\NormalTok{)}

\CommentTok{# Here is one solution, using strsplit}
\KeywordTok{strsplit}\NormalTok{(fishlength,}\StringTok{" "}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1] "120" "mm" 
## 
## [[2]]
## [1] "240" "mm" 
## 
## [[3]]
## [1] "159" "mm" 
## 
## [[4]]
## [1] "201" "mm"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# We see that strsplit returns a list, let's use sapply to extract only }
\CommentTok{# the first element (the number)}
\NormalTok{splitlen <-}\StringTok{ }\KeywordTok{strsplit}\NormalTok{(fishlength,}\StringTok{" "}\NormalTok{)}
\KeywordTok{sapply}\NormalTok{(splitlen, }\ControlFlowTok{function}\NormalTok{(x)x[}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "120" "240" "159" "201"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Now all you need to do is use 'as.numeric' to convert these bits of text to numbers.}
\end{Highlighting}
\end{Shaded}

The main purpose of splitting dataframes into lists, as we have done above, is so that we can save time with analyses that have to be repeated many times. In the following examples, you must have already produced the objects \texttt{hydrosp} and \texttt{allomsp} (from examples in the previous section).Both those objects are \emph{lists of dataframes}, that is, each element of the list is a dataframe in itself. Let's look at a few examples with \texttt{sapply} first.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# How many observations per species in the allom dataset?}
\KeywordTok{sapply}\NormalTok{(allomsp, nrow)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PIMO PIPO PSME 
##   19   22   22
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Here, we applied the 'nrow' function to each separate dataframe.}
\CommentTok{# (note that there are easier ways to find the number of observations per species!,}
\CommentTok{# this is just illustrating sapply.)}

\CommentTok{# Things get more interesting when you define your own functions on the fly:}
\KeywordTok{sapply}\NormalTok{(allomsp, }\ControlFlowTok{function}\NormalTok{(x)}\KeywordTok{range}\NormalTok{(x}\OperatorTok{$}\NormalTok{diameter))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       PIMO  PIPO  PSME
## [1,]  6.48  4.83  5.33
## [2,] 73.66 70.61 69.85
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Here, we define a function that takes 'x' as an argument:}
\CommentTok{# sapply will apply this function to each element of the list,}
\CommentTok{# one at a time. In this case, we get a matrix with ranges of the diameter per species.}

\CommentTok{# How about the correlation of two variables, separate by species:}
\KeywordTok{sapply}\NormalTok{(allomsp, }\ControlFlowTok{function}\NormalTok{(x)}\KeywordTok{cor}\NormalTok{(x}\OperatorTok{$}\NormalTok{diameter, x}\OperatorTok{$}\NormalTok{height))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      PIMO      PIPO      PSME 
## 0.9140428 0.8594689 0.8782781
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# For hydro, find the number of days that storage was below 235, for each year.}
\KeywordTok{sapply}\NormalTok{(hydrosp, }\ControlFlowTok{function}\NormalTok{(x)}\KeywordTok{sum}\NormalTok{(x}\OperatorTok{$}\NormalTok{storage }\OperatorTok{<}\StringTok{ }\DecValTok{235}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 2006 2007 2008 2009 2010 
##    0   18    6    0    0
\end{verbatim}

\hypertarget{using-lapply}{%
\subsubsection{\texorpdfstring{Using \texttt{lapply}}{Using lapply}}\label{using-lapply}}

The \texttt{lapply} function is much like \texttt{sapply}, except it always returns a list.

For example,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Get a summary of the hydro dataset by year:}
\KeywordTok{lapply}\NormalTok{(hydrosp, summary)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $`2006`
##       Date               storage           year     
##  Min.   :2006-01-02   Min.   :411.0   Min.   :2006  
##  1st Qu.:2006-04-01   1st Qu.:449.5   1st Qu.:2006  
##  Median :2006-06-29   Median :493.0   Median :2006  
##  Mean   :2006-06-29   Mean   :514.3   Mean   :2006  
##  3rd Qu.:2006-09-26   3rd Qu.:553.8   3rd Qu.:2006  
##  Max.   :2006-12-25   Max.   :744.0   Max.   :2006  
## 
## $`2007`
##       Date               storage           year     
##  Min.   :2007-01-01   Min.   :137.0   Min.   :2007  
##  1st Qu.:2007-04-02   1st Qu.:223.0   1st Qu.:2007  
##  Median :2007-07-02   Median :319.0   Median :2007  
##  Mean   :2007-07-02   Mean   :363.2   Mean   :2007  
##  3rd Qu.:2007-10-01   3rd Qu.:477.0   3rd Qu.:2007  
##  Max.   :2007-12-31   Max.   :683.0   Max.   :2007  
## 
## $`2008`
##       Date               storage           year     
##  Min.   :2008-01-07   Min.   :202.0   Min.   :2008  
##  1st Qu.:2008-04-05   1st Qu.:267.8   1st Qu.:2008  
##  Median :2008-07-03   Median :345.0   Median :2008  
##  Mean   :2008-07-03   Mean   :389.5   Mean   :2008  
##  3rd Qu.:2008-09-30   3rd Qu.:551.8   3rd Qu.:2008  
##  Max.   :2008-12-29   Max.   :637.0   Max.   :2008  
## 
## $`2009`
##       Date               storage           year     
##  Min.   :2009-01-05   Min.   :398.0   Min.   :2009  
##  1st Qu.:2009-04-04   1st Qu.:467.0   1st Qu.:2009  
##  Median :2009-07-02   Median :525.5   Median :2009  
##  Mean   :2009-07-02   Mean   :567.6   Mean   :2009  
##  3rd Qu.:2009-09-29   3rd Qu.:677.8   3rd Qu.:2009  
##  Max.   :2009-12-28   Max.   :791.0   Max.   :2009  
## 
## $`2010`
##       Date               storage           year     
##  Min.   :2010-01-04   Min.   :251.0   Min.   :2010  
##  1st Qu.:2010-04-03   1st Qu.:316.0   1st Qu.:2010  
##  Median :2010-07-01   Median :368.5   Median :2010  
##  Mean   :2010-07-01   Mean   :428.5   Mean   :2010  
##  3rd Qu.:2010-09-28   3rd Qu.:577.5   3rd Qu.:2010  
##  Max.   :2010-12-27   Max.   :649.0   Max.   :2010
\end{verbatim}

Suppose you have multiple similar datasets in your working directory, and you want to read all of these into one list, use \texttt{lapply} like this (run this example yourself and inspect the results).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Names of your datasets:}
\NormalTok{filenames <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"pupae.csv"}\NormalTok{,}\StringTok{"pupae.csv"}\NormalTok{,}\StringTok{"pupae.csv"}\NormalTok{)}
\CommentTok{# (This toy example will read the same file three times).}

\CommentTok{# Read all files into one list,}
\NormalTok{alldata <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(filenames, read.csv)}

\CommentTok{# Then, if you are sure the datasets have the same number of columns and names,}
\CommentTok{# use do.call to collapse the list:}
\NormalTok{dfrall <-}\StringTok{ }\KeywordTok{do.call}\NormalTok{(rbind, alldata)}
\end{Highlighting}
\end{Shaded}

\BeginKnitrBlock{rmdtry}
Recall the use of \texttt{dir} to list files, and even to find files that match a specific pattern (see Section \ref{fileswd}. Read all CSV files in your working directory (or elsewhere) into a single list, and count the number of rows for each dataframe.
\EndKnitrBlock{rmdtry}

Finally, we can use \texttt{lapply} to do all sorts of complex analyses that return any kind of object. The use of \texttt{lapply} with lists ensures that we can organize even large amounts of data in this way.

Let's do a simple linear regression of log(leafarea) on log(diameter) for the Allometry dataset, by species:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Run the linear regression on each element of the list, store in a new object:}
\NormalTok{lmresults <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(allomsp, }\ControlFlowTok{function}\NormalTok{(x)}\KeywordTok{lm}\NormalTok{(}\KeywordTok{log10}\NormalTok{(leafarea) }\OperatorTok{~}\StringTok{ }\KeywordTok{log10}\NormalTok{(diameter), }\DataTypeTok{data=}\NormalTok{x))}

\CommentTok{# Now, lmresults is itself a list (where each element is an object as returned by lm)}
\CommentTok{# We can extract the coefficients like this:}
\KeywordTok{sapply}\NormalTok{(lmresults, coef)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                       PIMO       PIPO       PSME
## (Intercept)     -0.3570268 -0.7368336 -0.3135996
## log10(diameter)  1.5408859  1.6427773  1.4841361
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# This shows the intercept and slope by species.}
\CommentTok{# Also look at (results not shown):}
\CommentTok{# lapply(lmresults, summary) }

\CommentTok{# Get R2 for each model. First write a function that extracts it.}
\NormalTok{getR2 <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x)}\KeywordTok{summary}\NormalTok{(x)}\OperatorTok{$}\NormalTok{adj.r.squared}
\KeywordTok{sapply}\NormalTok{(lmresults, getR2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      PIMO      PIPO      PSME 
## 0.8738252 0.8441844 0.6983126
\end{verbatim}

\BeginKnitrBlock{rmdtry}
Try to fully understand the difference between \texttt{sapply} and \texttt{lapply} by using \texttt{lapply} in some of the examples where we used \texttt{sapply} (and vice versa).
\EndKnitrBlock{rmdtry}

\hypertarget{simpleloops}{%
\section{Loops}\label{simpleloops}}

Loops can be useful when we need to repeat certain analyses many times, and it is difficult to achieve this with \texttt{lapply} or \texttt{sapply}. To understand how a \texttt{for} loop works, look at this example:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{)\{}
  \KeywordTok{message}\NormalTok{(i)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 1
\end{verbatim}

\begin{verbatim}
## 2
\end{verbatim}

\begin{verbatim}
## 3
\end{verbatim}

\begin{verbatim}
## 4
\end{verbatim}

\begin{verbatim}
## 5
\end{verbatim}

Here, the bit of code between \{\} is executed five times, and the object \texttt{i} has the values 1,2,3,4 and 5, in that order. Instead of just printing \texttt{i} as we have done above, we can also index a vector with this object:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# make a vector}
\NormalTok{myvec <-}\StringTok{ }\KeywordTok{round}\NormalTok{(}\KeywordTok{runif}\NormalTok{(}\DecValTok{5}\NormalTok{),}\DecValTok{1}\NormalTok{)}

\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(myvec))\{}
  \KeywordTok{message}\NormalTok{(}\StringTok{"Element "}\NormalTok{, i, }\StringTok{" of the vector is: "}\NormalTok{, myvec[i])}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Element 1 of the vector is: 0.3
\end{verbatim}

\begin{verbatim}
## Element 2 of the vector is: 0.1
\end{verbatim}

\begin{verbatim}
## Element 3 of the vector is: 0.1
\end{verbatim}

\begin{verbatim}
## Element 4 of the vector is: 0.7
\end{verbatim}

\begin{verbatim}
## Element 5 of the vector is: 0.2
\end{verbatim}

Note that this is only a toy example: the same result can be achieved by simply typing \texttt{myvec}.

Now let's look at a useful application of a \texttt{for} loop: producing multiple plots in a \texttt{pdf}, using the \texttt{allomsp} object we created earlier.

This bit of code produces a \texttt{pdf} in your current working directory. If you can't find it, recall that you can use \texttt{getwd}() to get the current working directory.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Open a pdf to send the plots to:}
\KeywordTok{pdf}\NormalTok{(}\StringTok{"Allom plot by species.pdf"}\NormalTok{, }\DataTypeTok{onefile=}\OtherTok{TRUE}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{)\{}
  \KeywordTok{with}\NormalTok{(allomsp[[i]],}
       \KeywordTok{plot}\NormalTok{(diameter, leafarea, }\DataTypeTok{pch=}\DecValTok{15}\NormalTok{, }\DataTypeTok{xlim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{80}\NormalTok{), }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{450}\NormalTok{),}
            \DataTypeTok{main=}\KeywordTok{levels}\NormalTok{(allom}\OperatorTok{$}\NormalTok{species)[i]))}
\NormalTok{\}}
\CommentTok{# Close the pdf (important!)}
\KeywordTok{dev.off}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Here, we create three plots (\texttt{i} goes from 1 to 3), every time using a different element of the list \texttt{allomsp}. First, \texttt{i} will have the value 1, so that we end up using the dataframe \texttt{allomsp{[}{[}1{]}{]}}, the first element of the list. And so on. Take a look at the resulting PDF to understand how the code works.

\emph{Note:} On windows (with Adobe reader) If the pdf (\texttt{Allom\ plot\ by\ species.pdf}) is open, the above will fail. If you try this anyway, close the pdf and try again. You may have to run the command \texttt{dev.off}() another time to make sure the device is ready.

Another way to achieve the same result is to avoid splitting the dataframe into a list first, and simply take subsets on the fly. Consider this template (make your own working example based on any dataset).

We assume here you have a dataframe called `dataset' with a factor `species', for which you want to create separate plots of Y vs.~X.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pdf}\NormalTok{(}\StringTok{"somefilename.pdf"}\NormalTok{, }\DataTypeTok{onefile=}\OtherTok{TRUE}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{(lev }\ControlFlowTok{in} \KeywordTok{levels}\NormalTok{(dataset}\OperatorTok{$}\NormalTok{species))\{}
  
  \KeywordTok{with}\NormalTok{(}\KeywordTok{subset}\NormalTok{(dataset, species}\OperatorTok{==}\NormalTok{lev),}
       \KeywordTok{plot}\NormalTok{(X,Y, }
            \DataTypeTok{main=}\KeywordTok{as.character}\NormalTok{(lev)))}
\NormalTok{\}}
\KeywordTok{dev.off}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{webservices}{%
\chapter{R on the web}\label{webservices}}

\hypertarget{introduction-4}{%
\section{Introduction}\label{introduction-4}}

This short chapter will show how to interact with, and deploy web services from R. An API (`Application Programming Interface') is a way to access data or services on a server, for example to download or upload data. The most common architecture for APIs is known as RESTful Web Services (or `REST API' for short). We will use the \texttt{httr} package to download data from REST APIs.

We start with downloading data from, and querying remotely stored databases, and include two working examples: a database (updated every 15min) in a MongoDB database, and a single table stored in a PostgreSQL database.

\textbf{Packages used in this chapter}

\begin{itemize}
\tightlist
\item
  By now standard packages, \texttt{lgrdata}, \texttt{dplyr}, \texttt{lubridate}
\item
  \texttt{plumber} for launching web services.
\item
  \texttt{DBI} to interface with databases.
\item
  \texttt{dbplyr} to make this interface even easier.
\item
  \texttt{purrr} (for \texttt{flatten\_dfr}, though the package offers much more).
\end{itemize}

\hypertarget{reading-data-from-remote-databases}{%
\section{Reading data from remote databases}\label{reading-data-from-remote-databases}}

\hypertarget{nosql}{%
\subsection{NoSQL}\label{nosql}}

In this example we show how to read data from MongoDB - a popular NoSQL database. With the \texttt{mongolite} package it is very straightforward to read data that can be transformed to a dataframe. Here, every item in the database is a piece of JSON, but of equal length and with the same names, so that each item can become a row in a dataframe.

For a remotely stored MongoDB database, you first have to construct the URL, which includes a username and password. The URL looks like,

\begin{verbatim}
"mongodb://username:password@hostingsite.com:portnr/databasename"
\end{verbatim}

The next example is a working example of a database stored on mlab.com, and grabs data using the \texttt{mongolite} package.

The database contains data on number of cars parked on 13 car parks in Almere, the Netherlands. The data are updated every 15 minutes.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# A working URL (5/6/2019)}
\NormalTok{parkingdata_url <-}\StringTok{ "mongodb://guest:123password123@ds229186.mlab.com:29186/almereparking"}

\CommentTok{#}
\KeywordTok{library}\NormalTok{(mongolite)}

\CommentTok{# Make a database connection. Here you don't download data yet, just}
\CommentTok{# set up a connection.}
\NormalTok{db <-}\StringTok{ }\KeywordTok{mongo}\NormalTok{(}\DataTypeTok{collection =} \StringTok{"almereparkingjson"}\NormalTok{,}
            \DataTypeTok{url =}\NormalTok{ parkingdata_url)}

\CommentTok{# We can now download the last 1000 rows of the data.}
\NormalTok{parkingdata <-}\StringTok{ }\NormalTok{db}\OperatorTok{$}\KeywordTok{find}\NormalTok{(}\DataTypeTok{limit =} \DecValTok{1000}\NormalTok{, }\DataTypeTok{sort =} \StringTok{'\{"updated": -1\}'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

If you simply want to download all data, just do \texttt{db\$find()}, it takes less than a minute.

\BeginKnitrBlock{rmdreading}
The above example shows how to make a query with the \texttt{mongolite} package, you can read \href{https://jeroen.github.io/mongolite/query-data.html}{more options in the documentation}.
\EndKnitrBlock{rmdreading}

\hypertarget{sql}{%
\subsection{SQL}\label{sql}}

Here, we briefly show how to interact with SQL databases. There are many R packages available, partly because there are many implementations of SQL databases (including postgres, which we show here). A unified interface is provided by the \texttt{DBI} package (\href{https://db.rstudio.com/dbi/}{link to documentation}), which allows us to use nearly the same code for very different databases.

Here, we only show how to read rectangular data with the \texttt{DBI} and \texttt{dbplyr} packages.

With \texttt{dbConnect}, we setup a connection to the remotely available database (which does not download data yet). Using the connection we can list the tables available, download a table, and many other things.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# General database interface}
\KeywordTok{library}\NormalTok{(DBI)}

\CommentTok{# Drivers for postgres.}
\KeywordTok{library}\NormalTok{(RPostgreSQL)}

\CommentTok{# For generating SQL queries.}
\KeywordTok{library}\NormalTok{(dplyr)}
\KeywordTok{library}\NormalTok{(dbplyr)}

\CommentTok{# Set up connection.}
\CommentTok{# !! This is a working connection (6/5/2019)}
\NormalTok{con <-}\StringTok{ }\KeywordTok{dbConnect}\NormalTok{(}\DataTypeTok{drv =} \KeywordTok{PostgreSQL}\NormalTok{(),}
                 \DataTypeTok{user =} \StringTok{"mjvgsdzg"}\NormalTok{,}
                 \DataTypeTok{password =} \StringTok{"RsIxTmV9a95Gbb6Vo7IgG9wZNiv4Hq5L"}\NormalTok{,}
                 \DataTypeTok{host =} \StringTok{"balarama.db.elephantsql.com"}\NormalTok{,}
                 \DataTypeTok{port =} \DecValTok{5432}\NormalTok{,}
                 \DataTypeTok{dbname =} \StringTok{"mjvgsdzg"}\NormalTok{)}

\CommentTok{# List available tables (only one in this case)}
\KeywordTok{dbListTables}\NormalTok{(con)}

\CommentTok{# Makes a direct connection to the table, but does}
\CommentTok{# not download anything yet:}
\NormalTok{cars <-}\StringTok{ }\KeywordTok{tbl}\NormalTok{(con, }\StringTok{"automobiles"}\NormalTok{)}

\CommentTok{# We can download the entire table with collect,}
\CommentTok{# but note that in practice we rarely do this as databases may be extremely large.}
\NormalTok{cars_data <-}\StringTok{ }\KeywordTok{collect}\NormalTok{(cars)}
  
\CommentTok{# We can now make queries using dplyr syntax, to collect only subsets of data.}
\CommentTok{# for example, find all cars with weight over 2000kg.}
\NormalTok{heavycars_query <-}\StringTok{ }\NormalTok{cars }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(weight }\OperatorTok{>}\StringTok{ }\DecValTok{2000}\NormalTok{)}

\CommentTok{# What does the query look like in SQL?}
\KeywordTok{show_query}\NormalTok{(heavycars_query)}

\CommentTok{# Now send the query to the database, collect the data.}
\NormalTok{heavycars <-}\StringTok{ }\KeywordTok{collect}\NormalTok{(heavycars_query)}


\CommentTok{# Many other functions from dplyr or other can be used on databases,}
\CommentTok{# but not everything! Some trial and error may be necessary.}
\CommentTok{# Find all cars that have 'buick' in the name, using grepl:}
\NormalTok{buick_query <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(cars,}
                \KeywordTok{grepl}\NormalTok{(}\StringTok{"buick"}\NormalTok{, car_name)}
\NormalTok{               )}
\end{Highlighting}
\end{Shaded}

\BeginKnitrBlock{rmdtry}
Run both examples above - getting data from a (continuously updated\_ MongoDB database, and a simple static PostreSQL database. Try applying some \texttt{dplyr} filters and summaries on the data.
\EndKnitrBlock{rmdtry}

\hypertarget{accessing-an-api}{%
\section{Accessing an API}\label{accessing-an-api}}

A REST API is simply presented as a URL, to which a specific service can be accessed, and even parameters passed (when necessary). A URL may simply look like:

\begin{verbatim}
https://someserver.com/getdata
\end{verbatim}

or may be more complicated, with queries, authentication, and so on. Let's look a simple example, using the \texttt{httr} package:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(httr)}

\CommentTok{# The first step is to reach out to the server, and get a response.}
\CommentTok{# Here, g is a complicated object that we do not inspect directly.}
\NormalTok{g <-}\StringTok{ }\KeywordTok{GET}\NormalTok{(}\StringTok{"https://opendata.cbs.nl/ODataApi/OData/37789ksz/TypedDataSet"}\NormalTok{)}

\CommentTok{# Important: if the server could be reached, you have permission, }
\CommentTok{# and the service is available, you should see 200 as the response.}
\CommentTok{# Other HTML codes include 404 (service not found).}
\KeywordTok{status_code}\NormalTok{(g)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 200
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# We can read the actual data with the `content` function:}
\NormalTok{dat <-}\StringTok{ }\KeywordTok{content}\NormalTok{(g)}

\CommentTok{# In this case, dat has two components - the interesting one is 'value'}
\NormalTok{uitkering_data_list <-}\StringTok{ }\NormalTok{dat}\OperatorTok{$}\NormalTok{value}
\end{Highlighting}
\end{Shaded}

Unfortunately the result is a nested list, with NULL elements in some. To make this into a dataframe, we want to flatten each list, each of these will become a row in our dataframe, and bind all the rows together. This is such a common problem that I will show a robust solution:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr) }\CommentTok{# bind_rows}
\KeywordTok{library}\NormalTok{(purrr) }\CommentTok{# flatten_dfr}

\NormalTok{uitkering_data <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(uitkering_data_list, flatten_dfr) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{bind_rows}
\end{Highlighting}
\end{Shaded}

We now have data from the Dutch government on social benefits, a dataset that gets updated frequently. The use of the API directly rather than downloading the data manually is clearly a much better option.

As we saw in this example, the challenge is often not so much getting \emph{something} from the web service, but often we have substantial work to shape it into a useful object in R (usually: a dataframe).

\BeginKnitrBlock{rmdtry}
Try downloading data from this URL (containing Dutch demography data since 1898).

\url{https://opendata.cbs.nl/ODataApi/odata/37556/TypedDataSet}
\EndKnitrBlock{rmdtry}

\hypertarget{deploying-an-api-with-plumber}{%
\section{\texorpdfstring{Deploying an API with \texttt{plumber}}{Deploying an API with plumber}}\label{deploying-an-api-with-plumber}}

\hypertarget{deploying-a-simple-api}{%
\subsection{Deploying a simple API}\label{deploying-a-simple-api}}

With \texttt{plumber} we can quickly set up an API, that we can use from within any other programming language, web site, or program. Normally you would deploy the API on a server running R, so that the R service can be used from anywhere. Here, to keep things simple, we deploy the API on your own machine (`locally'), but it will work similarly to when it runs on a remote server.

The first step is to create a standalone script (with extension .R) that defines as many \emph{functions} as you like. Each function can take arguments. Take the following example, paste it in a script, call it \texttt{plumber.R}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# plumber.R}

\CommentTok{#* Echo back the input, in uppercase}
\CommentTok{#* @param msg The message to echo}
\CommentTok{#* @get /echo}
\ControlFlowTok{function}\NormalTok{(}\DataTypeTok{msg=}\StringTok{""}\NormalTok{)\{}
  \KeywordTok{list}\NormalTok{(}\DataTypeTok{msg =} \KeywordTok{paste0}\NormalTok{(}\StringTok{"The message is: '"}\NormalTok{, }\KeywordTok{toupper}\NormalTok{(msg), }\StringTok{"'"}\NormalTok{))}
\NormalTok{\}}

\CommentTok{#* Plot a histogram}
\CommentTok{#* @png}
\CommentTok{#* @get /plot}
\ControlFlowTok{function}\NormalTok{()\{}
\NormalTok{  rand <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{)}
  \KeywordTok{hist}\NormalTok{(rand)}
\NormalTok{\}}

\CommentTok{#* Return the sum of two numbers}
\CommentTok{#* @param a The first number to add}
\CommentTok{#* @param b The second number to add}
\CommentTok{#* @get /sum}
\ControlFlowTok{function}\NormalTok{(a, b)\{}
  \KeywordTok{as.numeric}\NormalTok{(a) }\OperatorTok{+}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(b)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The first function sends back an uppercase version of a message, the second function plots a histogram, and the third function adds two numbers. Obviously, you can write much, much more complicated R functions that can be subsequently called using the API. These functions are chosen because they return different things: text, a plot, and a number. Let's see how they work in practice.

With our API `endpoints' (the three functions) defined, we can start the API via:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(plumber)}

\CommentTok{# There are no other arguments besides a directory to find the file.}
\NormalTok{p <-}\StringTok{ }\KeywordTok{plumb}\NormalTok{(}\StringTok{"plumber.R"}\NormalTok{)}

\CommentTok{# Deploy the API.}
\NormalTok{p}\OperatorTok{$}\KeywordTok{run}\NormalTok{(}\DataTypeTok{port=}\DecValTok{8001}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Your R process will now be busy (until you close it), with a message like:

\begin{verbatim}
Starting server to listen on port 8001
\end{verbatim}

This will also open up a \texttt{swagger} window, which is a simple interface to our own Web service. Here you can `Try out' the various end points.

\BeginKnitrBlock{rmdtry}
Try out the web service you just created as follows: open up a browser, and try each of the three endpoints:

\texttt{127.0.0.1:8001/echo?msg="make\ me\ uppercase!"}
\texttt{127.0.0.1:8001/plot"}
\texttt{127.0.0.1:8001/sum?a=2\&b=3"}

Now go back to the script above, and notice how each endpoint is defined (\texttt{echo}, \texttt{plot}, and \texttt{sum})
\EndKnitrBlock{rmdtry}

\BeginKnitrBlock{rmdreading}
The above example comes straight from the \texttt{plumber} documentation, which you can read here: \url{https://www.rplumber.io/}

More complicated examples are available as well.
\EndKnitrBlock{rmdreading}

\bibliography{book.bib}


\end{document}
